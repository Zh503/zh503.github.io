---
title: IVDetect
date: 2024-04-22 09:53:28
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

# Vulnerability Detection with Fine-Grained Interpretations

来源：`ESEC/FSE '21: 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering`（CCF A）

## 摘要

尽管基于机器学习（ML）和深度学习（DL）的漏洞检测器（VD）取得了成功，但它们仅限于提供关于给定代码是否易受攻击的决策，而不提供有关代码哪部分与检测到的漏洞相关的详细信息。我们提出了IVDetect，一个可解释的漏洞检测器，其理念是使用人工智能（AI）来检测漏洞，同时使用智能助手（IA）以易受攻击的语句的形式提供VD解释。在漏洞检测方面，我们单独考虑了易受攻击的语句及其周围上下文，通过数据和控制依赖进行分析。这使得我们的模型在区分易受攻击的语句方面，比现有方法中使用的易受攻击代码与上下文代码的混合表现得更好。除了粗粒度的漏洞检测结果外，我们还利用可解释的人工智能为用户提供细粒度的解释，包括程序依赖图（PDG）中的子图，以及与检测到的漏洞相关的关键语句。我们对漏洞数据库的实证评估表明，IVDetect在top-10 nDCG和MAP排名得分上，比现有基于DL的方法分别高出43%–84%和105%–255%。在top-5排名列表中，IVDetect能够通过其解释正确指出与漏洞相关的易受攻击的语句，准确率达到67%。在准确性方面，IVDetect比基准解释模型提高了12.3%–400%和9%–400%。

## 1 引言

软件漏洞已经给我们的社会软件基础设施造成了重大损害。为了解决这个问题，已经提出了几种自动化的漏洞检测（VD）方法。它们可以大致分为两类：基于程序分析（PA）的[1, 2, 7–9, 33]和基于机器学习（ML）的[23, 29, 31]。基于PA的VD技术通常专注于解决特定类型的漏洞，如缓冲区溢出[3]，SQL注入[6]，跨站脚本攻击[5]，认证绕过[4]等。除了这些类型之外，更通用的软件漏洞，例如库/框架API使用中的软件漏洞，也以各种形式出现。为了检测它们，已经利用机器学习（ML）和深度学习（DL）从先前的易受攻击代码中隐式学习漏洞的模式[15, 20, 37]

###### 尽管具有一些优势，基于ML/DL的VD方法仍然局限于提供粗粒度的检测结果，即整个给定方法是否易受攻击。与基于PA的方法相比，它们在详细说明可能涉及检测到漏洞的具体语句的代码行细粒度细节方面存在不足。人们可以使用故障定位（FL）技术[16]来定位易受攻击的语句，然而这需要大型的、有效的测试套件。由于现有基于ML/DL的VD工具提供的这种粗粒度的反馈，开发人员不知道在代码中何处以及查找和修复什么漏洞。这阻碍了他们调查潜在漏洞的能力。

为了提升基于ML/DL的VD水平，我们提出了IVDetect，一个可解释的VD，其理念是使用人工智能检测粗粒度的漏洞，同时通过可解释的ML智能助手提供关于与漏洞相关的易受攻击语句的细粒度解释。

对于粗粒度的漏洞检测，我们的创新之处在于对易受攻击代码的上下文感知表示学习。在训练过程中，现有的基于ML/DL的VD方法[20, 37]将方法中的整个易受攻击代码作为输入，而没有将易受攻击的语句与周围的上下文代码区分开来。这种在训练过程中区分漏洞代码和上下文的做法使IVDetect能够更好地学习区分易受攻击的代码和良性代码。我们通过程序依赖图（PDG）表示源代码，并将漏洞检测问题视为基于图卷积网络（GCN）[17]进行图分类，并加入特征注意力（FA），即FA-GCN。在代码表示学习中，易受攻击的语句连同周围的代码一起被编码。

为了进行细粒度解释，鉴于采用的方法被IVDetect认为存在漏洞，我们的创新之处在于利用可解释的机器学习模型（即文献[36]中的模型）来解释涉及到检测到的漏洞的PDG中的脆弱语句。选择PDG子图作为解释的原因是漏洞通常涉及语句之间的数据和控制依赖关系（参见文献[27]）。

为了得出作为解释的脆弱语句，我们利用可解释的机器学习模型GNNExplainer（文献[36]），该模型能够“解释”模型为何做出其决策。具体来说，在漏洞检测后，为了生成解释，IVDetect输入FA-GCN模型及其决策（是否存在漏洞），以及给定方法𝑀的输入PDG 𝐺𝑀。目标是找到解释子图，即在𝑀的PDG中定义为最小子图G，它能最小化使用整个𝐺𝑀与使用G时的预测分数差异。为此，我们利用GNNExplainer，其中搜索G被构建为边掩码集𝐸𝑀的学习过程。如果一个边属于𝐸𝑀（即从𝐺𝑀中移除），并且影响了模型的决策，那么这个边就是关键的，必须包含在检测结果的解释中。因此，PDG中的最小子图G包含节点和边，即与检测到的漏洞最具决定性/相关的关键语句和程序依赖关系。

利用IVDetect的结果，从业者可以：

1）检查潜在脆弱方法的排名列表；

2）利用解释功能进一步调查代码中哪些语句导致模型预测出这种脆弱性。

我们进行了多项实验，以评估IVDetect在方法级的漏洞检测以及针对脆弱语句的解释方面的表现。我们使用了三个大型的C/C++漏洞数据集：Fan [13]、Reveal [11]和FFMPeg+Qemu [37]。在方法级漏洞检测（VD）方面，我们的结果显示，IVDetect在两个排名得分nDCG和MAP上，分别比现有的ML/DL基方法 [11, 19, 20, 28, 37] 提高了43%–84%和105%–255%。在语句级解释方面，IVDetect能在67%的案例中准确指出与脆弱性相关的脆弱语句，并且在前5名的排名列表中表现出色。它在准确度上比基线模型ATT [36]和GRAD [36]分别提高了12.3%–400%和9%–400%。

本文的贡献包括：

A. 可解释性漏洞检测及其细粒度解释。

a. 带细粒度解释的漏洞检测：IVDetect 是首个利用可解释机器学习技术，通过 PDG 子图、语句及其依赖关系的细节增强漏洞检测的方法。

b. 脆弱代码的情境感知表征学习：我们对脆弱代码表征学习的创新之处在于考虑了脆弱语句周围的上下文代码和修复，以更好地训练漏洞检测模型。

B. 实证评估。

我们的结果显示，IVDetect 在检测和解释方面都显示出高准确性（详见数据/结果 [10]）。

## 2 动机

### 2.1例子

图1展示了Linux 4.6中的方法ec_device_ioctl_xcmd，该方法用于构建CromeOS设备的I/O控制命令。该代码在国家漏洞数据库（National Vulnerability Database）的公共漏洞和暴露（CVE-2016-6156）中被列为脆弱代码。

![](https://s2.loli.net/2024/04/12/1v4zY6TBMtoZIbs.png)

相应修复的提交日志指出：“在第6行和第13行，驱动程序通过指针arg使用copy_from_user()函数获取用户空间数据。第一次获取的值（存储在u_cmd中）（第6行）用于获取in_size和out_size元素，并在第10行分配一个缓冲区（s_cmd），以便之后在第13行将整个消息复制到驱动程序中，这意味着整个消息（s_cmd）的复制大小基于第一次获取时的旧值（u_cmd.outsize）。此外，第二次获取复制的整个消息还包含in_size和out_size的元素，这些是新值。第二次获取的新值可能会在竞态条件下被另一个用户线程更改，这将导致在使用不一致的值时出现双重获取错误。”

因此，为了修复这个错误，开发人员在第17至21行添加了代码，以确保由于两个获取调用之间的竞态条件导致u_cmd.outsize和u_cmd.insize没有改变。此外，内存访问可能也超出了数组边界，在将命令传输到ChromeOS设备的第23行的方法调用cros_ec_cmd_xfer(...)中可能导致缓冲区溢出。

![image-20240412100310567](https://s2.loli.net/2024/04/12/KSPAkeNulErV5Bw.png)另一个问题出现在第27行的copy_to_user。方法调用cros_ec_cmd_xfer (...)可以将s_cmd->insize设置为较小的值。因此，必须使用新的较小值，以避免向用户复制过多的数据：第27行的u_cmd.insize被改成了s_cmd->insize。
这段有漏洞的代码可能会导致拒绝服务、缓冲区溢出、程序崩溃等损害。深度学习（DL)的进展使几种方法[20, 37]可以从历史中隐式学习有漏洞代码的模式，并检测更一般的漏洞。然而，与基于程序分析的方法相比，它们在提供有关易受攻击语句的细粒度级别以及模型决定漏洞原因方面仍然有限。例如，基于PA的方法，如竞争检测技术，可能会发现第6行和第13行的两个获取语句的涉入。在图1中的方法可能被DL模型视为有漏洞。但是如果没有任何细粒度的细节，开发人员将不知道从何处着手进行调查。这将使DL模型在VD方面的输出变得不够有建设性。此外，定位故障的技术[16]不能解决这个问题，因为它需要一个大而有效的测试套件。

关于检测方面，现有的基于深度学习的方法 [20, 37] 在训练过程中没有充分利用关于易受攻击代码的所有可用信息。例如，在训练过程中，我们知道第23行和第27行存在漏洞/错误，其他通过数据/控制依赖关系相关的语句为易受攻击语句提供了上下文信息。然而，现有的方法 [20，37] 没有考虑易受攻击语句，也没有使用上下文代码来帮助模型区分易受攻击和非易受攻击语句。整个方法将会被输入给深度学习模型。

### 2.2 方法概述和关键思想

我们推出了IVDetect，这是一种基于深度学习的可解释性漏洞检测方法，它不仅能提供有关漏洞决策的细粒度解释，还能提供与检测到的漏洞相关的程序依赖图（PDG）中的重要语句列表。具体而言，当IVDetect将某个方法视为存在漏洞时，它将提供与检测到的漏洞相关的PDG的重要语句列表。例如，它可以在图2中提供包括第13至15行、22至23行以及2527行的部分PDG子图，用于表示第23行和第27行的漏洞代码。我们使用包含重要语句的PDG子图进行细粒度的漏洞检测，因为它们可以为开发人员提供有关漏洞相关程序依赖性的线索，供进一步调查使用。此外，如果我们的模型确定代码是非漏洞的，它也可以生成PDG的关键子图，其中包含被认为是安全的关键语句。

IVDetect有两个主要模块（见图3）：基于图的漏洞检测模型和基于图的解释模型。输入是项目中所有方法的源代码。输出是带有检测结果/得分和解释（PDG子图）的方法排名列表。让我们解释一下我们的关键思想。

![image-20240412143838393](https://s2.loli.net/2024/04/12/k9ASepjUQFamHTq.png)

#### 2.2.1 基于图的漏洞检测模型（第3节）。

如第2.1节所述，漏洞通常表现为多个被利用的语句，因此，将漏洞代码作为带有数据和控制流的PDG子图来捕获是自然而然的。这也有助于开发人员通过这些流程进一步调查检测到的漏洞。为实现这一目标，我们使用图卷积网络（GCN）[17]来建模漏洞检测。方法𝑀的PDG  $ 𝐺_𝑁 = (𝑉 , 𝐸)$表示为一个图，其中𝑉是表示语句的节点集合，𝐸是表示数据/控制依赖关系的边集合。对于每个节点𝑣，都有一个特征描述$𝑥_𝑉$，表示节点的属性，例如变量名等。这些特征被总结在一个$𝑁 × 𝐷$的特征矩阵$𝑋_𝑀$中（𝑁：节点数目，𝐷：输入特征数目）。让𝑓成为对语句和方法进行标记的标签函数$𝑓 : 𝑉 → \{1, ..., 𝐶\}$，将节点𝑉和整个方法映射到𝐶个类别中的一个。在IVDetect中，𝐶=2表示漏洞（Vulnerable）和非漏洞（Non-Vulnerable）。

在训练集上对（非）漏洞代码进行训练时，GCN执行与CNN类似的操作，它使用一个小的滤波器/窗口在PDG的子结构上学习特征。与CNN处理图像数据不同的是，GCN中节点的邻居是无序且大小可变的。为了预测方法𝑀是否存在漏洞，我们建立了带有相关特征集合$𝑋_𝑀 = \{𝑥_𝑗 |𝑣_𝑗 ∈ 𝐺_𝑀\}$的PDG $𝐺_𝑀$。GCN学习了一个条件分布$𝑃 (𝑌 |𝐺_𝑀, 𝑋_𝑀)$，其中𝑌是表示标签{1, ..., 𝐶}的随机变量。该分布表示了图𝐺𝑀属于每个类别{1, ..., 𝐶}的概率，即𝑀是否存在漏洞（第3节）。

#### 2.2.2 脆弱语句与上下文的区分。

在训练过程中，对于训练数据集中方法中的每个脆弱语句𝑠，我们区分𝑠和𝑠的上下文语句。上下文由与𝑠具有数据和/或控制依赖关系的语句组成。这有助于我们的模型更好地识别出特定上下文中出现的脆弱代码，并更好地区分脆弱代码和良性代码。例如，现有的方法将图2中的整个程序依赖图输入模型。IVDetect在考虑与第27行具有数据/控制依赖关系的语句（数据依赖上下文：第31、22、13、10、6行；控制依赖上下文：第29、25、23、13行）的情况下，区分并学习第27行的脆弱语句的向量表示。

#### 2.2.3 漏洞检测的基于图的解释模型（第4章）。

在预测之后，IVDetect进行精细解释。它使用方法𝑀的程序依赖图𝐺𝑀和GCN模型作为输入来获取解释。为此，我们利用可解释的机器学习技术GNNExplainer [36]。它的目标是使用GCN和特定的输入图𝐺𝑀，产生影响模型决策的关键子图结构和特征。GNNExplainer的思想是，如果移除或修改一个节点/特征会影响预测结果，那么该节点/特征被认为是关键的，因此必须包含在关键集合中（让我们称之为解释集）。GNNExplainer在𝐺𝑀中寻找一个子图G𝑀，使得使用整个图𝐺𝑀和使用最小图G𝑀之间的预测分数差异最小。因为如果在输入的程序依赖图𝐺𝑀中没有包含这个子图G𝑀，GCN模型不会将𝐺𝑀视为脆弱，所以G𝑀被认为是包含关键语句和与检测到的脆弱性相关的数据/控制依赖关系的关键程序依赖图子图（如果结果是脆弱性）。如果结果是非脆弱性，G𝑀可以被视为模型决定输入方法𝑀为良性代码的安全语句。



## 3 基于图的漏洞检测模型

本节描述我们基于图的漏洞检测模型。我们首先解释如何为易受攻击的代码构建上下文感知表示学习，然后如何使用这些学习向量使用 FA-GCN [30] 进行漏洞检测。

### 3.1 上下文感知的表示学习

让我们来介绍一下我们如何为代码特征构建向量表示。对于一个语句，我们提取以下类型的特征：

#### 3.1.1 语句的子标记序列。

在词法级别上，我们按照子标记的序列捕获语句的内容。我们选择子标记粒度，因为与整个词法标记相比，子标记更有可能重复出现在源代码中[24]。我们对每个语句进行标记化，只保留变量、方法和类名。名称使用驼峰命名法或匈牙利命名法进行细分成子标记。我们移除只有一个字符的子标记，以避免噪音的影响。例如，在图4中，收集了𝑆27的标记，并将其拆分成序列：copy、to、user、arg等。然后，我们使用GloVe[26]为标记构建向量，并结合门控循环单元(GRU)[12]为𝑆27的子标记序列构建特征向量。GloVe被认为能很好地捕捉到标记之间的语义相似性。选择GRU将向量序列汇总为一个特征向量，为下一步做准备。



模型目标：进行词的向量化表示，使得向量之间尽可能多地蕴含语义和语法的信息。

输入：语料库

输出：词向量

方法的主要概述：首先基于语料库构建词的共现矩阵，然后基于共现矩阵（不明白的小伙伴可以看上一篇文章）和GloVe模型学习词向量。 开始 -> 统计共现矩阵 -> 训练词向量 -> 结束



全局向量的词嵌入（Global Vectors for Word Representation），通常简称为[GloVe](https://so.csdn.net/so/search?q=GloVe&spm=1001.2101.3001.7020)，是一种用于将词语映射到连续向量空间的词嵌入方法。它旨在捕捉词语之间的语义关系和语法关系，以便在自然语言处理任务中能够更好地表示词语的语义信息。

word2vector中的skip-gram模型是利用类似于自动编码的器网络以中心词的one-hot表示作为输入来预测这个中心词环境中某一个词的one-hot表示，即先将中心词one-hot表示编码然后解码成环境中某个词的one-hot表示(多分类模型，损失函数用交叉熵)。CBOW是反过来的，分别用环境中的每一个词去预测中心词。尽管word2vector在学习词与词间的关系上有了大进步，但是它有很明显的缺点：只能利用一定窗长的上下文环境，即利用局部信息，没法利用整个语料库的全局信息。鉴于此，斯坦福的GloVe诞生了，它的全称是global vector，很明显它是要改进word2vector，成功利用语料库的全局信息。





#### 3.1.2 语句的代码结构。

我们通过AST子树来捕获代码结构。在图4中，提取了𝑆27的AST子树，并将其输入到Tree-LSTM[32]中，以将结构转化为向量𝐹2。

Tree-LSTM是一种循环神经网络（RNN）的变体，特别适用于处理树形结构的数据，如自然语言中的句法树或程序中的抽象语法树。它是由斯坦福大学的Socher等人在2015年提出的。

传统的循环神经网络（RNN）在处理序列数据时表现出色，但在处理树形数据时效果较差，因为树形结构的输入不适合RNN的序列模型。Tree-LSTM通过在树的节点之间建立连接来解决这个问题，从而能够有效地捕获树形数据的结构信息。

在Tree-LSTM中，每个节点都有一个隐藏状态，它由该节点的输入和来自其子节点的隐藏状态计算而来。这样，隐藏状态可以传递到树的更深层次，从而保留了树形结构的信息。通过使用这种结构，Tree-LSTM可以在自然语言处理中进行句法分析、语义分析等任务，也可以在程序分析中进行代码理解和程序生成等任务。

Tree-LSTM的输出通常取决于具体的任务。在自然语言处理中，例如句法分析或情感分类任务中，Tree-LSTM通常会生成每个节点或树的某种表示，然后将这些表示传递到网络的顶部，最终输出一个向量表示整个句子或树的语义信息。这个向量可以被用来进行分类、聚类等任务。

在程序分析中，Tree-LSTM可能会被用来生成代码的表示，从而可以用于代码理解、代码补全或程序生成等任务。在这种情况下，Tree-LSTM的输出可能是代码片段的向量表示或具体的语法结构信息，以便后续的处理步骤使用。

总之，Tree-LSTM的输出可以是节点、树或整个结构的向量表示，具体取决于所解决的任务和网络的架构。

![image-20240412100504285](https://s2.loli.net/2024/04/12/XuLYnfN5p2raqws.png)

#### 3.1.3 变量和类型。

对于每个节点(即语句)，我们收集变量的名称及其静态类型，并将它们在相应的位置上细分成子标记。例如，我们收集变量s_cmd及其静态类型cross_ec_command。对于变量名称(如s_cmd)和变量类型(如cross_ec_command)构建的子标记序列，我们使用与特征1中相同的向量构建技术，包括GloVe和GRU。





门控循环单元（Gated Recurrent Unit，GRU）是一种循环神经网络（RNN）的变体，旨在解决长期依赖问题。它由德国人工智能研究所（German Research Center for Artificial Intelligence，DFKI）的Cho等人于2014年提出。

与标准的RNN相比，GRU引入了两个重要的门控机制：重置门（reset gate）和更新门（update gate）。这些门控机制允许GRU网络更有效地捕获和记忆序列中的长期依赖关系。

重置门决定了在当前时间步中，网络是否应该忽略先前的隐藏状态，从而允许网络根据当前输入来“重置”自己。更新门决定了在当前时间步中，网络应该如何将新的输入与先前的隐藏状态结合起来，以产生新的隐藏状态。这些门控机制使得GRU网络能够更好地处理长期依赖，避免梯度消失或梯度爆炸问题，因此在很多序列建模任务中表现出色。

总的来说，GRU是一种能够更有效地捕获序列信息的循环神经网络结构，适用于各种序列建模任务，如自然语言处理、时间序列预测等。



#### 3.1.4 周围的上下文。

在训练过程中，对于一个语句𝑠，我们还对其周围的语句进行编码，即上下文。我们有两种上下文。数据依赖和控制依赖的上下文包含与当前语句具有这些依赖关系的语句。例如，𝑆27的数据依赖上下文包括行31、22、13、10和6的语句。如果考虑控制依赖关系，则包括与𝑆27在行29、25、23和13处具有控制依赖关系的语句。上下文中语句的向量通过前面介绍的GloVe和GRU进行计算。由于依赖关系的数量可能不同，GRU模型输入的长度可能不同。因此，我们在零填充的基础上应用掩码层，允许模型跳过子标记序列末尾的零。这些零将不会被包括在训练中。

#### 3.1.5 基于注意力的双向GRU。

在获得所有特征𝐹1，𝐹2，...的向量之后，我们使用双向GRU和注意力层来学习每个特征𝐹𝑖的权重向量𝑊𝑖，基于该模型的隐藏状态。然后，我们通过将特征的原始向量与权重相乘来计算每个特征的加权向量，即我们有$F_{i}^{\prime}=W_{i}.F_{i}.$



最后，我们需要考虑依赖语句对当前语句在PDG中的影响。原因是如果其中一个邻近语句存在漏洞，则PDG中的这些邻近语句必然会对当前语句产生影响。例如，在PDG中，𝑆27的邻近语句包括第6行、第22行、第25行和第29行的语句。因此，我们将它们合并并总结为语句𝑆27的最终特征向量𝐹𝑆27，如下所示：
$$
F_{S27}=\sum_{i}W_{i}C o n c a t(h(F_{i}^{\prime},j))\qquad\qquad\qquad\qquad
$$
𝑊𝑖是用于组合的可训练权重；𝐶𝑜𝑛𝑐𝑎𝑡是用于将所有值连接成一个向量的连接层；ℎ是用于将向量汇总为一个值的隐藏层；𝑖 = S6, S22, S25, S27, S29；𝑗是特征索引。𝐹27在下一步中与GCN模型一起用于检测。

双向GRU结构是**一种循环神经网络的变体，具有前向和后向两个方向的信息传递**。 它能够在处理文本时同时考虑上下文的前后关系，更好地捕捉到文本中的语义和信息。 相比于传统的单向循环神经网络，双向GRU结构能够更全面地理解文本数据，提高模型的表达能力和性能。

### 3.2 使用FA-GCN进行漏洞检测

![image-20240417163533497](C:\Users\hao\AppData\Roaming\Typora\typora-user-images\image-20240417163533497.png) 图5展示了我们如何使用Feature-Attention GCN模型（FAGCN）[30]进行检测。其原理是，FA-GCN可以很好地处理具有稀疏特征（不是所有语句共享相同属性）和潜在噪声特征的程序依赖图（PDG）。首先，我们将方法𝑀解析成PDG。类似于CNN在图像上使用过滤器，FA-GCN在PDG的所有节点（语句）上执行滑动窗口操作。例如，在图5中，以节点𝑆27为中心的窗口标记为A，包括它自己和相邻的语句/节点𝑆6，𝑆22，𝑆25和𝑆29。另一个窗口（标记为B)是针对节点𝑆23的，包括它自己和相邻节点𝑆22和𝑆25。对于每个窗口，FA-GCN生成位于中心的语句的特征表示矩阵。例如，对于以𝑆27为中心的窗口，它使用图4中解释的过程生成语句𝑆27的特征向量𝐹𝑆27。从所有语句的表示向量中，FA-GCN使用一个连接层将所有这些向量链接成方法𝑀的特征矩阵F𝑚。F𝑚中的一行对应于PDG中的一个窗口。

Feature-Attention Graph Convolutional Network（特征注意力图卷积网络，Feature-Attention GCN）是一种用于图数据的深度学习模型，它结合了图卷积网络（GCN）和注意力机制。这种模型的设计旨在利用图结构中节点之间的关系，并且能够自适应地关注重要的节点特征。

在Feature-Attention GCN模型中，每个节点都有一个特征向量表示，这通常是节点的属性或特征。模型的目标是通过学习节点之间的关系来改进这些特征表示，从而使得节点特征更适合于特定的任务，比如节点分类或图表征学习。



关键组成部分包括：

1. 图卷积层（Graph Convolutional Layer）：用于在图结构上聚合节点的邻居信息，并更新节点的特征表示。这些层允许模型在考虑节点的局部邻域结构的同时进行信息传播和特征提取。
2. 注意力机制（Attention Mechanism）：用于在图结构中动态地计算节点之间的关系权重，以便对不同节点的特征进行不同程度的关注。这使得模型能够自适应地聚焦于图中最相关的节点，从而提高了模型的表征能力。
3. 特征注意力层（Feature-Attention Layer）：结合了图卷积层和注意力机制，用于在节点特征的聚合过程中引入注意力权重，以增强对重要节点特征的关注。

通过结合图卷积和注意力机制，Feature-Attention GCN模型能够更好地捕捉图结构中的关系，并且能够自适应地关注节点特征，从而提高了在图数据上的任务性能，比如节点分类、图表征学习等。



接下来，FA-GCN通过首先计算对称归一化拉普拉斯矩阵  ̃ 𝐴[17]，然后进行卷积操作生成方法𝑚的表示矩阵𝑀𝑚。之后，我们使用CNN模型中的传统步骤：使用空间金字塔池化层（将方法表示矩阵规范化为统一大小并减小其总大小），将其输出连接到全连接层，将矩阵转换为向量𝑉𝑚来表示𝑚。使用𝑉𝑚，我们通过使用两个隐藏层（控制向量的长度和输出)和softmax函数执行分类，为𝑚生成预测分数。我们使用这些分数作为漏洞得分对项目中的方法进行排序。根据预测分数[18, 20]，通过可训练的阈值来决定𝑚是V还是NV。

基于图的解释模型

让我们解释一下我们如何使用GNNExplainer [36] 构建我们的基于图的解释。输入包括经过训练的FA-GCN模型，方法𝑀的PDG(𝐺𝑀)，检测结果V或NV，以及预测得分。图6展示了我们针对V（易受攻击）的情况的处理过程（NV的情况类似处理）。

为了得出解释，关键目标是在方法𝑀的PDG𝐺𝑀中找到一个子图G𝑀，使得在使用整个图𝐺𝑀和使用最小图G𝑀进行预测时预测得分的差异最小化。为此，我们使用GNNExplainer与掩蔽技术[36]，将寻找最小图G𝑀的过程看作是学习边缘掩蔽集合𝐸𝑀的问题。其思想是，通过学习𝐸𝑀，IVDetect可以通过从𝐺𝑀中掩蔽𝐸𝑀中的边缘来得出解释子图G𝑀（通过“掩蔽”表示为Ç）。

图6展示了GNNExplainer的原理。当应用边缘掩蔽集合时，GNNExplainer会检查FA-GCN模型是否产生相同的结果（在这种情况下结果是V）。如果是，边缘掩蔽中的边缘不重要，不包括在G𝑀中。否则，边缘是重要的，包括在G𝑀中。由于可能的子图和边缘掩蔽集合的数量无法计算，GNNExplainer使用了边缘掩蔽𝐸𝑀的学习方法。

![image-20240412101047371](https://s2.loli.net/2024/04/12/pJjeOu65zWPY4aG.png)

让我们正式解释一下GNNEXplainer [36]的工作原理。它通过最大化最小图G𝑀和输入PDG𝐺𝑀之间的互信息（MI）来形式化问题：

![image-20240412101121587](https://s2.loli.net/2024/04/12/EU4ViDJ7hdbMneW.png)

𝑌是由FA-GCN模型决定的结果。因此，对于训练好的FA-GCN模型来说，熵项𝐻(𝑌)是恒定的。对所有的G𝑀最大化𝑀𝐼值等效于最小化条件熵𝐻(𝑌 |𝐺 = G𝑀)，根据条件熵的定义，可以表示为

![image-20240412101145889](https://s2.loli.net/2024/04/12/raZMIbxS21iNnsR.png)

当我们知道𝐺 = G𝑀时，该条件熵公式的含义是衡量关于结果𝑌还存在多少不确定性。GNNExplainer通过𝐾𝑀来限制G𝑀的大小，即选择与预测结果𝑌具有最高互信息的𝐾𝑀个边。直接优化公式4是不可行的，因此，GNNExplainer将G𝑀视为一个随机图变量G。方程4中的目标变为：

![image-20240412101225194](https://s2.loli.net/2024/04/12/GTgNYrj8zaFHpus.png)

从第5个方程中，通过使用Jensen不等式，我们得到了第6个方程。第6个方程中的条件熵可以通过用输入图𝐺𝑀上的𝐸𝑀进行掩蔽来优化EG [G𝑀 ]的替换来实现。现在，我们可以将问题简化为学习掩蔽𝐸𝑀。有关训练的详细信息可以在[36]中找到。产生的子图G𝑀直接用作解释。对于不易受攻击的情况，我们可以类似地生成解释。

5 经验评估 

5.1 研究问题 

为了评估 IVDetect，我们试图回答以下问题：

 RQ1. 方法级漏洞检测（VD）的比较。与最先进的方法级深度学习VD方法相比，IVDetect的性能如何？ 

RQ2. 用于细粒度VD解释的其他解释模型的比较。与最先进的细粒度VD解释模型相比，IVDetect的性能如何，能否指出易受攻击的语句？ 

RQ3. 易受攻击代码模式和修复模式。IVDetect在检测易受攻击的代码模式和修复模式方面是否有用？

 RQ4. 对内部特征的敏感性分析。内部特征如何影响IVDetect的整体性能？ 

RQ5. 对训练数据的敏感性分析。不同的数据分割方案如何影响IVDetect的性能？

 RQ6. 时间复杂度。IVDetect的时间复杂度是多少？

5.2 数据集
为了对IVDetect进行实证评估，我们对三个公开的漏洞数据集进行了多次实验，其中包括Fan等人的[13]、Reveal [11]和FFMPeg+Qemu [37]（表1）。Fan等人[13]的数据集涵盖了2002年至2019年期间的CWE（Common Weakness Enumeration）漏洞，每个漏洞有21个特征。在方法层面上，数据集包含超过10,000个有漏洞的方法和修复后的代码。Reveal数据集[11]包含超过18,000个方法，其中有9.16%是有漏洞的。FFMPeg+Qemu数据集在Devign研究[37]中使用，包含超过22,000个方法，其中45.0%的条目存在漏洞。

5.3 实验方法

 RQ1. 基于方法级深度学习的漏洞检测方法比较。基准模型。我们将IVDetect与最先进的基于深度学习的漏洞检测方法进行比较：

1) VulDeePecker [20]：基于双向LSTM对语句及其数据/控制依赖关系进行处理的深度学习方法。
2) Devign [37]：使用具有门控图递归层的GGCN模型对抽象语法树（AST）、控制流图（CFG）、数据流图（DFG）和代码序列进行图分类的深度学习方法。
3) SySeVR [19]：除了语句和程序依赖关系外，该方法还使用程序切片，并利用多个深度学习模型（LR、MLP、DBN、CNN、LSTM等）。
4)  Russell等 [28]：该深度学习方法将源代码编码为代码令牌矩阵，并通过集成分类器中的卷积模型（RFC）进行处理。
5) Reveal [11]：该方法使用GGNN、MLP以及在源代码的图表示中使用Triplet Loss进行处理。

步骤。数据集包含多个有漏洞和无漏洞的方法。我们将其中所有有漏洞的方法随机分为80%、10%和10%用于训练、调整和测试。为了训练，我们在80%的部分中添加与有漏洞方法数量相同的无漏洞方法，以得到平衡的训练数据。对于调整和测试，我们还添加了无漏洞方法，但是使用了原始数据集中有漏洞和无漏洞方法之间的真实比例来构建调整/测试数据。我们使用AutoML [21]在所有模型上自动调整调整数据集上的超参数。我们还在数据集之间进行了评估。我们首先在Reveal和FFMPeg+Qemu两个数据集的组合上训练了我们的模型，这个组合有相同数量的有漏洞和无漏洞方法。然后我们在Fan数据集上测试了该模型，该数据集中有漏洞和无漏洞方法的比例更加接近实际情况。为了确保模型适用于跨数据集的评估，我们还使用Fan数据集的20%来调整参数，并在剩下的80%上进行预测。评估指标。我们使用以下评估指标。

平均准确率𝑀𝐴𝑃 = 对于𝑞从1到𝑄的𝐴𝑣𝑔𝑃 (𝑞)的求和除以𝑄，其中平均准确率𝐴𝑣𝑔𝑃 = 对于𝑘从1到𝑛的𝑃 (𝑘)𝑟𝑒𝑙 (𝑘)的求和，其中𝑛是结果的总数，𝑘是列表中的当前排名，𝑟𝑒𝑙 (𝑘)是一个指示函数，当排名为𝑘的项目实际上是脆弱的时候等于1，否则为零。𝑄是分类类型的总数。这是因为我们只有两种类型，即脆弱和非脆弱类别，但是我们根据它们的分数对所有方法进行排名（1表示脆弱，否则为0）。在排名为𝑘时的标准化折现累积增益：𝑛𝐷𝐶𝐺𝑘 = 𝐷𝐶𝐺𝑘 𝐼𝐷𝐶𝐺𝑘，其中𝐷𝐶𝐺𝑘是在排名𝑘处的折现累积增益的求和，𝐼𝐷𝐶𝐺𝑘是在排名𝑘处的理想折现累积增益的求和，其中𝑟𝑖是位置𝑖上结果的分数，而𝑅𝑘是实际脆弱方法（按照它们的分数排序）在结果列表中到位置𝑘的排名。
第一个正确预测的脆弱方法的排名（𝐹𝑅）是排名列表中第一个的。平均排名（𝐴𝑅）是在排名列表中正确预测的脆弱方法的排名的平均值。曲线下面积准确率（AUC）被定义为𝐴𝑈𝐶 = 𝑃 (𝑑 (𝑚1) > 𝑑 (𝑚2))，其中𝑃是概率，𝑑是检测模型（可以看作是一个二元分类器），𝑚1是随机选择的正实例，𝑚2是随机选择的负实例。精确率（P）是检索到的相关实例在所有检索到的实例中的比例。它的计算公式是𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 = 𝑇 𝑃 / (𝑇 𝑃+𝐹𝑃)，其中𝑇 𝑃是真正例的数量，𝐹𝑃是假正例的数量。召回率（R）是被检索到的相关实例在所有相关实例中的比例。它的计算公式是𝑅𝑒𝑐𝑎𝑙𝑙 = 𝑇 𝑃 / (𝑇 𝑃+𝐹 𝑁)，其中𝑇 𝑃是真正例的数量，𝐹 𝑁是假反例的数量。F值（F）是精确率和召回率的调和平均值。它的计算公式是𝐹𝑠𝑐𝑜𝑟𝑒 = 2 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛∗𝑅𝑒𝑐𝑎𝑙𝑙 / (𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛+𝑅𝑒𝑐𝑎𝑙𝑙)。

RQ2. 对于细粒度解释，与其他解释模型进行比较。基准。我们将IVDetect与以下解释模型进行比较：1）ATT[36]：该模型是一个图注意力网络，使用注意力机制评估输入图中边的权重（重要程度）；2）GRAD[36]：该方法使用基于梯度的方法计算GNN的损失函数对邻接矩阵的梯度。过程。我们的目标是评估IVDetect在指向易受攻击语句的细粒度解释方面的效果。因此，为了训练/测试解释模型，我们需要使用Fan数据集，因为它包含易受攻击语句及其修复。其他两个数据集仅包含方法级别的漏洞，没有修复。因此，在这个RQ2中，对于漏洞预测部分，我们使用在Reveal和FFMPeg+Qemu上训练并在Fan数据集上预测的FA-GCN模型。对于被预测为非易受攻击的但实际上是易受攻击的方法，我们将这些情况视为错误，因为由此产生的解释对于错误的检测是不合理的。对于实际上是非易受攻击的方法（无论预测结果是易受攻击还是非易受攻击），我们无法使用它们，因为非易受攻击的方法没有修复语句作为正确解释的标准。因此，我们使用被正确检测为易受攻击的易受攻击方法集合进行解释模型的评估。让我们用𝐷来表示这个集合。对于解释，我们将𝐷随机划分为80％的训练集，10％的调参集和10％的测试集。对于训练，我们使用修复语句作为解释的标签，因为这些修复语句是易受攻击的。对于测试，我们将解释模型生成的相关语句与实际修复语句进行对比。在这个RQ2中，测试集中的每个方法和训练的FA-GCN模型都是解释模型的输入。评估指标。给定由基于图的解释模型生成的解释子图G𝑀，我们按照以下方法评估模型的解释准确性。对于一个方法，如果G𝑀与修复漏洞的代码更改中的任何语句存在重叠，那么G𝑀被认为是正确的解释，即与检测到的漏洞相关。然后，我们计算准确率，即正确解释的数量与总解释数量的比率。由于代码更改可能包括添加、删除和修改，我们进一步定义了以下重叠条件。如果易受攻击版本中的某个语句𝑆被删除或修改以进行修复，且G𝑀 ∋ 𝑆，则认为解释子图G𝑀是正确的，否则为错误的。如果易受攻击版本中添加了语句𝑆′，我们会在修复版本中检查G𝑀是否包含与𝑆′具有数据或控制依赖关系的任何语句。如果是，我们认为它是正确的；否则，认为是错误的。在图2中，G𝑀包含具有与17-21行中添加的语句相关的语句S23。因此，G𝑀是正确的。其理由是，如果解释子图G𝑀包含与添加的修复语句相关的语句，那么该解释在指出与漏洞相关的代码方面是有用的。我们还使用Mean First Ranking (MFR)（即解释语句中第一条需要修复的语句的平均排名）和Mean Average Ranking (MAR)（即解释语句中所有需要修复的语句的平均排名）。如果一个需要修复的语句没有被选作解释，则在计算MFR/MAR时不予考虑。

RQ3. 弱点代码模式和修复模式。流程。我们使用一种挖掘算法在解释子图集合上挖掘弱点代码模式。我们还挖掘了这些弱点的修复模式。详见第6.3节。评估指标。我们统计了被识别出的模式数量。

RQ4. 特征的敏感性分析。流程。我们首先建立一个只包含代表代码的特征的基础模型，即代码令牌序列。接着，我们逐步添加其他特征来构建我们模型的其他变体，包括子标记序列、抽象语法树子树、变量名称、数据依赖和控制依赖等，详见第3.1节。我们为每个变体测量准确性。我们使用了Fan数据集以及和RQ1相同的实验设置。评估指标。我们使用和RQ1相同的评估指标。

RQ5. 训练数据的敏感性分析。我们在数据分割中使用不同的比例进行训练、调整和测试：(80%，10%，10%)、(70%，15%，15%)、(60%，20%，20%)和(50%，25%，25%)。我们使用了Fan数据集以及和RQ1相同的设置。评估指标。我们使用和RQ1相同的评估指标。

RQ6. 时间复杂度分析。我们测量了实际的训练和预测时间。

## 6 实验结果 

### 6.1 RQ1. 方法级别的漏洞检测比较 

在表2中，排名前10位的预测结果中，IVDetect有最多的正确预测（6个有漏洞的方法）。IVDetect正确检测到的有漏洞方法也在前10名中排得更高，其中有4个正确结果出现在前5名之内。其他基线方法在前5名中仅有0-1个正确检测结果。重要的是，IVDetect的第一名（即第一个正确检测到有漏洞的方法的排名）是第1名，而基线方法的排名则分别是第4名、第5名、第5名、第6名和第7名（表2中的粗体数值）。

此外，IVDetect在前20、前50和前100个预测结果中分别能检测到14个、35个和64个漏洞。表3、表4和表5显示了三个数据集上方法的比较结果。IVDetect在所有指标上表现更好（表3）。对于nDCG@{1,3}，所有基线方法都得到了零分，因为它们在前3个结果中没有正确检测到漏洞。与基线方法相比，IVDetect可以将nDCG@10从43%-84%提高，将nDCG@20从37%-71%提高。较高的nDCG表明IVDetect的排名更接近完美排名，并且正确的有漏洞方法出现在榜单的更高位置。对于MAP分数，IVDetect在前10个和前20个准确性上相对于基线方法的改进范围为105%-255%和53%-116%。较高的MAP表示IVDetect在榜单的所有前排位置上平均具有更高的精度。也就是说，在检测有漏洞的方法时，排名第一的结果具有较高的准确度。IVDetect还在第一名排名（FR）和平均排名（AR）上取得更好的成绩。其中，它的最佳FR评分是1，而下一个最好的表现者的评分是4。

对于AR@10，IVDetect在排名榜单中将一个正确的有漏洞方法的平均排名比基线方法高出2.7-4.0个位置。我们的工具在AUC上也相对较高，提高了6%-24%。对于Fan和Reveal数据集的比较结果是相似的（表4和表5）。在Fan数据集中，相较于基线方法，IVDetect可以将nDCG和MAP得分分别提高26%-43%和50%-170%，对于前10位和前20位，分别提高21%-475%和40%-250%。IVDetect的FR和AR在前10位和前20位上分别比基线方法好2-6个位置和0.7-2.7个位置，在前20位上则分别比基线方法好2-13个位置和1.6-9.1个位置。

在Reveal数据集中，nDCG、MAP、FR和AR的改进范围分别为33%-73%、42%-209%、2-7个位置和0-4个位置，对于前10位和前20位，则分别为19%-111%、28%-236%、2-12个位置和1.2-6.2个位置。由于易受攻击方法与非易受攻击方法之间的比例不同，三个数据集上的结果也不同。Fan和Reveal数据集中的比例为1:16和1:9.9，FFMPeg+Qemu数据集中的比例为1:1.2，因此易受攻击方法更多，并且在所有模型上的结果都持续更高。表6显示了IVDetect和基线方法的精确度和召回率结果。具体而言，在三个数据集上，IVDetect的精确度比所有基线方法都要高。它可以将精确度提高2.6%-105%。

对于召回率，它在Fan和FFMPeg+Qemu数据集上略差于Reveal（分别为1.4%和2.7%），在Fan数据集上略差于SySeVR（2.7%）。在Reveal数据集上，IVDetect在精确度方面比Reveal高出25.8%，但召回率低10.3%。然而，在F-score方面，IVDetect在FFMPeg+Qemu数据集上比最佳基线方法Reveal高出4.8%，在Fan数据集上高出16.7%，在Reveal数据集上高出12.5%。

图7显示，考虑从排名第一到排名第100的列表时，IVDetect始终具有更好的MAP和nDCG得分。从图8中可以看出，在跨数据集验证中，内部数据集设置下的MAP和nDCG结果比跨数据集设置下的结果要好。这是符合预期的，因为模型在同一数据集中的同一项目中可能已经看到过类似的易受攻击代码。跨数据集设置下的FR和AR值比内部数据集设置下的值高一个等级。图9显示了IVDetect和Fan数据集的基准线之间在前100个结果上的重叠分析。如图所示，IVDetect可以分别检测出17个、13个、13个、11个和10个VulDeePecker、SySeVR、Russell、Devign和Reveal所错过的易受攻击方法，而它们只能检测出2个、3个、4个、5个和5个IVDetect所错过的易受攻击方法。总的来说，IVDetect可以比基准线多检测出15个、10个、9个、6个和5个易受攻击方法。

### 6.2 RQ2. 对细粒度漏洞解释模型的比较

表7展示了不同解释模型的准确性。可以看到，使用GNNExplainer在准确性上相较于ATT和GRAD有所提升，分别提高了12.3%至400%和9.0%至400%。当我们改变解释子图的大小（即语句数量）从1到10时，这种提升效果得以体现。更高的准确度表明IVDetect能够在语句层面提供更好的细粒度漏洞检测解释。也就是说，在更多情况下，如果IVDetect能够正确检测出有漏洞的方法，它可以更精确地指出与漏洞相关的漏洞语句。在对有漏洞语句进行排序方面，使用GNNExplainer相较于ATT和GRAD分别提高了0.7和1.3个排名，并且相较于ATT和GRAD分别改善了0.6和1.3个排名的正确率。ATT使用图注意力网络中的边注意力为边赋予权重，而GNNExplainer直接在掩码后为子图给出得分。因此，在存在从一个节点到另一个节点有多条路径的情况下，边的权重是通过多条路径的权重平均值计算出来的，也就是说，ATT可能比GNNExplainer精确度较低。GRAD通过计算损失函数相对于输入的梯度来计算边的权重。然而，这种基于梯度的方法对于离散输入（输入图以邻接矩阵的形式表示）可能效果不佳。随着G𝑀中节点的数量增加，所覆盖的语句数量也会增加，准确度会更高。然而，计算时间和开发人员需要调查更多的语句也会增加。可以看到，当语句数量超过5时，准确度增加的速度较慢。因此，我们选择了5作为默认值。

### 6.3 RQ3. 漏洞代码模式分析

 此部分描述了另一个实验，我们利用IVDetect提供的解释子图挖掘漏洞代码和修复模式的能力。漏洞代码模式是指重复出现频率较高的漏洞代码片段，即超过一定阈值的片段。检测到的漏洞模式和相应的修复模式对开发人员来说是很好的资源，可以了解其他开发人员经常出现的漏洞代码，并学习如何修复相同模式的漏洞代码。根据RQ2中的结果，我们首先将与方法中漏洞相关的正确检测语句作为相关语句收集到一个集合G中。总共，我们获得了700多个G𝑀子图。需要注意的是，G𝑀是PDG的子图。对于每个G𝑀，我们使用关键字VAR来抽象出变量名称，使用数据类型来抽象出字面值。然后，我们对G使用不同频率阈值进行子图模式挖掘算法[25]，并收集不同大小的子图模式。输出结果是G𝑀中的频繁同构子图，它们被认为是漏洞代码模式，因为我们选择了包含与正确检测到的漏洞相关的正确解释语句的G𝑀。经过手动验证，我们得到了一些正确的模式（表8）。如表所示，随着频率阈值或模式大小的增加，模式数量如预期般减少。当它们都大于5时，我们找不到模式。让我们解释几个例子。图10显示了两个漏洞代码模式的示例。第一个模式（第2、4和6行）展示了项目firejail中涉及is_link(...), exit和copy_file(...)的API误用。使用方法是检查链接的有效性，如果有效则复制文件，否则停止执行。该模式出现了三次，每次使用不同的字符串字面值，开发人员进行了修复以替换这些语句。有趣的观察是，IVDetect能够从解释子图中消除位于第2行的fprintf语句，从而将其从模式中排除，尽管在项目中，fprintf语句和其他语句一起出现了三次。这显示了IVDetect的好处，因为如果一个工具没有语句级别的漏洞解释，并且从整个方法中挖掘模式，它会错误地将fprintf包含在模式中。第二个模式（第8-9行）展示了涉及一个脆弱方法调用udf_get_filename和对其返回值的检查的模式。该方法后来进行了修复，添加了第5个参数。另一个有趣的发现是，IVDetect不仅能够发现漏洞代码模式，还能够发现修复模式。图11显示了漏洞代码的两种修复模式。第一个漏洞（来自Linux内核），第2-5行，涉及方法f16_update_dst(...)。根据提交日志，为了避免另一个线程同时更改数据记录，开发人员需要提供互斥访问和延迟引用。这种修复模式在方法dccp_v6_send_response，inet6_csk_route_req和net6_csk_route_socket中重复出现了3次。对于开发人员来说，这种修复模式对于从一个方法学习修复并应用到其他两个方法是有用的。第二个模式（第7-13行）展示了一个涉及WavPack 5.0的ParseDsdiffHeaderConfig方法中malloc调用引发缓冲区溢出的修复模式。根据CVE-2018-7253，这个问题“允许远程攻击者通过恶意构造的DSDIFF文件造成拒绝服务（堆上的缓冲区超读）或可能重写堆”。这个修复模式在同一个项目中出现了三次。

### 6.4 RQ4. 特征表的敏感性分析

在图4中展示了当我们逐步将每个内部特征添加到我们的模型中时，指标发生的变化。总的来说，每个内部特征都对IVDetect的性能改进做出了积极的贡献，因为得分指标（nDCG、MAP和AUC）以及排名指标（FR和AR）都得到了改善。当IVDetect仅考虑代码中的标记序列（ST）时，第一个正确检测（FR）出现在位置14，因此，nDCG@{1,5,10}=0 和 MAP@{1,5,10}=0（未显示）。当考虑代码作为子标记序列（SST）时，IVDetect更好地处理了唯一标记，因为子标记出现的频率比标记更高 [24]。在前20位，FR提高了2个位置，AR提高了4.5个位置，nDCG和MAP相对分别提高了3.8％和22.2％。当额外考虑AST时，模型可以区分易受攻击的代码结构和语句。在前20位，FR和AR分别提高了1和1.5个位置，nDCG和MAP相对分别提高了7.4％和18.1％。然而，FR仍然是11，nDCG@{1,5,10}=0和MAP@{1,5,10}=0（未显示），因为标记和AST并不能很好地区分易受攻击的语句。变量特征还有助于将FR和AR从11提高到7和从13.5提高到12.5，nDCG和MAP相对分别相对提高了27.6％和46.2％在前20位。nDCG@10和MAP@10分别从0提高到0.33和0.18（未显示）。该特征使模型能够检测出类似的不正确变量使用情况。通过额外整合控制依赖（CD），FR和AR从7下降到5和12.5下降到11.2，nDCG和MAP相对分别提高了18.9％和36.8％。通过添加数据依赖（DD），FR和AR从5提高到4和从11.2提高到10.4。nDCG和MAP在前20位上分别提高了4.5％和7.7％。这个结果证实了易受攻击的代码通常涉及具有控制和/或数据依赖关系的语句[11, 37]。图12显示了一个检测到的易受攻击的方法：validate_event(...)是易受攻击的，被一个附加参数的新版本替换。我们使用模型（A）-（F）进行检测，并观察到在候选列表中validate_event(...)的排名从140（A）提高到121（B），99（C），71（D），48（E）和19（F）。虽然标记、子标记和AST上的特征都有贡献，但并不是很有帮助，因为模型之前没有在易受攻击的方法中见过它们。然而，变量/方法名称，尤其是周围语句与validate_event(...)之间的控制/数据依赖关系有助于区分这种漏洞，并将其推到前20位列表。控制依赖（例如，validate_event(...)和return -EINVAL之间的依赖关系）有助于提高29个排名。总的来说，排名的改进显示了所有特征的积极贡献。这个示例也展示了一个修复模式，出现三次，但使用不同的变量leader、sibling和event。

### 6.5 RQ5. 关于训练数据的敏感性分析 

如表10所示，随着更多的训练数据，性能就会如预期般变得更好。即使使用了60%/20%/20%的数据分配比例，IVDetect仍然实现了0.43的nCDG和0.25的MAP，这些指标仍然优于其他基准模型在前20位上的指标（基准模型的最高nDCG和MAP分别是0.38和0.20）。当训练数据减少了20%（从80%减少到60%）时，IVDetect的AUC仅下降了5.5%。 

### 6.6 RQ6. 时间复杂度 

为了生成所有方法的解释子图，Fan、Reveal和FFMPeg+Qemu数据集分别需要大约9天、2天和3天的时间才能完成。在Fan、Reveal和FFMPeg+Qemu数据集上训练IVDetect分别需要23小时、7小时和10小时。对于VD预测，每种方法只需要1-2秒的时间。 

**威胁效度。**我们只在C和C++代码的漏洞上进行了测试。原则上，IVDetect可以应用于其他编程语言。我们尽力在相同数据集上调整基准模型以进行公平比较。我们只关注基于深度学习的VD模型。

## 7 相关工作 

已经开发出了多种技术用于检测漏洞。基于规则的方法被开发出来，利用已知的漏洞模式来发现可能存在漏洞的代码，如FlawFinder[7]、RATS[9]、ITS4[33]、Checkmarx[1]、Fortify[8]和Coverity[2]。通常，这些规则是由人类专家手动定义的。静态分析的最新漏洞检测工具为每种漏洞类型提供了相应的规则。另一种漏洞检测方法是基于机器学习（ML）或基于度量的方法。通常，这些方法需要人工提取或概括的度量作为特征来描述漏洞，并在所定义的特征上训练机器学习模型，以预测给定代码是否存在漏洞。已经基于不同的度量构建了各种基于机器学习的方法，例如术语及其出现频率[29]、导入项和函数调用[23]、复杂性、代码变更和开发者活动[31]、依赖关系[22]、API符号和子树[34, 35]。最近，深度学习（DL）已被应用于检测漏洞。例如，一些方法训练一个DL模型来检测漏洞，例如在一个合成代码库中函数的词法表示[14]，与API调用相关的代码片段来检测两种类型的漏洞[20]，基于语法、语义和向量表示[19]，以及基于图的表示[37]。这些方法中没有一个旨在提供模型对于易受攻击语句的解释。

## 8 结论

 我们提出了一种名为IVDetect的新型基于深度学习的方法，为PDG中的子图提供解释，解释基于图的漏洞检测的预测结果。我们对漏洞数据库进行了实证评估，结果显示IVDetect在top-10 nDCG和MAP排名分数上超过了现有基于深度学习的方法的64%至122%和105%至255%。我们的主要限制包括1) 无法预见的漏洞，2) 由于与易受攻击语句的数据或控制依赖关系而错误地标识出易受攻击语句，3) 由于多条数据或控制依赖关系而错过易受攻击语句。作为一种基于机器学习/深度学习的漏洞检测模型，我们的目标是提升机器学习/深度学习的方法，这些方法无法指出导致模型预测漏洞的具体语句。因此，我们将IVDetect与相同类别的检测方法进行了比较。将来，我们计划将IVDetect与静态分析的漏洞检测方法进行比较。