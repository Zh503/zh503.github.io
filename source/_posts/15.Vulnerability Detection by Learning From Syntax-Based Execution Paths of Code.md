---
title: EPVD
date: 2024-04-22 09:53:28
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

# Vulnerability Detection by Learning From Syntax-Based Execution Paths of Code

代码仓库:https://zenodo.org/records/7123322

## 摘要

漏洞检测对于保护软件系统至关重要。基于深度学习的各种方法已被提出来学习漏洞的模式并进行识别。尽管这些方法在任务中展示了巨大的潜力，但仍存在以下问题：

(1)它们很难将与漏洞相关的信息与大量无关的信息区分开来，这影响了它们捕捉漏洞特征的有效性。

(2)它们对于处理长代码的效果较差，因为许多神经模型会限制输入长度，这影响了它们表示长漏洞代码片段的能力。为了缓解这两个问题，在本研究中，我们提出**将代码片段的基于语法的控制流图（CFG）分解为多个执行路径来检测漏洞**。具体地，给定一个代码片段，我们**首先基于其抽象语法树（AST）构建其CFG**，**将这样的CFG称为基于语法的CFG**，**并将CFG分解为从入口节点到出口节点的多个路径**。接下来，我们**采用一个预训练的代码模型和一个卷积神经网络，利用路径内部和路径之间的注意力来学习路径的表示**。**将路径的特征向量结合在一起作为代码片段的表示**，并输入分类器来检测漏洞。**将代码片段分解为多个路径来过滤掉与漏洞无关的多余信息**，帮助模型专注于漏洞特征。此外，由于分解后的路径通常比代码片段更短，所**以长代码中位于末尾的信息更有可能被处理和学习**。



为了评估我们模型的有效性，我们构建了一个包含231,000个代码片段的数据集，其中包含24,000个漏洞。实验结果表明，所提出的方法在精确率、召回率和F1-Score方面至少比现有最先进的基准模型高出22.30%、42.92%和32.58%。我们进一步分析了所提出方法优越性的原因。

## 引言

漏洞检测系统在软件安全中发挥着至关重要的作用[1]，[2]，[3]，可以防止一系列安全事件[4]，[5]，[6]。因此，对更准确、高效的自动化软件漏洞检测方法的兴趣不断增长[7]，[8]，[9]，[10]。一般来说，现有的检测模型可以大致分为两类：（1）基于模式的漏洞检测模型[11]，[12]，[13]，[14]，[15]；（2）基于代码相似性的检测方法[9]，[10]，[16]，[17]，[18]，[19]。基于模式的漏洞检测方法[11]，[12]，[13]依赖专家手动定义漏洞规则或特征来检测漏洞。这些方法需要繁琐的人工努力，并且很难同时实现低误报率和低漏报率[18]，[20]。基于代码相似性的方法采用数据挖掘和机器学习技术来预测软件漏洞的存在性[16]，[17]，[18]，[21]。这种方法不需要专家手工制定的启发式规则，可以自动捕捉漏洞特征，成为一种有希望的替代方案。最近，受深度学习（DL）技术强大性能的影响，一些方法[16]，[17]，[18]，[20]，[21]已经提出利用DL模型从已知漏洞中自动学习漏洞特征，并在项目中识别未知的漏洞。

例如，李等人[18]提出了一种基于程序切片的方法，名为VulDeePecker，该方法通过基于库/API函数调用对源代码进行切片，并将切片代码馈入RNN[22]来检测漏洞。周等人[10]提出了将代码片段转化为基于抽象语法树（AST）、控制流图（CFG）、数据流图（DFG）和自然代码序列的图，并利用图神经网络（GNN）[23]从图中学习代码表示以识别漏洞的方法。

尽管现有的基于深度学习的漏洞检测方法表现出了很大的潜力，但它们仍然受到两个问题的限制。

(1) 它们很难从大量无关信息中识别并专注于与漏洞相关的信息。例如，当内存缓冲区中的数据量超过存储容量时，将触发缓冲区溢出漏洞。这种类型的漏洞只与使用缓冲区的代码相关。换句话说，如果代码片段中的许多语句与缓冲区无关，这些语句对于检测缓冲区溢出漏洞是没有帮助的。

(2) 现有的基于深度学习的方法在处理长代码片段时效果较差。由于GPU内存和计算资源受限，现有的神经模型经常限制其输入长度，例如CodeBERT [24]只保留前400个标记，并截断输入中的其他部分。因此，如果与漏洞相关的信息位于代码片段的截断部分，现有方法很难检测到这种漏洞。

为了缓解这两个问题，在这项工作中，我们提出了一种新颖的方法，可以更好地从代码片段中捕捉漏洞特征，特别是那些与漏洞无关的大量信息和长代码片段。我们观察到，一个代码片段通常包含多个执行路径来处理不同的情况，但通常只有少数执行路径是容易受到漏洞攻击的。基于这一观察，我们提出将代码片段分解为多个执行路径，使用神经模型学习每个路径的表示，并将多个路径的表示组合起来得到最终的代码表示。

对于上述现有方法的第一个问题，由于每个执行路径都是一个具有简单和线性结构的凝聚单元，将代码片段解耦为执行路径可以帮助模型专注于一致且高度相关的上下文信息，更好地捕捉漏洞特征。例如，使用后释放漏洞通常与单个执行路径相关。与直接对整个代码片段进行编码相比，分别对其执行路径进行编码可以过滤掉与漏洞无关的一些信息，并且方便提取漏洞特征。与此同时，由于执行路径中每个语句的执行顺序是线性的，神经模型不需要理解复杂的代码结构。它们可以专注于捕捉代码片段中更准确的语义信息。至于第二个问题，对于具有多个执行路径的代码，每个执行路径都比整个代码片段短，不太可能超出神经模型的长度限制。因此，长代码的尾部更有可能由神经网络进行处理，而不是被截断掉。

基于上述提到的思想，我们提出了一种名为EPVD的新方法，该方法将代码片段分解为多个执行路径以进行漏洞检测。具体而言，给定一个代码片段，EPVD首先将其解析为抽象语法树（AST），并基于AST构建其控制流图（CFG）。我们将这样的CFG称为基于语法的CFG。CFG中的每个节点表示一个语句，每条边表示两个语句之间的控制依赖关系。然后，EPVD使用一种基于贪心的路径选择算法从入口节点选择固定数量的路径，这些路径以CFG中的一个出口节点作为终点。我们在本文中将这样的CFG路径称为执行路径。我们仅选择固定数量的执行路径，因为代码中的循环可能会引入无限路径，而我们只需找到几条路径即可涵盖与代码片段中的漏洞相关的信息。每个选择的执行路径会被输入到一个预训练的代码模型中，以捕捉路径的内部注意力并学习其特征向量。此外，我们采用卷积神经网络（CNN）来捕捉不同路径之间的注意力，并融合所选择路径的表示以产生代码表示。最后，我们采用多层感知机（MLP）分类器基于代码表示来检测漏洞。

为了评估EPVD的有效性，我们通过合并三个现有的高质量漏洞数据集（即REVEAL数据集[25]、Big-Vul数据集[26]和Devign数据集[10]）来整理一个大型C/C++漏洞数据集。新数据集包含超过231k个代码片段，其中含有24k个漏洞。我们评估了我们的方法，并将其与五种最先进的基于DL的方法进行了比较。实验证明我们的模型在多个指标上都表现优于所有基准模型。具体而言，EPVD在精确度、召回率和F1值方面分别以22.30%、42.92%和32.58%的较大幅度提高了最佳基准模型的性能。进一步的分析证明了我们的模型能够从含有大量无关信息和长代码的漏洞代码片段中捕捉到漏洞特征的有效性。

总结一下，本文的主要贡献如下：

1）我们实现了一种基于抽象语法树构建代码片段控制流图的方法，并提出了一种基于贪婪算法的策略来选择控制流图中的代表性执行路径。

2）我们提出了一种基于执行路径的神经漏洞检测模型，名为EPVD，能够更好地捕捉漏洞特征并处理长代码。

3）我们进行了全面的实验证明了EPVD的有效性，并验证了EPVD中的技术决策的合理性和益处。评估结果显示EPVD优于所有基准模型，并且EPVD中的技术决策是合理且有益的。

4）我们发布了包括源代码、数据集和评估结果在内的复现包[27]。

本文的剩余部分的组织如下。我们首先在第二节介绍相关的工作。然后，在第三节中描述我们方法的动机，并提供基于语法的CFG的初步内容。第四节介绍我们的方法。实验结果将在第五节中呈现。第六节展示了我们方法的局限性和一些对有效性的威胁。最后，我们在第七节总结我们的工作，并讨论未来的工作。

## 相关工作

### A.利用神经网络进行软件漏洞检测

已经发展出了各种技术来检测漏洞。在文献中，早期的工作主要通过手动设计的漏洞模式来检测漏洞[11]，[12]，[13]。然而，这些工作需要繁琐的手动努力来分析和制定漏洞模式。另一方面，由于某些规则中的语法元素常常出现在不同的代码片段中，这些语法元素可能导致高假阳性和假阴性率[14]，[15]，[20]。为了减少人力工作，最近一些研究利用基于神经网络的模型来自动学习代码片段的语义特征[17]，[19]。基于深度学习的现有漏洞检测模型可以分为两大类：基于标记的模型和基于图形的模型。基于标记的模型将代码视为一个平面序列，并利用神经网络从已知漏洞中捕捉漏洞特征和检测未知漏洞[17]，[18]，[28]。例如，Russell等人[17]利用递归神经网络(RNN)和卷积神经网络(CNN)从代码标记序列中提取代码特征以进行漏洞检测。Li等人[18]使用BiLSTM [29]对输入代码片段的切片版本，即代码小工具，进行编码以检测漏洞。作者们根据“关键点”（例如库/API函数调用）对每个代码片段进行切片。然而，这些基于标记的方法没有考虑源代码的结构信息，导致了不准确的检测。 

基于图的检测模型通过使用各种图表示来表示代码，并采用神经网络来学习代码片段的结构属性，以进行漏洞检测。例如，Zhou等人采用门控图循环网络来捕捉来自源代码的三种图表示（即，AST、CFG和DFG）的代码片段的结构信息。Chakraborty等人提出了REVEAL，它利用门控图神经网络、重采样技术和三元损失函数来学习代码片段的结构属性。Lietal.提出了IVDetect，它将代码表示为程序依赖图（PDG），并通过图卷积网络将漏洞检测视为基于图的分类任务。IVDetect首先利用GloVe模型学习PDG中节点的表示，然后采用图卷积神经网络优化代码表示以用于检测。然而，由于这两个阶段在训练期间不相互交互，第一个阶段中的最优解可能导致第二个阶段中的最优代码表示，导致训练模型无法有效地检测到漏洞。尽管我们尽力复制和重新训练IVDetect模型（如采用多个较小的学习率和自适应学习率），但它在我们的合并数据集上无法收敛。因此，我们不使用这个模型进行比较。最近，Wu等人将代码片段的PDG转换成图像，以保留结构细节。此外，他们采用了图的三个中心指标（即度中心性、Katz中心性和接近中心性）来突出显示易受攻击语句的注意力。Cao等人提出了一种基于流敏感图神经网络的语句级内存相关漏洞检测方法，以共同学习语义和结构信息。

陈等人进行了一项全面的实证研究，探索了传统静态缺陷检测方法与现有基于神经网络的方法在定位触发缺陷路径方面的差距。作者们首先对一般的漏洞检测过程进行了形式化，并将十一种方法划分为三类：方法级、切片级和语句级。方法级和切片级方法将代码片段的方法或切片报告为有漏洞。语句级方法报告有漏洞的语句。然后，他们提出了一种新的细粒度度量标准，称为BTP，用于计算现有模型检测到的语句与触发缺陷路径上的语句之间的重叠程度。通过在D2A数据集上对十一种方法进行实验，作者们发现现有的漏洞检测方法在定位触发缺陷路径方面是不足的。我们提出的方法可以视为方法级漏洞检测方法，因为它通过基于多个基于语法的执行路径直接预测方法是否存在漏洞，而不是明确指出有漏洞的语句或切片。

我们的方法在技术上与现有方法有所不同：首先，我们的方法将输入的代码片段分解成几条基于语法的控制流图中的执行路径，这可以简化代码结构，并帮助神经模型捕捉漏洞特征。其次，我们提出了一种新的基于贪心策略的路径选择方法，可以尽可能涵盖尽可能多的代码语句。换句话说，分解的基于语法的执行路径可以指示漏洞的起源和触发方式。第三，与现有的方法级别检测方法不同，我们的方法应用 CNN 来融合多个路径表示以表示代码片段，这有助于捕捉触发错误的信息和路径间的关注。第四，我们的方法利用已预训练的代码模型（即 CodeBERT）基于执行路径学习代码表示，这是现有工作尚未探索的。

### B.基于预训练模型的代码表示模型

受到自然语言处理领域（NLP）预训练模型出色性能的启发，一些研究人员将这些预训练模型应用于提升与代码相关的任务[24]，[38]，[39]，[40]，[41]，[42]。大部分工作致力于在大规模源代码语料库上预训练模型，并进行一系列下游任务的微调[24]，[38]。例如，冯等人[24]提出了CodeBERT，它采用了掩码语言建模，并用替代令牌检测作为预训练目标，以支持代码搜索和摘要任务。CuBERT采用了掩码语言建模和下一个句子预测作为预训练目标，以学习代码表示[38]。此外，一些预训练模型在预训练阶段还考虑了代码片段的结构信息[39]，[40]，[41]，[43]。例如，郭等人[43]提出了GraphCodeBERT，它通过边预测和节点对齐任务学习代码片段的数据流信息。由于这些预训练模型在多项与代码相关的任务中表现出色，一些研究尝试采用预训练模型来检测漏洞代码[1]，[2]，[44]。然而，所有这些方法都直接利用预训练的代码模型进行预测，并面临从长代码和具有复杂结构的代码中捕捉漏洞特征的挑战。相反，我们的模型提取多个执行路径，更有可能从长代码的尾部语句中学习漏洞特征。此外，执行路径中的每条语句的顺序是线性的，这有助于捕捉代码中的语义信息。

## 动机和初步

在这一部分中，我们首先通过两个真实世界的漏洞代码片段来呈现我们方法的动机。然后，我们介绍基于语法的控制流图的定义。

![image-20240320092335721](https://s2.loli.net/2024/03/20/SOrs3RWPtYfbFnm.png)

### A.动机

为了更好地展示现有漏洞检测模型的两个限制，我们研究了一些现实世界的漏洞，并得出两个重要观察结果。第一个观察结果是：

一个存在漏洞的函数可能包含大量与漏洞无关的语句。例如，图1(a)展示了一个来自Linux内核项目的函数[45]，其中包含一个由CVE-2018-12633[46]公开的信息泄露漏洞。具体来说，第9行和第29行是漏洞所在的语句。在这段代码片段中的vbg_misc_device_ioctl()函数使用copy_from_user()函数两次读取相同的用户数据。用户数据的头部被重复获取，恶意用户可以在两次获取之间篡改头部中的关键变量，导致严重的内核错误。正如我们所看到的，这个函数有67行代码，但只有其中几行，即第9行和第29行，与漏洞相关。如果我们直接将整个函数输入神经模型，模型将很难准确捕捉到漏洞的特征。另一方面，我们注意到尽管这个函数包含很多执行路径，但此漏洞只能被其中的一些路径利用。因此，我们提出通过从代码的语法控制流图中提取和采样执行路径来减少与漏洞无关的信息，使神经模型更容易捕捉到漏洞的特征。

观察2：截断长代码片段尾部的语句可能会对漏洞检测的有效性产生负面影响。为了减少GPU内存和计算资源，大多数神经漏洞检测模型都限制了输入大小，这可能会导致与漏洞相关的关键信息丢失。图1（b）所示的函数包含CVE-2016-7115[48]暴露的MACTelnet项目[47]中发布的缓冲区溢出漏洞。该漏洞位于第58行，允许远程服务器通过MT_CPTYPE_PASSWORD控制数据包中的长字符串执行任意代码。如果我们使用基于子标记的标记器（如CodeBERT[24]使用的标记器）对该函数进行标记，则易受攻击的线路将被标记为698-708个标记。由于大多数检测模型的输入极限小于512，因此脆弱线将被此类模型截断，并且它们将很难捕捉到该漏洞的特征

B.基于语法的控制流图

如上所述，我们的方法旨在将代码片段分解成多个执行路径，并从这些路径中学习其表示。在实践中，动态提取用于漏洞检测的执行路径会非常昂贵。编译大型项目（如Linux内核）也是昂贵的。此外，现有数据集中提供的漏洞数据通常是无法编译的，有时甚至是不完整的代码片段。因此，需要编译的技术（如符号执行）不适用于我们的场景。因此，我们选择以静态方式提取执行路径。具体而言，我们选择基于代码片段的AST构建CFG并从CFG中提取执行路径。我们将这样的CFG称为基于语法的CFG，其中每个节点表示代码片段中的一个语句，每个有向边表示语句之间的可能执行顺序。基于语法的CFG类似于Joern构建的CFG。Joern是一种广泛使用的静态分析工具，也可以基于AST构建CFG。但是，Joern通过分析更细粒度的AST节点（如运算符）来构建CFG，如果我们只需要构建CFG，这样做效率不高。在我们的实验环境中，使用Joern为1,000个代码片段构建CFG大约需要4,560秒，而使用我们的基于语法的CFG构建方法只需要49秒。因此，我们使用基于语法的CFG构建方法代替Joern。

形式上，我们采用$G_i =（V_i，）$表示代码片段ci的基于语法的CFG，其中$V_i =（v^1 _i，v^2 _i，...，v^{|Vi| }_i）$是包含$|V_i|$个语句的节点集合，$\varepsilon_i$是表示语句之间控制流的边集合。每个边都是$c_i$中两个语句之间的关系，一个语句可能在另一个语句之后执行。$G_i$中的路径是一个节点序列$p =（n1，n_2，...，n_k）$，其中节点$n_k$是$c_i$的第k个语句。对于任意一对相邻节点$n_p和n_q$，存在从$n_p到n_q$的边。如果起始节点等于结束节点，则路径将成为一个循环。

## IV、 建议的方法

我们在本节详细阐述了提出的方法。我们的方法的整体工作流程如图2所示。我们首先将每个代码片段解析成抽象语法树（AST），并根据AST构建基于语法的控制流图（CFG）。接下来，我们提出了一种基于贪心策略的路径选择算法，从基于语法的CFG中选择多条执行路径，即将代码片段分解为多个执行路径。然后，我们使用CodeBERT [24]将选定的路径编码为带有路径内注意力的向量，然后将其输入到卷积神经网络（CNN）中捕捉路径间的注意力。最后，我们利用多层感知机（MLP）分类器进行检测。

![image-20240320095449257](https://s2.loli.net/2024/03/20/FbU6HJcaRs8GArD.png)

### A.根据AST构建控制流图

A.根据AST构建控制流图

这个阶段将代码片段作为输入，使用tree-sitter[50]将其解析成抽象语法树（AST），并从AST构建基于语法的控制流图（CFG）。在本节中，我们使用图3中的示例来说明如何从代码片段的AST构建基于语法的CFG。在构建CFG之前，我们使用正则表达式删除代码片段中的空行和注释。我们还标记了代码中每个语句的行号。由于语法CFG中的每个节点表示一个独立的语句，因此在构建CFG时，我们仅考虑AST中的语句节点。为了简化说明，我们进行了以下定义：

简单语句：它们在其AST中不包含其他语句的语句。

下一个语句：一个节点的下一个语句指的是在执行该节点后可能执行的语句。一个节点可能有多个下一个语句。

非子节点下一个语句：一个节点的非子节点下一个语句是该节点的下一个语句，并且不包含在以该节点为根的子树中。

常规语句：不包括中断语句、继续语句、返回语句和抛出语句的语句。

![image-20240320095607776](https://s2.loli.net/2024/03/20/y8xbcVdWLwaHl2s.png)

构建基于语法的代码片段CFG，我们首先将代码片段的所有语句作为CFG的节点添加进去，并将第一条语句视为入口节点，将所有return_statement、assert_statement和throw_statement视为出口节点。如果代码片段的最后一条语句不是出口节点，我们在代码末尾添加一个虚拟出口节点。然后，我们以广度优先的方式遍历AST，并为每种语句类型设计规则，以构建CFG中的边。

1）对于既是Simple Statement又是Normal Statement的每个语句，如果它的下一个兄弟语句在AST中存在，我们将它连接到这个兄弟语句上。例如，在图3中，我们将节点2连接到节点3，将节点3连接到节点4。

2）对于每个循环语句，即for_statement和while_statement，我们将其与第一个子语句以及下一个兄弟语句（如果存在）连接起来。如果最后一个子语句是Normal Statement，我们将该语句连接到循环语句上。例如，在图3中，我们将节点4连接到节点5，将节点4连接到节点10，将节点5连接到节点4。

3）对于每个break_statement，我们首先找到它在AST中的第一个祖先语句，该祖先语句是循环语句或switch_statement。然后，我们将它连接到该祖先语句的Non-Child Next Statement上。

4）对于每个continue_statement，我们首先找到它在AST中的第一个祖先语句，该祖先语句是循环语句。然后，我们将它连接到该祖先语句上。

5）对于每个if_statement，我们首先将它与下一个兄弟语句连接起来（如果存在该语句），并将其then_block的最后一个子语句连接到它当前的Next Statements上（如果最后一个子语句是Normal Statement）。例如，在图3中，我们将节点6连接到节点4，将节点7连接到节点4，将节点10连接到节点12，将节点11连接到节点12。然后，如果它的子语句包含else_statement，我们将else_statement连接到它的每个Next Statement上，删除从if_statement到其Next Statements的边，并添加从if_statement到else_statement的边。对于图3，我们将节点8连接到节点4，删除节点6到节点4的边，将节点6连接到节点8。接下来，我们遍历else_statement。我们将其最后一个子语句连接到其当前的Next Statements上。如果最后一个子语句是Normal Statement，我们删除从它到其Next Statement的边，并将它连接到其第一个子语句上。对于图3，我们将节点9连接到节点4，删除节点8到节点4的边，将节点8连接到节点9。最后，我们将if_statement连接到其then_block的第一个子语句上。对于图3，我们将节点5连接到节点6，将节点6连接到节点7，将节点10连接到节点11。

6）对于每个switch_statement，我们将其连接到第一个case_statement。对于每个case_statement，我们首先将其连接到下一个case_statement或default_statement。然后，如果该case_statement的最后一个子语句是Normal Statement，我们将其连接到该case_statement的当前Next Statements上。最后，我们将case_statement连接到其第一个子语句上。对于每个default_statement，如果该default_statement的最后一个子语句不是Normal Statement，我们将其连接到其第一个子语句上，并将其最后一个子语句连接到switch_statement的Non-Child Next Statements上。

7）对于每个try_statement，我们将其catch_clauses视为语句。我们无法为try_statement构建一个“正确”的CFG，因为我们无法仅从调用者的AST中知道每个函数调用可能抛出的异常。此外，构建一个“完整”的CFG需要将try_block中的每个语句与每个catch_clause连接起来，这可能引入太多的死路径并对后续阶段产生负面影响。因此，我们选择仅将try_block中的最后一个Normal Statement连接到catch_clauses。具体来说，我们将try_statement连接到其try_block中的第一个语句，将try_block的最后一个Normal Statement连接到其第一个catch_clause上。对于每个catch_clause，我们将其连接到其第一个语句和下一个catch_clause上。此外，对于try_block和每个catch_clause中的最后一个Normal Statement，我们将其连接到try_statement的Non-Child Next Statement上。

### B.路径选择

代码片段可以看作是其所有执行路径的组合。然而，如果代码片段包含循环，则可能会有无限多个执行路径。对于编码代码片段的所有执行路径可能需要大量的计算资源。因此，我们认为在学习相应代码片段表示时，在CFG中编码全部执行路径是不可行的。我们在基于语法的CFG中将执行路径定义为从入口节点到出口节点的路径，并在此之后将其称为执行路径。此外，在未知代码片段中准确定位易受攻击的语句是非常困难的。如果我们仅提取一个执行路径来表示代码片段，则很有可能会错过易受攻击的语句，并且对漏洞检测的性能产生负面影响。幸运的是，基于我们对实际漏洞的观察和第三节中介绍的例子，我们发现往往只需几个执行路径就可以覆盖漏洞的根本原因。因此，我们选择并编码几个具有代表性的执行路径来表示相应的代码片段，而不是在CFG中编码全部或仅一个执行路径。当将代码片段表示为AST路径时，Alon等人也使用了类似的策略。这个阶段负责从前几个阶段构建的CFG中选择几个代表性的执行路径。

选择执行路径有两个要求：首先，为了避免代码片段中丢失重要信息，所选路径应尽可能覆盖尽可能多的代码行。其次，为了减轻模型训练的负担，我们期望所选路径尽可能短。不幸的是，这两个要求在一定程度上存在冲突。为了在它们之间达到一个平衡，我们提出了一种基于贪心的路径选择算法。

算法1展示了我们如何选择执行路径。为了方便说明，我们做出以下定义：

分支节点：CFG中出度大于1的节点。

分支边：CFG中源节点为分支节点的边。

路径权重：路径的权重是其所有边的权重之和。

假设我们最多可以从CFG中选择m条路径。我们算法的关键思想是，对于前m-1条路径，我们尽量选择多样且短的路径，而对于最后一条路径，我们尽量最大化所有路径的总节点覆盖范围。具体来说，首先，我们将CFG中所有边的初始权重设为1，并将CFG中的所有节点标记为未覆盖。然后，我们逐个选择前m-1条执行路径。对于每条路径：（1）对于每个出口节点，我们选择一个包含至少一个未覆盖节点且在CFG中路径权重最小的候选执行路径。（2）我们从选定的候选路径中选择包含最多未覆盖节点的路径。例如，在图3中，第一个选定的执行路径是(1, 2, 3, 4, 10, 12)。（3）我们标记该路径中的每个节点为已覆盖，并将该路径中的分支边权重增加100，以奖励对新边的探索。（4）我们继续从更新后权重的CFG中选择下一个未覆盖节点最短的执行路径。例如，在图3中，第二个选定的执行路径是(1, 2, 3, 4, 10, 11, 12)，因为从节点10到节点12的边的权重已增加。最后，我们选择最后一条路径尽可能覆盖更多节点。具体来说，我们在CFG中迭代执行路径，忽略包含循环的路径，找到覆盖最多未覆盖节点的路径，并选择最短的路径。我们忽略包含循环的执行路径，是因为对于每条这样的路径，必定存在一条覆盖相同节点集合但不含循环且更短的执行路径。

在第五节中，我们提供更详细的内容来评估不同路径选择算法以及路径数量对模型性能的影响。

C.代码表示学习

该阶段旨在从选择的$m$条执行路径中学习目标代码片段的表示。直观地说，为了获得良好的表示，我们需要捕捉每条路径的特征以及路径之间的关系。该阶段首先利用预训练的CodeBERT模型[52]学习路径内的注意力，并将每条路径编码为特征向量。我们使用CodeBERT是因为它是基于Transformer的模型，与基于RNN的模型相比，它能更好地捕捉长序列中的长期依赖关系，并且它在大规模代码数据上进行了预训练，并在代码理解和代码生成任务中显示出了有效性[24]。具体而言，给定一个选择的路径$P$，我们首先按顺序将其所有节点（即语句）连接在一起形成代码片段$S$。然后，CodeBERT使用子词分词器[53]将$S$标记为长度为n的标记序列，并使用嵌入层将标记序列映射为嵌入序列$\tilde{X} = {\tilde{x}_1,\tilde{x}_2,...,\tilde{x}_n}$，并使用多个Transformer层学习每个代码标记的上下文嵌入。Transformer层将向量序列（例如$\tilde{X}$）作为输入，采用多头自注意层[54]、前馈层和层归一化操作[55]来捕捉路径内的注意力并改进输入向量，具体如下：
$$
\hat{X} = MultiHead(\tilde X, \tilde X, \tilde X), ----------(1) \\

X^i = LayerNorm( \hat X + FFN(\hat X))----------- (2)
$$
在这里，$MultiHead(·)$、$FFN(·)$和$LayerNorm(·)$分别表示多头自注意力层[54]、前向传播层和层归一化操作[55]。$i$在$X^i$中表示Xi是第$i$个Transformer层的输出。经过$l$个Transformer层的处理后，路径P被编码成一系列上下文嵌入$X^l = \{x^l_1, x^l_2,...,x^l_n\}$。我们将在$S$开头插入的特殊标记“$[CLS]$”的嵌入$x^l_1$视为$P$的表示，这是在使用CodeBERT进行分类任务时的常见做法[24]。由于我们将代码片段分解为多个路径，我们分别使用CodeBERT对每个路径进行编码，并将它们的表示垂直连接成矩阵$E ∈ R^{m×d}$，具体如下：
$$
E=\begin{bmatrix}
e_1 \\
...\\
e_m 
\end{bmatrix}----------(3)
$$
其中，$e_i$指的是第i条路径的表示。

然后，这个阶段采用CNN来学习路径之间的注意力，并融合所选路径的特征向量，即E。具体而言，按照在文本分类中使用CNN的思路[56]，我们首先使用具有k个卷积滤波器的CNN从E中捕捉路径之间的特征，如下所示：
$$
c_j = \phi _c (E \odot F^j)
$$
其中，$\odot$表示内积操作符，$\phi _c$表示卷积操作，$F^j ∈ R^{q×d}$是第j个滤波器，$q$是滤波器的窗口大小。$d$表示表示的维度。为了捕捉最显著的特征，我们使用最大池化将所有滤波器的卷积结果组合起来，如下所示：
$$
C = MaxPooling(c_1, c_2,...,c_k).   ----------(5)
$$
最后，我们将C语言和所有选定路径的表示相结合，得到最终的代码表示，并使用一个多层感知器分类器来进行漏洞检测，具体步骤如下：
$$
Z =\big[C ‖ e_1 ‖ ··· ‖ e_m\big] , (6) \\
\hat y = Softmax(MLP(tanh(Z))), (7)
$$
"‖"代表水平连接操作。

#### D.检测模型训练

我们通过最小化以下损失来训练分类器：
$$
L(\hat y, y)=−y · log (\hat y)+(1− y) · log (1 −\hat y) ,
$$
其中$y$是真值。$\hat y$是输出值。

## V.实验

在本节中，我们进行了大量实验来证明我们模型的优越性，并分析其有效性的原因。具体来说，我们的目标是回答以下研究问题：

RQ1：与现有的最先进基线相比，EPVD在漏洞检测方面有多有效？

RQ2：所提出模型的不同设计选择有什么影响？

RQ3：EPVD能否在各种类型的漏洞中胜过现有的漏洞检测方法？

RQ4：训练数据的规模如何影响EPVD的性能？

RQ5：EPVD在现实应用中有多有效？

RQ6：EPVD在检测漏洞方面有多高效？

### A.数据集

为了评估EPVD的有效性，我们建立了两个数据集：（1）从多个现有漏洞数据集中合并得到的数据集，（2）从其他真实开源项目中收集到的数据集。这两个数据集的统计数据如表I所示。第二列和第三列分别是非漏洞函数和漏洞函数的数量。第四列表示每个数据集中非漏洞函数和漏洞函数的比例。第五列是不同数据集中源代码的总数。对于合并后的数据集，我们将三个现有的高质量数据集合并在一起，即REVEAL数据集[25]、Big-Vul数据集[26]和由Devign的作者构建的数据集[10]（以下简称Devign数据集）。REVEAL数据集[25]包含来自Linux Debian Kernel和Chromium这两个大型开源项目的超过22K个函数，其中9.15%的函数存在漏洞。Big-Vul数据集[26]是根据2002年至2019年的CVE条目构建的，涵盖了348个不同的项目和91个不同的漏洞类型。Devign数据集来自于两个大型C项目，即QEMU[57]和FFmpeg[58]。这三个数据集都是根据开源项目中的真实C/C++漏洞构建而成，已被先前在漏洞检测方面的工作广泛使用[3]，[9]，[10]，[25]，[26]。

![image-20240320104136047](https://s2.loli.net/2024/03/20/wVpHRr1hzbWGd8n.png)

我们将合并后的数据集随机分为三个不重叠的训练集、验证集和测试集，比例分别为80%、10%和10%。为避免数据重复，我们在将每个样本转换为词元并删除注释后，删除了重复的测试样本，即与一个或多个训练样本完全相同的样本。最终，合并后的数据集中还剩下超过231K个函数，其中10.5%是有漏洞的。

关于第二个数据集，我们按照之前的工作[28]，通过收集来自Redis [59]和Lua [60]的与安全相关的提交来构建数据集。Redis是一个众所周知的数据库系统服务器，而Lua是一种广泛使用的脚本语言。根据Chen等人的方法[28]，我们首先通过选择提交消息中包含与bug相关的关键词（如“bug”，“crash”，“memory error”，“vulnerability”和“fix”）的提交来提取修复bug的提交。然后，三位经验丰富的软件工程师仔细检查每个与bug相关的提交的修改，了解如何修复bug，并将修复提交中的安全函数标记为负面，将对应易受攻击提交中的易受攻击函数标记为正面。手动检查所有与bug相关的提交共花费了120小时。由于Lua项目中漏洞数量较少，我们还将Redis和Lua项目的数据集合并，并将其命名为“混合数据集”。

此外，我们还希望研究不同类型漏洞在 EPVD 性能上的表现。由于 Big-Vul 数据集[26]是从现实世界的 CVE 信息中爬取的，包含了多种漏洞类型，我们从 Big-Vul 数据集中确定了数量最多的前十种漏洞类型。对于每一种漏洞类型，我们首先从 Big-Vul 数据集中挑选出该类型的易受攻击代码片段，然后从合并后的数据集中随机选择一定比例的非易受攻击代码片段，以使选中的易受攻击代码片段与选中的非易受攻击代码片段的比例与合并数据集中的比例相同。我们将80%的代码片段放入训练集，剩余的20%的代码片段分别放入验证集和测试集。表II总结了不同类型漏洞的详细信息。

CWE119. 内存缓冲区边界不当限制：这种类型的漏洞包括对内存缓冲区的操作，但它可以从缓冲区的边界之外读取或写入内存位置。这种漏洞类别会导致系统崩溃或泄露敏感信息。

CWE20. 输入验证不当：这种类型的漏洞包括接收输入或数据的函数，但没有进行有效验证或错误验证。如果输入或数据没有经过验证，软件将接收到意外的输入，导致控制流程改变或任意代码执行。

CWE399. 资源管理错误：这种类型的漏洞是由于软件执行过程中对系统资源（如内存和文件）的错误管理而引起的。

CWE264. 权限、特权和访问控制：这种类型的漏洞与不当的访问控制有关，如权限、特权和其他安全特性的管理。

CWE416. 使用已释放空间：这种类型的漏洞会引用先前被释放的内存，可能导致有效数据的损坏或执行任意代码。

CWE125. 越界读取：这种类型的漏洞会导致读取过多的数据，进而导致分段错误或缓冲区溢出。

CWE189. 数值错误：这种类型的漏洞与数字的不正确计算或转换有关，如数字类型之间的不正确转换以及使用不正确运算符进行浮点数比较。

CWE362. 并发使用带有不正确同步的共享资源：这种类型的漏洞包含可以与其他代码并发运行的代码片段，而该代码需要对一个共享资源进行临时独占访问。共享资源可能会被同时运行的另一个代码修改。

CWE476. 空指针解引用：这种类型的漏洞会在应用程序解引用一个期望为有效但为空的指针时导致崩溃或退出。

CWE190. 整数溢出或环绕：这种类型的漏洞会在将整数值递增为大于原始值的值时产生整数溢出或环绕。当该值用于进行安全决策或控制循环时，源代码变得关乎安全。

### B.实验方法

基准：为了评估我们的方法的有效性，我们将其与七种最先进的技术进行比较，即VulDeePecker [18]、SySeVR [20]、DeepWukong [28]、VGDetector [61]、Devign [10]、REVEAL [25]和CodeBERT [24]，它们属于三种类型，即基于标记的模型、基于图的模型和预训练模型。

VulDeePecker是基于令牌的模型，首先根据代码片段中的“关键点”（如库/API函数调用）对其进行切片，然后使用长短期记忆网络（LSTM）[22]对切片的代码片段进行编码和预测。

SySeVR是基于图的模型，将代码片段表示为程序依赖图（PDG），并利用漏洞句法特征，如库/API函数调用、数组使用、指针使用和算术表达式，对PDG进行切片。它采用LSTM [22]来学习切片代码的表示并检测漏洞。

DeepWukong是基于图的模型。它首先根据控制流和数据流信息构建代码片段的PDG，并使用包含系统API调用和算术运算符的语句作为切片标准来切割代码片段。然后，它采用图神经网络[62]和Doc2Vec [63]对代码片段进行编码和漏洞预测。

VGDetector利用控制流图表示代码片段。它使用图卷积网络[62]和Doc2vec[63]来学习控制流图的表示以进行漏洞检测。

Devign是一种基于图的模型，利用门控图循环网络（GGN）[23]来表示将输入代码片段的抽象语法树（AST）、控制流图（CFG）、数据流图（DFG）和代码序列结合起来形成的图，用于漏洞检测。

REVEAL是一种基于图的模型，它将Devign[10]与重新采样技术[32]和三元组损失[33]相结合，用于检测漏洞。

CodeBERT是一种基于预训练的模型，它是直接使用CodeBERT [24]来预测输入代码片段是否存在漏洞的方法。这个模型在多个软件工程任务上取得了良好的性能。

![image-20240320104706806](https://s2.loli.net/2024/03/20/hj97brM6iTaXC3k.png)

评估指标：参考之前的作品[9]，[10]，[24]，我们采用了三个广泛使用的分类指标，即准确率、召回率和F1得分，用于评估。准确率 = # TP /（# TP + # FP） ， 召回率 = # TP /（# TP + # FN） ，F 1 = 准确率 * 召回率 /（准确率 + 召回率） 。# TP 表示正确检测到的易受攻击代码片段的数量。# FP 表示错误地将非易受攻击代码片段误报为易受攻击。# FN 是将易受攻击代码片段错误预测为非易受攻击的数量。

实验环境：我们使用PyTorch [64]以Python实现了EPVD。实验是在一个配备了4个NVIDIA GeForce GTX 3090 GPU和两个主频为2.90 GHz的Intel Xeon Gold 6226R CPU的机器上进行的。实验设置：对于路径选择阶段，默认情况下我们将选择的路径数目m设置为3。在本节中，我们研究不同m值对我们方法的有效性的影响。在代码表示学习阶段，我们使用了具有128个滤波器形状的CNN。我们将连接层中的隐藏层大小设置为768。在训练过程中，我们使用AdamW [65]作为优化器，并基于验证集上的最佳F1-Score选择最佳模型。

C.总体性能分析（RQ1）

我们在合并的数据集上训练和评估我们的方法以及所有基线，并通过精确度、召回率和F1分数比较它们的性能。结果表格III中显示，最佳结果已用粗体标出。我们可以看到EPVD在这三个指标上的表现明显优于所有基线，并取得了66.69%的F1分数，表明EPVD的有效性。具体而言，它在精确度、召回率和F1分数上相较于表现最好的基线CodeBERT分别提升了22.30%、42.92%和32.58%。此外，我们还有以下发现：

（1）SySeVR是表现最差的基线。其中一个可能原因是LSTM在建模程序语义方面的能力有限。还有一个可能的原因是SySeVR采用特定的预定义标准（即库/API函数调用、数组使用、指针使用和算术表达式）对源代码进行切片，这可能导致在切片过程中丢失与漏洞相关的信息。与此类似，VulDeePecker也使用了类似的切片标准（即库/API函数调用）并且表现不佳。与VulDeePecker和SySeVR相比，我们的方法不仅采用了强大的代码表示模型，还引导神经模型关注于小而连贯的代码片段，即执行路径，这有助于神经模型更好地从代码中捕捉到漏洞模式。

（2）我们可以看到，CodeBERT表现优于所有其他基线，尽管它不像VulDeePecker一样对输入代码进行切片，也不像其他基于图的基线那样明确提取和利用代码的结构信息。这表明CodeBERT可以有效地从代码中捕捉与漏洞相关的语法和语义信息，证明了我们选择使用CodeBERT来编码执行路径的合理性。除了CodeBERT和EPVD之外，VGDetector在精确度和F1分数方面取得了最佳表现。一个可能的原因是通过编码控制流图，VGDetector可以有效地捕捉代码的执行逻辑，提升了漏洞检测能力。我们的方法可以被视为兼具CodeBERT和VGDetector的优点，因为它从控制流图中提取执行路径，并使用CodeBERT对其进行编码。执行路径的简单线性结构和较短的长度使神经网络更容易捕捉与漏洞相关的信息。

(3)在其他基准测试中，尽管DeepWukong考虑了控制流和数据流，但其性能比VGDetector和EPVD差。经过分析结果，我们认为可能的原因是：

1）DeepWukong使用的切片标准，即包含系统API调用和算术运算符的语句，有时与特定的漏洞无关。因此，DeepWukong生成的切片可能会丢失与漏洞相关的信息。

2）DeepWukong中的神经模型仍需要理解复杂的代码结构，这并不容易。相比之下，首先，EPVD通过使用我们的路径选择算法尽最大可能覆盖分解执行路径中的语句，努力保留了代码中的所有信息。此外，执行路径的结构简单且线性，使神经网络更容易从中获取与漏洞相关的信息。

![image-20240320104746654](https://s2.loli.net/2024/03/20/doeaJ9RWDb1E3rP.png)

为了更好地理解EPVD的性能，我们将EPVD的预测结果与最佳基准线CodeBERT进行比较。首先，我们从测试集中选择了小于400个标记的代码片段，这是CodeBERT的输入长度限制，并比较EPVD和CodeBERT在这些代码片段上的性能。表格IV显示了结果。我们可以看到，EPVD在所有指标上的表现都优于CodeBERT。EPVD的召回率甚至增加了103.10％。一个可能的原因是EPVD可以简化代码结构，并帮助现有神经网络捕捉漏洞特征。为了支持这一观点，我们使用if语句的数量来衡量代码片段的结构复杂度，并发现EPVD检测到了比CodeBERT多544个漏洞，其中302个包含三个或更多if语句。此外，我们还从测试集中选择了超过400个标记的代码片段，并将它们视为长代码片段，与CodeBERT进行检测性能的比较。

表格V呈现了结果，EPVD的F1-Score从53.18％提高到了61.78％，优于CodeBERT。具体而言，我们统计了超过400个标记的漏洞，并发现EPVD能正确识别其中的265个，而CodeBERT仅能识别87个。这证实了我们的观点。此外，图4(a)展示了我们测试集中的一个样本，它是php/php-src项目[66]中包含CVE-2014-3515 [67]漏洞的一个函数。这个漏洞的根本原因在第47行。由于函数非常长，在被CodeBERT处理之前，第47行会被截断以满足CodeBERT的输入长度限制。缺少第47行会导致神经模型难以捕捉到这个函数的漏洞特征，因此CodeBERT无法检测到这个漏洞。对于EPVD，它从函数中提取了多条执行路径，并将它们作为输入。图4(b)展示了一条提取的路径。我们可以看到，提取的路径要比函数短得多，漏洞的根本原因位于此路径中的第29行，在输入神经模型之前不会被截断。这增加了神经模型捕捉漏洞特征的概率。

根据我们的手动检查，我们还发现EPVD能够更好地区分与漏洞相关的信息和与漏洞无关的信息，优于基线结果。图5展示了一个例子，其中的三个函数来自于php-src项目[66]。图5(a)中的函数是一个测试样本，包含整数溢出漏洞（第41行和第42行），并且由CVE-2016-3078 [68]揭示。图5(b)和(c)中的函数是训练样本。我们可以看到：（1）图5(a)和(b)中的函数之间有许多相似的语句，用灰色矩形标出。虽然我们的方法已经针对图5(b)中的非漏洞函数进行了训练，但它仍然能够正确预测图5(a)中的函数为漏洞函数。这意味着我们的方法成功地忽略了与漏洞无关的信息。（2）图5(c)也是一个整数溢出漏洞，由CVE-2016-3078 [68]揭示，与图5(a)中的漏洞类似。虽然两个函数除了与漏洞相关的语句不同外，我们的模型仍然将它们视为与漏洞相关的相似函数，而不会被其他无关信息干扰。

### D.详细分析（RQ2）

在这个子部分中，我们想要探讨不同模型选择对我们方法的有效性产生的影响，包括不同的路径选择方法、不同数量的选定路径以及不同的路径融合方法。

1）不同路径选择方法的效果：EPVD的关键思想是将长代码分解为多个执行路径，并学习基于这些路径的表示来捕捉漏洞模式。为了在代码覆盖率和路径长度之间进行权衡，我们提出了一种路径选择方法，该方法首先选择两条不同且较短的路径，然后选择能够覆盖最多未覆盖语句的路径作为最后的路径。为了探索不同路径选择方法对EPVD性能的影响，我们将EPVD与其两个变体进行比较：（1）EPVD-2，该变体首先从CFG中选择一条最短的执行路径，然后依次选择两条能够覆盖最多未覆盖语句的路径。（2）EPVD-3，该变体依次选择三条能够覆盖最多未覆盖语句的路径。除了使用的路径选择方法不同外，EPVD和这两个变体是相同的。将EPVD与这两个变体进行比较可以帮助我们理解路径选择方法的重要性和路径分解的可行性。

我们的比较结果如表VI所示。平均覆盖率列是源代码中可覆盖的代码行数与三条路径总数的比率。我们可以看到，模型使用的长路径越多，平均覆盖率就越高，这是直观的。然而，就平均覆盖率而言，这三种路径选择方法之间的差异很小（≤1.53%）。EPVD在F1-Score方面表现优于EPVD-2和EPVD-3，分别高出0.55分和1.14分，尽管它的覆盖率略低于EPVD-2和EPVD-3。此外，训练EPVD-2和EPVD-3所需的时间分别比EPVD多出2.11%和2.26%。因此，我们认为选择两条短且不同的路径以及一条最大化代码覆盖率的长路径是一个有益的决策。

2）选定路径数量的影响：在EPVD中，我们将代码片段分解为三条执行路径。尽管选择所有执行路径是不切实际的，我们仍然有许多选定路径数量的选项，如第IV-B节所讨论。因此，我们希望评估不同选定路径数量对EPVD性能的影响。我们构建了我们方法的三个变体，即EPVD-p2、EPVD-p4和EPVD-p5，除了选择2、4和5个执行路径外，其余与EPVD相同。对于每个具有m条路径的变体，我们用我们的路径选择方法选择m-1条短且不同的路径，并选择一条长且覆盖率高的路径。我们将它们的性能与EPVD进行比较。表VII呈现了结果。我们可以看到，EPVD在F1-Score方面取得了第二好的表现，而EPVD和EPVD-p5之间的性能差异非常小（仅为0.0.3%）。然而，与EPVD相比，EPVD-p5的训练时间增加了37.57%。此外，EPVD是在Precision方面表现最好的。考虑到效果和效率之间的权衡，我们认为将选定路径数量设置为三是合理的。

3）不同路径融合方法的影响：在EPVD中，我们采用了CNN来学习路径间的注意力并融合三个执行路径。为了探索不同路径融合方法对我们方法性能的影响，我们将EPVD与其两个变体EPVD-mlp和EPVD-blstm进行比较。EPVD-mlp首先将选定路径的表示水平连接，然后将连接向量输入MLP以获得最终的代码表示。EPVD-blstm采用BiLSTM [22]来融合路径表示。按照之前的工作 [18]，我们使用了一个三层的BiLSTM。两个变体的其他超参数与EPVD相同。为了检查EPVD与这两个变体之间的性能差异是否具有统计学意义，我们参考之前的工作 [69]，使用样本外自助验证 [70]，[71]生成一个自助样本。我们重复这个过程50次，并在95%置信水平下应用Wilcoxon符号秩检验 [72]进行统计分析。

![image-20240320105148561](https://s2.loli.net/2024/03/20/vsMNyQc79zZDp3t.png)

结果呈现在表VIII中。我们可以看到，我们的模型在F1得分方面比这两个变体都要高出0.42分以上。EPVD相对于该两个变体（即EPVD-mlp和EPVDblstm）的改进具有统计学意义，p值均小于0.001。结果证实了CNN能够更好地捕捉多个执行路径中的路径间注意力。4）贪婪式路径选择策略的影响：在EPVD中，我们采用了贪婪式策略对代码片段的基于语法的CFG进行分解。为了理解贪婪式路径选择策略的效果，我们构建了EPVD的两个变体，分别为EPVD-multi-encoder和CodeBERT-slicing。EPVD-multi-encoder采用了三个不同的CodeBERT模型来分别对三个提取的执行路径进行编码，然后利用三个MLP分类器计算这些提取的执行路径的三个概率。由于如果代码片段的任何一个执行路径是易受攻击的，则该代码片段是易受攻击的，我们选择这三个概率中最高的概率作为最终的输出概率，并且只基于这个概率计算评估指标。具体来说，如果最终的概率大于0.5，则预测输入代码片段是易受攻击的，否则，认为是非易受攻击的。CodeBERT-slicing使用了DeepWukong的切片方法，但采用CodeBERT来对代码切片进行编码。我们在表IX中呈现了比较的结果。我们可以看到，在召回率和F1得分方面，EPVD优于EPVD-multi-encoder，这表明将选定的路径融合用于漏洞检测比分别检测每个路径更加有效。一个可能的原因是组合多个路径可以提供附加的与漏洞相关的信息。EPVD在所有的评估指标上都大幅优于CodeBERT-slicing，这意味着具有特定标准的切片方法不如我们的贪婪式路径选择策略有效。这可能是因为覆盖所有与漏洞相关的切片标准很难，如果不是不可能的话，并且使用预定义的标准进行切片可能会导致丢失一些对于某些漏洞来说重要的信息。

### E.不同类型漏洞的检测结果（RQ3）

![image-20240320105205751](https://s2.loli.net/2024/03/20/V78AJ5opjM9uvZR.png)

如表X所示，EPVD在检测不同类型的漏洞时性能存在变化，因为不同类型的漏洞表现出不同的行为。我们还可以看到：（1）EPVD在10种类型中有8种类型表现最佳，几乎所有这些漏洞都与控制流和数据流信息相关，例如CWE20和CWE264。这是因为EPVD不仅明确地分解控制流信息，还在每个路径中隐含了数据流信息。由于每个分解的执行路径具有更简单的逻辑、线性结构和较短的长度，CodeBERT可以更好地捕捉源代码的数据流信息，有助于EPVD检测与数据流相关的漏洞。（2）EPVD在检测CWE119和CWE476漏洞方面没有达到最佳性能。相比之下，VGDetector和DeepWukong分别达到了最佳F1分数，分别为60.69%和59.45%。我们手动检查了结果，并发现CWE119漏洞的长度通常在神经模型的输入限制范围内，这可能限制了所提出模型的优势。此外，CWE476漏洞与数据流信息密切相关，因为它们通常在指针指向无效内存地址并引用它们时发生，导致不可预见的错误和软件系统崩溃。EPVD没有明确考虑数据流信息，这可能使EPVD比DeepWukong更难捕捉与CWE476相关的特征。（3）SySeVR无法检测到属于CWE264的漏洞，表X中相应的条目标记为“N/A”。原因可能是SySeVR采用BiLSTM来编码切片的源代码，导致其捕捉代码语义信息的能力有限。此外，VGDetector和CodeBERT均没有检测到任何CWE190漏洞。这个结果的主要原因是CWE190中的数据集数量较小，可能只包含有限的漏洞模式。此外，VGDetector没有检测到任何CWE476漏洞。一个可能的原因是VGDetector仅考虑了控制流信息，而CWE476与数据流信息密切相关。

### F.训练数据敏感性分析（RQ4）

在这个部分中，我们旨在了解不同数量的训练数据对我们提出的模型的有效性产生的影响。在其他研究问题中，我们将合并数据集的80%、10%和10%用于训练、验证和测试。在这个研究问题中，我们使用相同的验证和测试集，但分别使用合并数据集的70%和60%作为训练集来训练我们的方法。请注意，这两个较小的训练集是从原始训练集随机抽样得到的。正如在表XI中所示，随着训练集规模的减小，我们的方法在F1分数方面的表现下降，这是可以理解的。具体而言，当使用合并数据集的70%和60%进行训练时，F1分数分别从66.69%下降到65.68%和64.43%。然而，即使使用较少的训练数据，我们的方法仍然比所有基准模型至少高出28.08%（64.43%对比50.30%）。这表明我们的方法在不同数量的训练数据下都能始终表现良好。

### G.EPVD在现实应用中的有效性（RQ5）

为了调查EPVD在实际应用中的有效性，我们遵循之前的研究[28]，并使用两个开源项目收集到的数据集进行实验，即Redis数据集、Lua数据集和混合数据集。对于每个数据集，我们根据提交时间的升序对样本进行排序，使用前80%的样本进行训练，10%进行评估，10%进行检测。我们将EPVD与第V-C节介绍的基线方法进行比较。表十二显示了EPVD在实际项目中与基线方法的性能比较。EPVD在三个数据集上的F1值方面，至少超过了基线模型19.58%、20.21%和20.78%。根据我们的实验，我们发现有些模型无法在Lua和/或Redis数据集中检测到任何漏洞。我们在表十二中将相应的条目标记为"N/A"。在Lua数据集上，大多数基线方法的F1值是"N/A"。可能的原因是Lua数据集中漏洞数量较少且数据不平衡，阻碍了基线模型学习漏洞模式。这些结果表明EPVD在实际应用中比基线方法更有效。

### H.EPVD的效率（RQ6）

表格 XIII 列举了 EPVD 和 CodeBERT 在两个阶段的时间成本，即模型训练和漏洞检测。结果显示，EPVD 在这两个阶段所需时间比 CodeBERT 多。这是符合预期的，因为 EPVD 使用 CodeBERT 对代码片段的三个序列进行编码，并包含一个额外的 CNN 进行路径融合。具体而言，在合并的数据集上，EPVD 训练一个时期大约需要 1.25 小时。考虑到我们只需要训练一次 EPVD，并且训练是在离线环境中进行的，我们认为训练成本是可以承受的。EPVD 平均预测一个代码片段是否存在漏洞只需 0.02 秒，这意味着 EPVD 的效率对于实际使用是足够的。考虑到 EPVD 在检测性能方面大幅提高了 CodeBERT，如表 III 所示，我们认为 EPVD 的额外时间成本是值得的。我们将进一步研究如何提高 EPVD 的效率。

## VI、 讨论

在这个部分中，我们讨论EPVD可能失败的情况、所选路径的质量和代码覆盖率，以及对本工作有效性的威胁。

### A. 我们的方法失败在哪里

通过随机选择和手动分析一些EPVD未能检测到漏洞的样本，我们总结了几种EPVD很难处理的情况。首先，EPVD往往难以检测不与训练集中任何有漏洞样本相似的新漏洞。几乎所有基于学习的漏洞检测方法都面临这种情况。其次，EPVD无法检测跨函数漏洞。例如，如果被检测函数调用了一个有漏洞的函数，我们的模型很难检测出这种漏洞。对于EPVD来说，检测这种类型的漏洞可能存在挑战。我们将在未来的工作中尝试解决这个限制。第三，由于EPVD没有明确提取数据流信息，在检测与数据流密切相关的漏洞时可能无法达到卓越的性能。然而，正如在第V-E节中所示，EPVD在一些需要考虑数据流信息的漏洞类型上也优于所有基准线。我们认为这是因为分解的执行路径隐含着数据流信息，可以被CodeBERT所捕捉和编码。因此，我们认为对于与数据流相关的漏洞，EPVD也能提供帮助。我们将在改进EPVD以显式考虑数据流信息方面作为未来工作。

### B. 所选路径的质量和代码覆盖率

由于我们仅基于AST构建基于语法的CFG，并从中选择执行路径，因此我们的方法选择的某些执行路径可能是死路径，即在运行时永远无法执行的路径。为了获得代码片段的准确执行路径，我们需要编译代码并获得足够的运行时信息，这是昂贵且不太实际的。陈等人[3]提出了一种名为ContraFlow的新型漏洞检测模型，它采用静态分析器SVF [73]从源代码中提取一组值流路径，并利用自监督对比学习[74]对值流路径进行编码。然后，ContraFlow利用主动学习[75]选择最具代表性的路径，并采用软注意力[76]执行路径敏感分析并选择最具代表性的路径。与ContraFlow不同，EPVD利用贪心的路径选择方法从基于语法的CFG中选择代表性的执行路径，并利用CNN融合所选路径。

另一个值得一提的是，代码片段的选择执行路径可能无法覆盖其所有语句。这是可以预料的，因为我们只能选择有限的执行路径来在性能和效率之间做出权衡。虽然我们可以从基于语法的CFG中迭代选择执行路径，直到覆盖代码片段的所有语句，但我们认为这可能不会显著提高性能，而只会大大增加我们方法的训练和推理时间。例如，如第V-D节所示，通过增加所选路径的数量，我们的方法的F1-Score仅略有提高0.02%，但训练时间增加了37.47%。

### C. 威胁到有效性

这项工作的一个有效性威胁是我们的数据集只基于C/C++项目,这可能无法代表所有的编程语言。然而，大多数的CVE都发现在C/C++项目中，而我们的方法是通用的，可以扩展到其他编程语言。

另一个有效性威胁是我们由于硬件限制无法进行广泛的超参数优化。可能有些在表III、VI、VII和IX中提出的模型或基准模型会受到某些超参数（如学习率和批大小）的影响。这是使用深度学习模型的工作中普遍存在的问题，几乎对所有类似的实验都产生影响。为了减轻这个问题的影响，我们在CodeBERT中保持了超参数值的一致性。我们在重新复现基准模型时非常谨慎，以确保实验设置合理，并尽可能与相关论文和复现数据包中的描述相匹配。

## 七、结论和未来工作

在这项工作中，我们提出了一种新颖的方法，通过选择、编码和融合输入代码片段的多个基于语法的执行路径来学习检测漏洞。与现有的基于学习的漏洞检测方法相比，我们的方法通过将代码分解为多个执行路径，可以更好地区分与漏洞无关的信息和与漏洞相关的信息，更好地处理漏洞相关信息位于末尾的长漏洞代码，并从代码中有效捕获漏洞特征。我们将我们的方法与目前最先进的方法在三个高质量数据集中收集的超过231K个函数上进行了比较。实验结果表明，我们的方法显著优于所有基准线。为了促进未来的研究，我们还在Zenodo [27]上公开了我们的代码和工件。

在未来的工作中，我们计划在我们的方法中采用其他预训练的代码模型，如SPT-Code [39]和GraphCodeBERT [43]。我们还计划将我们的方法应用于其他需要对源代码进行编码的下游任务，如代码克隆检测和代码摘要。此外，我们计划通过明确考虑代码中的其他结构信息，如数据流和值流信息，来提高EPVD的效果。