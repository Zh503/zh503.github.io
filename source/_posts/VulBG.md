---
title: VulBG
date: 2024-05-06 09:05:44
tags:
  - 有代码
categories:
  - 学习笔记
  - 论文译文
---

## 文章信息

文献名:Enhancing Deep Learning-based Vulnerability Detection by Building Behavior Graph Model

github仓库:https://github.com/CGCL-codes/VulBG

## 摘要

随着现代软件的快速发展，由软件漏洞引发的安全事故日益增多，比如黑客攻击、僵尸网络攻击和用户信息泄露等，给软件系统带来了巨大严重的威胁。据报道，75% 的开源代码库 — 现代软件供应链中至关重要的组成部分 — 存在漏洞，其中一半的代码库包含高风险漏洞。因此，迫切需要开展大规模和准确的软件漏洞检测方法，以更好地保护软件安全，以及软件供应链。基本上，自动漏洞检测（VD）技术分为两类：动态分析和静态分析。众所周知，基于动态分析的VD方法存在时间开销和路径覆盖受限的问题。此外，动态方法通常需要运行要检查的系统。这些限制使其不适用于大规模的VD。相比之下，静态方法可扩展到大规模软件分析，但通常存在高误报和漏报。具体来说，基于相似性的静态分析在检测由代码克隆引起的漏洞时表现良好，但在检测其他错误时失败。基于模式的静态分析依赖于专家预定义的规则来识别漏洞。然而，这些规则需要不断更新以检测新的错误。最后，基于数据流的静态方法通常使用近似值来确保收敛，这保证了不会漏报，但会以高误报为代价。

近年来，由于深度学习（DL）可以自动从代码中提取特征，因此提出了各种基于DL的漏洞检测（VD）方法[4]，[5]，[6]，[7]，[8]，[9]，[10]，[11]，[12]，[13]，[14]，[15]，[16]，[17]，[18]并证明其有效性。为了实现可扩展的漏洞分析，一些方法将源代码视为文本，并将漏洞检测任务转化为自然语言处理（NLP）问题[4]，[5]，[8]，[9]，[16]，[17]，[18]。例如，VulDeePekcer [4]应用静态分析提取程序切片，并训练双向长短期记忆（Bi-LSTM）模型来检测切片级漏洞。实际上，虽然基于文本的VD方法可以实现高可扩展性，但由于忽略了程序语义，其检测性能并不理想。为了缓解这个问题，研究人员[10]，[11]，[12]，[13]，[14]，[15]，[19]试图提取中间表示，如抽象语法树（AST）和程序依赖图（PDG），以保留程序的细节。例如，Funded [19]首先进行复杂的程序分析以提取源代码的增强AST，然后使用图神经网络（GNN）训练漏洞检测器。由于考虑了程序语义，这些基于语义的方法在合成漏洞数据集上的性能优于基于文本的工具。然而，根据最近的一项研究[20]，不仅基于文本的方法，而且基于语义的方法在检测现实世界的漏洞时都表现不佳。

同时，我们还观察到几乎所有现有的基于DL的VD方法都将语义提取工作交给了神经网络（NN），很少进行代码特征的深入研究。这是不合适的，因为漏洞往往存在于函数的一小部分中。将整个函数传递给神经网络模型会引入与漏洞无关的大量信息。此外，现有方法将焦点限定在一个函数上，忽略了函数之间的潜在连接。一个函数是实现某些功能的代码集合。即使两个函数实现完全不同的功能，它们的子任务中可能存在共同的逻辑、算法和编程模式。此外，我们将代码中实现特定功能的逻辑、算法或编程模式定义为行为，并将每个函数视为一组行为。因此，函数之间的连接可以通过它们共享的行为来解决。一个漏洞可能存在于一个行为或一组行为中。通过利用函数之间的连接，可以更容易地检测到具有相似漏洞的函数。

在本文中，我们构建了一个行为图模型，用于连接不同函数的行为并利用它来增强现有基于深度学习的方法的检测能力。具体来说，我们首先执行程序切片，将一个函数划分为一组切片，并将每个切片视为函数的一种行为。然后，基于不同函数中不同程序切片（即行为）的相似计算构建了图形。在获得全局行为图之后，我们应用节点嵌入技术将每个节点（即函数）转换为作为函数的行为特征的向量表示。这些向量可用于增强现有基于深度学习的漏洞检测模型的能力。

为此，我们实现了一个名为VulBG的新框架。我们使用不同的真实世界数据集对VulBG进行评估：由[15]提出的具有45.6%易受攻击率的FFMpeg+Qemu数据集以及由[20]提出的具有9.7%易受攻击率的Chrome+Debian数据集。实验结果表明，我们提出的行为图模型使现有方法能够在平衡和不平衡数据集上检测到更多漏洞。此外，我们还将其与五种不同方法的五种最新基于深度学习的漏洞检测（VD）基准模型进行比较：基于文本的模型TextCNN[21]，基于AST的模型ASTGRU[22]，基于预训练的模型CodeBERT[23]以及基于图形的模型Devign[15]和VulCNN[24]，并在FFMpeg+Qemu数据集和Chrome+Debian数据集上进行评估。实验结果表明，行为图模型本身的性能足以击败其他模型。此外，在将我们的行为图模型应用于这些基准模型后，VulBG还能进一步提高所有基准模型的性能。

总的来说，本文做出了以下贡献：

• 我们提出了一种新颖的想法，可以从函数的源代码中提取抽象行为，并构建了一个行为图，将不同函数的行为相关联，以帮助漏洞检测。

• 我们实现了 VulBG 框架，通过将行为图与其他基于深度学习的漏洞检测模型相结合，提高了漏洞检测的性能。

• 我们评估了 VulBG，并选择了五个最先进的漏洞检测模型作为基准模型。实验结果表明，VulBG 可使所有基准模型都能检测到更多真实世界的漏洞。

论文结构。 本文的余下部分安排如下。第二部分介绍了我们论文的动机。第三部分介绍了我们的系统。第四部分报告了实验结果。第五部分讨论了未来的工作。第六部分描述了相关工作。第七部分总结了本文。

## 动机

漏洞是代码中可能导致安全问题的缺陷。尽管代码和漏洞种类各不相同，但漏洞之间存在内在的模式，这也是漏洞检测能够实现的原因。最先进的基于深度学习的漏洞检测方法通常遵循以下步骤：选择一种方法来表示函数，然后使用神经网络来学习漏洞的模式。

在现实世界中，函数往往具有复杂的逻辑，而易受攻击的语义通常只占函数的一小部分。给定一个函数作为输入，基于深度学习的漏洞检测模型需要学习许多语义，而找到易受攻击的语义就像在大海捞针一样困难。此外，函数之间也存在连接，例如代码重用和相似的实现，同样的漏洞可能存在于不同的函数中，但漏洞检测模型可能会被函数的差异所困惑。

我们以CVE-2018-17958 [25]和CVE-2018-17962 [26]为例来说明这个问题。这两个漏洞位于函数rtl8139 do receive和pcnet receive中，这两个函数在Qemu中为不同的网络卡实现接收功能。为了便于说明，我们简化与漏洞有关的函数逻辑，并在图1中展示了问题。这两个漏洞的原因都是函数使用了隐式类型转换将一个size t变量强制转换为int类型，可能导致整数符号溢出，然后在后续的memcpy中使用该变量而没有正确的边界检查。

![image-20240506094458648](https://s2.loli.net/2024/05/06/usLecyXAvtkU5ZY.png)

尽管这两个漏洞具有完全相同的逻辑，但函数的规模引入了干扰，使漏洞检测模型难以过滤出易受攻击的语义。这两个函数的规模分别为284行和160行，而这两个漏洞的规模分别为8行和10行。换句话说，只有不到5%的函数代码是与漏洞相关的，其他所有代码都是多余的。因此，提取易受攻击的语义并删除不相关的代码对于漏洞检测是有益的。

通过程序切片是提取脆弱语义的好方法，但基于切片的漏洞检测仍然存在问题。首先，用于生成精确切片的信息并非总是可用的。切片需要一个感兴趣点作为其入口。为了生成精确的切片，需要细粒度的信息，比如漏洞所在行、和漏洞相关的变量，但这些信息很难获得。静态分析工具的限制也使得获得精确切片变得困难。

根据Scvd [27]的说法，当前最先进的基于AST的静态分析工具Joern [10]在解析一些语句时会失败，且不能正确处理宏。基于编译的静态分析工具在为包含数千个函数的数据集生成切片时具有难以接受的时间开销。其次，尽管NN模型能够从漏洞切片中学习模式，但它仍需要读取整个功能进行检测，其中脆弱语义是离散的。因此，我们需要另一种方法来提取脆弱语义。

此外，这两个函数之间存在潜在的连接，因为它们具有相似的功能，并且两个漏洞的原因相同。然而，这两个函数的相似性较低。两个函数大小的比例是1.8比1，两个函数之间的余弦相似度为21%（函数通过tf-idf [28]向量化）。在这种情况下，基于相似性的VD方法可能无法识别这些漏洞。因此，除了相似性之外，需要提出代表函数之间连接的方式。

为了提取脆弱语义并解决函数之间的连接，我们提出使用行为图来辅助DL-based VD。我们首先尝试通过语义进行函数分割，并提取函数的抽象行为。通过在潜在的脆弱操作上进行切片，我们可以将函数拆分为部分。每个切片包含函数的一部分语义，因此我们将其视为函数的一个行为，然后函数可以由一组行为表示。在这种情况下，漏洞可能存在于函数行为的一个子集中。尽管我们尚不能确定哪个集合包含脆弱语义，但不太可能包含漏洞的语句已被过滤掉。

![image-20240506094521737](https://s2.loli.net/2024/05/06/zgrb4NXt1w7kCJV.png)

为了进一步识别漏洞语义并处理功能之间的连接，我们基于函数的行为构建了一个图形。通过计算行为的相似性，我们可以找出行为之间的连接，通过将行为与对应的函数连接起来，我们可以找出具有相似行为的函数。通过这种方式，函数之间的连接被建立。此外，对于那些“无害”的行为，不会导致漏洞的行为，会有从非脆弱函数连接到它们，以澄清它们的无害性。对于可能导致漏洞的行为，会有更多从脆弱函数连接过来的边。

我们以图2为例。与脆弱函数连接更多的行为，就越有可能包含漏洞语义（例如，行为3比行为5更有可能包含漏洞语义）。具体来说，行为1可以被视为“无害”，因为许多非脆弱函数也具有这种行为。对于行为3和4，它们可能被认为包含有漏洞语义，因为有脆弱函数共享这些行为。对于行为5，它是一种罕见的行为，因为没有其他函数具有这种行为。我们无法确定它是否会导致漏洞，但通过向行为图添加更多函数来减少异常值，可以消除这种限制。借助行为图的帮助，我们可以自动识别哪组行为可能存在漏洞，并通过函数之间的连接来解决类似漏洞。

一般来说，为了帮助筛选出易受攻击的语义并解决函数间的连接关系，我们提出了行为图的概念，并基于行为图设计了VulBG，以增强漏洞检测的能力。

## 系统结构

在这一部分中，我们介绍如何构建行为图并将其用于设计VulBG以增强基于DL的虚拟设备。 概述如图3所示，VulBG由三个阶段组成：行为图构建、行为特征提取和模型融合。

![image-20240506094435467](https://s2.loli.net/2024/05/06/eXPip5g7kKLdC1Z.png)

B. 概述

• 行为图构建：给定函数的源代码，我们首先使用切片和代码嵌入来得到函数的行为。通过对行为进行聚类，我们得到一组中心行为，然后基于中心行为和行为的相似性来构建行为图。

• 行为特征提取：为了利用行为图的结构信息，我们对每个函数节点应用图嵌入来将其转换为一个向量，然后使用多层感知器（MLP）进一步处理函数的行为特征。

• 模型融合：为了利用行为特征来增强现有的基于DL的虚拟设备模型（例如TextCNN、ASTGRU、CodeBERT、Devign和VulCNN），我们使用模型融合将行为特征与上述模型提取的特征结合起来进行分类。

B. 行为图构建

VulBG旨在利用函数间的连接关系来提高漏洞检测的准确性。我们提出了行为图的概念，用于表示函数的行为特征。具体来说，行为图由函数节点和行为节点组成。函数节点来源于训练数据中的函数，而行为节点是切片的聚类中心。对于属于一个函数的每个切片，都有一条边将其对应的聚类中心（行为节点）连接到函数节点。

图4展示了一个由三个函数和三个中心行为组成的简单行为图示例。行为图中有两种节点类型：中心行为节点（黄星）和函数节点（蓝星）。我们以函数1（F1）为例介绍行为图的构成。在图4(a)中，F1有两种行为（B1、B2），分别属于中心行为1（CB1）和中心行为3（CB3），因此在行为图中有两条边，一条连接F1与CB1，另一条连接F1与CB3。示例中的F3也分别连接到CB1和CB3，因此通过这两个共享的中心行为建立了F1和F3之间的连接。此外，边的权重是行为与它们对应的中心行为之间的距离。

![image-20240506094610601](https://s2.loli.net/2024/05/06/RBm9PI5nflFADdb.png)

图5和算法1描述了构建行为图的详细过程。主要包括四个阶段：代码切片、嵌入、聚类和图构建。为了构建图，我们首先提取大量函数的行为，然后对它们进行聚类，以获取一组代表所有行为的中心行为。通过用函数拥有的行为来表示函数，我们可以将函数与中心行为连接起来，从而构建行为图并清晰地建立函数之间的连接。

![image-20240506094734044](https://s2.loli.net/2024/05/06/FzZatYbShXK7mjQ.png)

![image-20240506094801647](https://s2.loli.net/2024/05/06/cmBJ5ElfWZGtRDk.png)

1) 代码切片
为了了解函数的行为，我们利用程序切片将函数分解成各个部分。程序切片是一种广泛使用的静态分析技术，只提取与某些关注点相关的语句，从而消除我们不关心的语句的干扰。由于易受攻击的语义通常存在于特定的操作中（如内存访问和危险的API调用），对这些操作进行切片可以淘汰不太可能有漏洞的代码，并将VD集中在潜在有漏洞的代码上。因此，在漏洞检测的上下文中，切片是描述函数行为的一种好方法。
SySeVR [8] 提出了一组包括四种操作（即API调用、指针操作、数组操作和算术操作）的漏洞语法特征，这些操作更容易导致错误。基于这些类型的操作，我们制定了以下切片规则：
- API调用：特定库的API函数调用，包括与内存分配器相关的API、字符串操作和内存操作的API。对这些API的误用可能导致各种漏洞，如缓冲区溢出、使用已释放的内存和信息泄漏。我们对函数调用的所有参数进行反向切片，并对其返回值进行正向切片。
- 内存操作：对指针类型变量和类似数组的变量进行的操作，包括SySeVR的语法特征中的指针操作和数组操作。这种操作是内存破坏（如空指针解引用和越界访问）的主要原因。对于这种操作，我们对指针类似的变量进行反向切片。如果内存访问是由一个变量索引的，我们还对这个变量进行反向切片。

对于算术运算，我们不直接切片这种类型的操作。在漏洞检测中，检查算术运算是为了找出可能发生整数溢出或被零除的操作。整数溢出并不总是导致漏洞，但当溢出变量在某些内存访问中被使用时，将导致越界访问，并且在敏感API中使用溢出变量可能会导致逻辑错误。由于我们已经切片了内存操作和API调用，大多数有问题的算术操作已经包含在切片中，所以不需要单独切片算术运算。另外，程序中几乎每一行代码都包含算术运算，切片算术运算会引入与漏洞无关的噪音。

我们基于Joern [29]实现程序切片。切片所需的数据流依赖性和控制流依赖性通过Joern提供的PDG和CFG获得，规则中操作涉及的变量是通过Joern的查询结果获得的。对于要切片的每个变量，我们向前或向后遍历CFG以根据数据流依赖性收集语句和变量，涉及数据流依赖的变量也将稍后被切片。如果分支语句如“if”、“for”和“while”是切片代码的后支配者/前支配者，它们将被包含在前向/后向切片中。如果这些分支语句中的变量与被切片变量没有数据流依赖，那么这些变量将不被切片。

我们以文本形式表示切片，而不是使用SySeVR [8]的PDG子图。实验证明，95.8%的切片含有不到64个单词，因此不需要使用图形来表示切片，因为图形的复杂度较高。

2) 嵌入

在代码切片后，我们可以获得函数的行为方式。由于函数的行为是代码切片，它们以文本形式存在。我们可以使用模式匹配算法（如 K.M.P [30]）来描述相似性，但将其实现在聚类算法中是困难的，因为它忽略了代码切片中的语法和语义特征。为了使后续处理更灵活方便，我们选择使用文本嵌入算法将行为转换为向量。在我们的论文中，我们使用 CodeBERT [23] 来嵌入这些行为。首先，CodeBERT 是建立在一个双向转换器上的，可以捕捉代码序列之间的长距离依赖关系。它可以保持上下文之间的关系，收集潜在的易受攻击的代码模式，并最小化信息损失。其次，CodeBERT 继承了多头注意力的结构，使模型能够关注代码序列的多个关键点。因此，在处理循环条件时，CodeBERT 比其他嵌入算法（如 Word2Vec [31]）表现更好。此外，[32] 显示了即使没有微调，CodeBERT 在代码分类方面表现出色，因此 CodeBERT 是我们这种情况的最佳选择。CodeBERT 将每个单词嵌入到一个有 768 维度的向量中，这对于后续处理来说太笨重了。我们使用汇聚结果将每个行为（代码切片）转换为一个有 768 维度的向量，以减小嵌入大小。

3) 聚类

将行为嵌入到向量中后，我们可以构建一个行为图。然而，这个图可能非常庞大，所携带的信息较粗略，因此存储和处理起来较为困难。为了减少节点数量并使信息更为集中，我们使用聚类方法提取中心行为。在我们的论文中，我们使用MiniBatchKMeans [33]对向量进行聚类。MiniBatchKMeans是K-Means [34]的一种优化变体，用于聚类大量数据，它是一种无监督聚类算法，试图通过最小的簇内方差将样本分配到K个簇中。

4) 图构建

行为图是通过连接函数与其行为对应的中心行为而获得的。由于行为之间存在差异，我们将边的权重设置为行为的相似度，以保留这些信息。两个行为的相似度取决于它们的嵌入结果的接近程度。我们可以使用行为和其相应中心行为之间的距离来表示它们的相似度。在我们的论文中，我们使用欧氏距离 [35] 来描述行为和中心行为的相似度。

C.行为特征提取

为了高效地利用函数行为信息和行为图中函数之间的关联信息，我们采用图嵌入方法将节点转化为向量。使用图嵌入来表示行为图有以下几个好处：

• 在向量上进行计算比直接操作图更简单和更快速。

• 图中节点和边的信息只能通过数学和统计学进行表示和计算。通过嵌入，图的信息可以在向量空间中更加灵活地处理。

特别地，我们利用一种广泛使用的工具（例如Node2Vec[36]）进行嵌入。Node2Vec是一种图嵌入方法，它使用带有深度优先搜索（DFS）和广度优先搜索（BFS）的偏置随机游走过程来探索邻域。BFS部分可以准确地通过探索源节点周围来获取网络的微观视图，而DFS部分可以进一步获取网络的宏观视图。Node2Vec将随机游走的结果视为单词，并利用Word2Vec进行嵌入。这是一种简单但高效的无监督学习目标，用于训练图的分布式表示。在我们的论文中，我们使用Node2Vec将行为图中的函数节点转化为一个128维的向量进行进一步处理。
为了进一步处理图向量，我们构建了一个四层MLP分类器，以图向量为输入，并使用其最后一个隐藏层的输出作为行为特征进行融合。这个行为图模型由四个线性层组成，使用ReLU作为激活函数，丢弃率为0.5，学习率为0.0001。这个模型还将用于评估行为图的漏洞检测能力。

![image-20240506095350779](https://s2.loli.net/2024/05/06/Wk4S97he8PT6EYl.png)

D.为新样本预测行为特征

为了将行为图模型应用到实践中，模型应该能够预测新函数的行为特征。如图7所示，整体预测过程与图5中描述的训练过程相同，唯一的区别在于在图嵌入步骤中使用了修正后的Node2Vec来获取新节点的向量。

![image-20240506164854279](https://s2.loli.net/2024/05/06/Sf9FW1pkDX5yegC.png)

我们修改了Node2Vec，使其能够在进行预测时表示新节点。对于每个需要被嵌入的新函数节点，我们暂时将其添加到图中，并使用新节点作为入口进行随机游走。然后我们将游走的结果传递给Word2Vec，并利用其在线更新能力来学习新节点的表示。之后，新节点就会从图中移除。与图中大量旧节点相比，每次预测只需要添加一个新节点，而它对图结构的影响很小。此外，随机游走可以并行化，Word2Vec的在线更新可以进行批处理，这样在进行大量预测时就不会消耗太多时间。

E. 融合

由于现有基于深度学习的漏洞检测方法忽略了函数之间的关联，我们的目标是将行为特征应用于它们，以提高漏洞检测能力。在模型融合中，我们将行为图模型的最后一个隐藏层的输出与现有基于深度学习的漏洞检测方法的最后一个隐藏层的输出连接起来，最后使用一个线性层进行输出。图6展示了模型融合的过程。虽然这种融合方法很简单，但尽量减少对其他模型的修改，使VulBG具有很高的可扩展性。

为了证明VulBG的效果，我们选择了四类中的五个最先进的基于深度学习的漏洞检测方法作为基线：基于文本的TextCNN [21]，基于AST的ASTGRU [22]，基于预训练的CodeBERT [23]，基于图的Devign [15]，以及VulCNN [24]。

对于TextCNN，CodeBERT和ASTGRU，我们重新实现了基线模型，并在我们的论文中报告了最佳性能。所有重新实现的基线模型使用学习率为0.0001，批量大小为32，交叉熵损失作为损失函数，Adam作为优化器。对于Devign和VulCNN，我们直接使用它们的开源代码来开始我们的实验。

1) TextCNN

TextCNN 是一个简单的卷积神经网络（CNN），它利用 1d 卷积层从源代码的嵌入中提取特征。该模型将漏洞检测视为一项纯自然语言处理分类任务，因此其结构简单，训练速度快。在我们论文中对 TextCNN 的实现中，使用了 Word2Vec 进行文本嵌入。对于 1d 卷积层，我们选择了三种不同的滤波器大小（3、4、5），每种大小有 100 个滤波器用于提取源代码不同部分的特征。接下来我们使用四个线性层来处理这些特征，并输出漏洞的概率。TextCNN 基线采用 tanh 作为激活函数，丢失率为 0.3。

2) ASTGRU

ASTGRU 使用 AST 作为模型的输入，而不是源代码。它也是一种基于树的模型，从源代码中提取 AST，遍历树来获得输入序列。然后使用 Word2Vec 对序列进行嵌入，使用双向门循环单元（Bi-GRU）来学习代码的特征。ASTGRU 基线由两个 Bi-GRU 层和一个线性层组成，采用 ReLU 作为激活函数，丢失率为 0.2。

3) CodeBERT

正如在第三部分 III-B1 中所描述的，CodeBERT 学习编程语言的表示并支持不同的下游任务。在这里，我们采用了使用 BERT [37] 模型用于序列分类的方法，并在 CodeBERT 池化结果后添加线性层进行分类。我们使用的预训练模型是 codebert-base [38]，由于其巨大的内存和时间消耗，在训练过程中没有对其进行微调。CodeBERT 基线使用两个线性层来进一步处理代码的嵌入，并使用 ReLU 作为激活函数，dropout 率为 0.3。

4) Devign

Devign 是一种基于图的 VD，包括三个连续的组件：1）图嵌入层，将函数的源代码编码为具有全面程序语义的联合图结构；2）门控图循环层，利用门控循环单元（GRU）层学习图中节点的特征，通过汇总和传递相邻节点上的信息；3）卷积模块，包括一个卷积层和一个 softmax 层，用于提取用于图级预测的节点表示。

5) VulCNN

VulCNN 使用 Joern [29] 和 Sent2Vec [39] 从源代码生成 PDG。它在 PDG 上计算度中心性、Katz 中心性和接近中心性。基于这三种中心性，VulCNN 生成三个向量，并将它们视为图像的三个通道。然后使用 CNN 完成分类任务。

## 实验评估

在本节中，我们的目标是回答以下研究问题：

• RQ1：行为图在漏洞检测中的性能如何？

• RQ2：VulBG在改善最先进模型在漏洞检测方面的性能方面有效吗？

• RQ3：在漏洞检测中，使用不同代码嵌入方法和图嵌入技术的VulBG的性能如何？

### A. 实验设置

1）数据集

我们使用FFMpeg+Qemu和Chrome+Debian数据集来评估我们的工作。数据集的统计信息如表一所示。FFMpeg+Qemu数据集是一个平衡的数据集，已经在许多先前的研究中使用过[15]，[20]，[40]。它包含了两个流行的实际软件，用C语言编写，提供了超过25,000个函数，其中45.56%存在漏洞。Chrome+Debian数据集是由ReVeal提出的一个不平衡的数据集[20]。它包含了来自Chromium和Debian源代码仓库的代码，具有超过21,000个函数，其中9.79%存在漏洞。

对于每个数据集，我们将其随机分为80%的训练集，10%的验证集和10%的测试集。对所有后续的实验，我们使用相同的数据集划分。由于Chrome+Debian数据集存在严重的不平衡，我们使用过采样方法来重新平衡这个数据集的训练集。

![image-20240506100054405](https://s2.loli.net/2024/05/06/5EoSek3Kpi8dMWf.png)

2) 性能指标

我们将精确率（P）、召回率（R）和F1值（F-measure）视为主流的性能指标。以下是指标的计算公式，其中真阳性（TP）是正确检测为易受攻击的样本的数量，假阳性（FP）是错误地将非易受攻击的样本检测为易受攻击的数量，真阴性（TN）是正确检测为非易受攻击的样本的数量，假阴性（FN）是错误地将易受攻击的样本检测为非易受攻击的数量。

![image-20240506100448790](https://s2.loli.net/2024/05/06/qCbYNud5xaoHAyc.png)

3) 环境

我们在一台拥有32个CPU核心和一块RTX 5000 GPU的服务器上运行所有实验。在中间阶段中，我们基于Joern [29]实现了切片阶段，基于Scikit-learn [41]进行聚类，基于改进的Node2Vec [36]进行图嵌入，基于Word2Vec [31]和CodeBERT [23]进行词嵌入。我们基于PyTorch [42]构建和训练模型。

### B. 聚类参数选择

 在构建行为图时，使用MiniBatchKMeans进行聚类，其性能很大程度上取决于输入的超参数K，该参数定义了类别的数量。我们应用“肘部法”[43]来找出最适合的K值。肘部法是一种常用的启发式方法，通过找到变化曲线的“肘部”来确定聚类的数量，在本文中我们将畸变作为变化度量标准。
 图8显示了MiniBatchKMeans的畸变曲线随K变化的情况，对于FFMpeg+Qemu数据集和Chrome+Debian数据集，K分别为1140和1150时出现了“肘部”。为保持一般性，我们选择1140作为接下来实验的最佳K值。

![image-20240506100329747](https://s2.loli.net/2024/05/06/KFyqP2lzs6VMXU7.png)

### C. Performance of Behavior Graph

在这一部分，我们旨在回答RQ1：行为图在漏洞检测中的表现如何？

为了证明行为图的表现，我们首先评估了第三节-B4中描述的以行为特征为输入的行为图模型。我们还将我们的行为图模型与基于文本、基于AST、基于预训练和基于图的五种最先进的方法进行了比较。实验结果显示在表II中。

![image-20240506102033599](https://s2.loli.net/2024/05/06/8JLaogubnQVBZqt.png)

总的来说，我们的行为图模型取得了较高的F1（56.1%）和召回率（61.2%）。就F1和召回率而言，在这六种方法中，它在FFMpeg+Qemu数据集上排名第一，在Chrome+Debian数据集上排名第二，这已经证明了行为图在漏洞检测中的良好表现。

除了我们的行为图模型外，基于图的模型通常比其他方法表现更好，因为基于图的模型考虑了程序的语法、数据流和控制流特征。基于AST的方法ASTGRU处理代码的语法并将树结构用作模型输入，但实验结果表明它不如基于文本的模型TextCNN 效果好。令我们惊讶的是，TextCNN 在不平衡数据集上表现特别出色，达到了40.2%的F1。与行为图模型相比，TextCNN 的精确率高出3.8%，召回率相似，这使得它在F1方面具有整体性能优势。

由于我们在构建行为图时使用了CodeBERT来嵌入片段，我们还将CodeBERT分类器与行为图模型进行了比较，以展示CodeBERT的有效性。如表II所示，CodeBERT分类器的F1为53.2%，与TextCNN 相似。尽管CodeBERT分类器的表现并不出色，我们认为其表现受限的主要原因是CodeBERT无法处理大型函数：CodeBERT只能处理最多512个字的代码片段，对于更大的函数，由于截断可能会丢失脆弱的语义，因此直接使用CodeBERT进行整个函数的漏洞检测是不合适的。

我们观察到行为图模型具有较高的召回率（61.2%和59.3%），但其精确度并不高（51.8%和26.4%）。这意味着它在发现漏洞方面表现良好，但有时会错误地将一些非漏洞函数判断为漏洞。这个结果的原因如下：

• 行为图所涉及的行为之间的关系可以显示出类似的漏洞语义，使得多层感知器在检测漏洞函数方面表现良好，召回率高。

• 一些非漏洞函数与漏洞函数有相似的行为，导致误报，因此精确度不太好。

总而言之，行为图模型在平衡和非平衡的数据集上都表现良好，证明了行为图对于漏洞检测具有有用信息。

### D.行为图改进

在本节中，我们旨在回答RQ2：VulBG在改善最先进的模型在漏洞检测方面的性能方面有多有效？

为了回答这个问题，我们根据第III-D节的内容，将VulBG应用于五种最先进的方法，并分别将这些模型的性能与不使用行为图的情况进行比较。

![image-20240506102410454](https://s2.loli.net/2024/05/06/Hynm1e7zZrabN26.png)

实验结果如表III所示，每个指标的变化都列在得分下面。根据表III，所有融合模型的F1和召回率都更高。在FFMpeg+Qemu数据集上，除了BG+TextCNN的准确率外，每个模型的所有指标得分都更高；而在Chrome+Debian数据集上，除了BG+CodeBERT的召回率下降外，每个模型的所有指标也都有所改善。

对于BG+TextCNN，其在FFMpeg+Qemu数据集上的F1提高了6%，召回率显著提高了15.7%。尽管准确率下降了3.1%，但BG+TextCNN融合模型总体上取得了更好的结果。准确率下降的原因是，行为图的准确率不高，而TextCNN基准模型在所有基准模型中达到了最高的准确率（57.9%），因此模型的融合可能导致准确率的平均化。在Chrome+Debian数据集上，BG+TextCNN的所有指标都有3.5%至4.6%的改善，由于TextCNN基准模型的高性能，融合模型在F1方面排名第一，达到了44.4%。对于BG+ASTGRU，融合模型在这两个数据集上的所有指标都有提高，改善主要体现在召回率上，分别提高了5.0%和9.1%。

对于BG+CodeBERT模型，在两个数据集上，融合模型的F1分数分别提高了5.3%和7.8%。而在Chrome+Debian数据集上，召回率下降了23%。CodeBERT基准模型的召回率为80.2%，而精确率仅为14.6%，这意味着CodeBERT模型几乎将所有样本都判断为有漏洞。在这种情况下，80.2%的召回率是异常的，而融合模型召回率的下降是合理的。对于基于图的模型，在两个数据集上，融合模型在所有指标上的性能都更好。在FFMpeg+Qemu数据集上，BG+Devign的F1、精确率和召回率分别为60.2%、55.9%和65.2%，是平衡数据集上表现最好的模型。在Chrome+Debian数据集上，BG+Devign的召回率显著提高了14.2%，精确率也增加了4.3%，使得F1分数提高了7.9%。

总体来说，VulBG对于改善基于深度学习的漏洞检测模型的性能有显著影响。在FFMpeg+Debian数据集上，平均而言，F1、精确率和召回率分别提高了4.2%、0.1%和8.7%；在Chrome+Debian数据集上，分别提高了6.5%、5.3%和1.7%。高召回率使得基于深度学习的漏洞检测模型能够找到更多漏洞，而更高的F1分数也证明了VulBG能够改善不同模型的整体性能。

### E. 消融实验

在这一节中，我们的目标是回答RQ3，研究在VulBG中所需的代码嵌入和图嵌入技术的有效性，并找出VulBG最合适的组件。VulBG需要使用代码嵌入将片段转换为向量以进行更好的相似性计算，并需要使用节点嵌入从行为图中提取行为特征。我们选择了不同的代码嵌入和图嵌入方法，然后在FFMpeg+Qemu数据集上重新训练本文第III-B4节中描述的模型。

1）代码嵌入
我们评估了Word2Vec [31]、CodeBERT [23]和Sent2Vec [44]三种代码嵌入方法。Sent2Vec是一种广泛使用的句子嵌入方法，采用简单而高效的无监督目标来训练分布式表示句子的模型。Word2Vec是一种经典的基于连续词袋（CBOW）模型或Skip Gram模型的无监督词嵌入模型。

对于这三种方法，我们使用了默认的嵌入维度，并使用平均池化的结果来表示片段。我们分别重新训练和调整了模型，实验结果如表IV所示，使用CodeBERT进行代码嵌入的BG表现优于其他方法。因此，在VulBG中，我们采用了CodeBERT作为代码嵌入方法。

![image-20240506104627662](https://s2.loli.net/2024/05/06/grl9ZycoDQzqemR.png)

2) 图嵌入

我们选择了两种广泛使用的图嵌入技术：Node2Vec [36] 和 ProNE [45]，来研究它们在行为图上的性能。在第 III-B4 节中已经提到了 Node2Vec，ProNE 是一种快速且可扩展的网络嵌入方法，它将网络嵌入建模为稀疏矩阵分解。这两种方法都设置了相同的输出维度，并且在代码切片嵌入步骤中使用了 CodeBERT。需要注意的是，ProNE 的实现不支持加权边，因此在使用 ProNE 时将行为图的边权重移除。经过分别重新训练和调优模型后，表格 IV 显示 Node2Vec 在行为图模型中的性能超过了 ProNE。因此，我们在 VulBG 中使用了 Node2Vec。

五、讨论

A. 效度威胁

数据集。我们使用的两个真实世界数据集中的每个样本只包含一个函数，没有结构定义和宏定义。在我们的实验中，我们发现Joern可能会生成只有一个节点的错误PDG。当函数定义被包含在一个宏中时，就会发生这种情况，导致返回类型和参数类型缺失或函数名中有“##”。在这种情况下，Joern无法解析该函数，并且无法进行进一步的分析。为了尽可能保留更多的样本，我们尝试用固定字符串替换这些函数名并删除所有参数。这种解决方案会导致在遇到函数参数时分析无法继续。数据集中还包含格式错误的函数，如括号不匹配和没有闭合的“#if def”宏。我们会删除无法由Joern处理的函数，并对剩下的数据集进行实验。原始数据集的大小分别为FFMpeg+Qemu数据集的27,318，Chrome+Devign数据集的22,734，在进行了清理后，大小分别为25,524和21,059，如IV-A1节所述。

B. 局限性和潜在解决方案

PDG生成

我们工作中的程序切片阶段依赖于Joern生成的PDG。我们发现PDG中存在缺失边的问题，这会导致切片结果不准确。要生成完整的PDG，需要进行指针分析和其他数据流分析，但这些高级静态分析技术都是基于编译期间生成的中间表示（IR）来工作的。由于数据集中的代码不可编译，所以这些技术无法使用。基于PDG的其他基于深度学习的方法也面临这个问题，但目前还没有解决方案。最佳解决方案是构建一个可编译的数据集，以便后续的研究可以使用基于IR的分析技术。此外，IR更适合进行分析，因为它具有简化的语义信息的整洁形式，而AST主要关注语法。LLVM [46]提供了精确的基于IR的PDG生成，如果数据集符合其要求，将会很有帮助。

行为图

我们使用潜在脆弱操作的切片来表示函数的行为，但也有其他将函数分解的方法，比如使用函数的路径。此外，我们将行为图中边的权重设置为行为之间的相似性，并使用欧几里得距离作为相似度度量，这是一种相当简单的方法。通过改变权重度量的方法，行为图可以处理其他信息。

C. 行为图的好处

行为图的好处主要有两个方面。首先，具有相似切片的函数可以很容易地归为一组。其次，在行为图中与相应聚类中心连接的边的数量可以得出切片的重要性。在训练过程中，可以区分可能导致漏洞的切片类别。

作为一个以函数级别为单位的模型，VulBG 输出函数中是否存在漏洞。最近也提出了基于行级别的方法，首先使用检测模型检测漏洞，然后再使用额外的解释模型来定位漏洞，例如 IVDetect [47]、LineVul [48] 和 LineVD [49]。VulBG 也可以应用于这些可解释方法的检测模型中，以检测更多漏洞，然后再利用解释模型获得可解释的结果。

在未来的工作中，我们将对行为图的可解释性进行研究，希望通过研究函数的行为特征来在切片级别上定位漏洞，这将更有助于实践者发现 Bug。在行为图中，有两个指标可以用于解释输出：
- 行为图中边的权重代表函数行为与中心行为的相似性。当一组行为与漏洞具有很高的相关性时，与中心行为的相似性可能指示潜在的易受攻击切片。
- 在节点嵌入后，我们可以计算新函数节点到行为图中已知易受攻击函数节点的距离，这有助于指出这些新函数中 Bug 遵循的模式。

E. 对其他数据集的扩展

通常，VulBG并非针对特定的编程语言或源代码数据集进行设计。它可以通过轻微修改轻松地扩展到任何其他C/C++数据集（例如，NVD数据集[50]）。对于其他语言，用户可能需要根据语言特性调整切片规则，并切换到支持该编程语言的切片工具。然而，在真实场景中找到大量的漏洞始终是困难的。因此，在如何在仅有少量训练数据的情况下保持高检测性能方面是一个有价值的课题。在未来的工作中，我们将尝试在VulBG上应用少样本学习，以使其在真实场景中更加有效。

## VI. 相关工作

目前，可用的漏洞检测系统可以分为以下三类：静态漏洞检测、基于相似性的漏洞检测和基于机器学习的漏洞检测。至于静态漏洞检测，许多传统的程序分析工具或漏洞检测系统都是基于这种方式开发的（例如，Checkmarx [51]、RATS [52]和FlawFinder [53]）。这些工作首先需要人工专家确定检测规则，然后基于传统的静态分析理论（如数据流、抽象解释和污点分析）对程序进行分析。这些工作已被广泛应用，并证明它们能够发现各种软件系统中的漏洞。然而，这些工作存在以下不足之处：它们严重依赖于检测规则，因此无法检测未涵盖在检测规则中的漏洞。为了摆脱检测规则，基于相似性的漏洞检测应运而生。这类工作通过计算待测试样本与具有漏洞样本之间的相似性来检测漏洞。当相似性超过阈值时，样本被识别为易受攻击的。由于函数的源代码可以被视为一段文本[54]，[55]，一系列令牌[56]，[57]，一棵树[58]，[59]，甚至是一个图[60]，许多不同的方面[61]可以衡量函数的相似性。这些工作可能不再需要检测规则，但仍然需要人工专家确定易受攻击的样本。因此，它们只能找到克隆的漏洞，而无法找到新的漏洞[4]。基于机器学习的漏洞检测方法[4]，[5]，[6]，[7]，[8]，[9]，[10]，[11]，[12]，[13]，[14]，[15]，[16]，[17]，[18]已被证明在检测新的漏洞模式方面表现更好。这些工作可以分为两个子类。1) 这些工作将源代码视为一段文本，将漏洞检测转化为文本分类问题，并使用自然语言处理的解决方案来解决该问题[4]，[5]，[6]，[7]，[8]，[9]，[16]，[17]，[18]。2) 这些工作通过静态分析从源代码的抽象语法树构建程序依赖图，然后将漏洞检测任务转化为图或节点分类任务，并使用图神经网络来实现目标[10]，[11]，[12]，[13]，[14]，[15]。总的来说，VulBG属于第二类解决方案。与其他方案的不同之处在于，VulBG将所有样本放入一个图中，而不是将每个样本转化为一个独立的图。通过这样做，VulBG可以找到样本之间的联系。总结一下，VulBG提出了一种描述函数之间连接并通过构建行为图模型增强其他基于深度学习的漏洞检测方法的新概念。

## 结论

本文提出了一种新颖的方法，可以提取函数的行为，然后构建一个行为图来表示不同函数之间的连接。我们设计并实现了 VulBG，这是一个用于通过将行为图与其他基于 DL 的漏洞检测方法相结合来提高性能的框架。对两个真实数据集的评估结果表明，行为图本身已经足够用于漏洞检测，而 VulBG 进一步有效提高了不同类型 DL-based 漏洞检测方法（如 TextCNN、ASTGRU、CodeBERT、Devign 和 VulCNN）的整体性能。
