---
title: REGVD2
date: 2024-04-22 09:53:28
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

# ReGVD

来源：In 44th International Conference on Software Engineering Companion (ICSE ’22 Companion),

源代码：https://github.com/daiquocnguyen/GNN-ReGVD

代码基于CodeXGLUE -- Defect Detection进行调整源代码：https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Defect-detection

数据集来源文章：[*Devign*: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks](http://papers.nips.cc/paper/9209-devign-effective-vulnerability-identification-by-learning-comprehensive-program-semantics-via-graph-neural-networks.pdf)

数据集地址：https://drive.google.com/file/d/1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF/view?usp=sharing

将漏洞检测视为一个归纳文本分类问题，提出基于图神经网络的ReGVD模型

目标是开发一个通用的、实用的、与编程语言无关的模型，

ReGVD将每个原始源代码视为令牌的平面序列以构建图，其中节点特征仅由预训练的编程语言（PL）模型的令牌嵌入层初始化。然后，ReGVD利用GNN层之间的残差连接，并检查图级总和和最大池的混合，以返回源代码的图嵌入

在CodeXGLUE的真实世界基准数据集上获得了最高的漏洞检测精度。

## 引言：





将每个原始源代码视为一个平坦的自然语言序列，其中CodeBERT[5]等预训练编程语言（PL）模型提高了PL下游任务（如漏洞检测）的性能。

**Transformer模型是由谷歌公司提出的一种基于自注意力机制的神经网络模型，用于处理序列数据。相比于传统的循环神经网络模型，Transformer模型具有更好的并行性能和更短的训练时间，因此在自然语言处理领域中得到了广泛应用。**

**BERT（Bidirectional Encoder Representations from Transformers）是一种预训练模型，它是自然语言处理（NLP）领域的重大里程碑，被认为是当前的State-of-the-Art模型之一。BERT的设计理念和结构基于Transformer模型，通过无监督学习方式进行训练，并且能够适配各种NLP任务。**

**预训练模型是指在大规模文本数据上进行大量无监督训练，学习得到丰富的语言表示。BERT的预训练任务是通过掩码语言模型（Masked Language Model, MLM）和下一句预测（Next Sentence Prediction, NSP）两个阶段进行的。在MLM中，输入文本的一部分被随机掩码，模型需要预测这些被掩码的词。在NSP中，模型需要判断两个句子是否是原文中的连续句子。**



在BERT风格模型的自注意层内，输入序列中所有位置之间的所有交互都建立了一个完整的图，即每个位置都有一条到所有其他位置的边；因此，这限制了在源代码中学习局部结构以区分漏洞。

图神经网络（GNN）最近已成为将节点和图嵌入低维连续向量空间的主要方法

Devign利用门控GNN[14]进行漏洞检测，其中Devign使用PL解析器来提取多边缘图信息，但是每个预训练编程语言（PL）都没有一个完美的解析器，它可以成功地解析各种源代码和库，而不会出现任何内部编译错误和异常。

ReGVD:基于GNN的漏洞检测模型，

（i） ReGVD将每个原始源代码视为令牌的平面序列，以构建图（在第2.2节中），其中节点特征仅由预训练的PL模型的令牌嵌入层初始化。

（ii）ReGVD利用GNN层之间的残差连接来利用GNN（如GCN[13]或门控GNN[14]）（见第2.3节）。

（iii）ReGVD检查总和和最大池之间的混合，以生成源代码的图嵌入（在第2.4节中）。这种图嵌入被馈送到单个完全连接层，然后是softmax层，以预测代码漏洞。





(i) ReGVD 将每个原始源代码视为扁平的标记序列，以构建一个图（第 2.2 节），其中节点特征仅由预训练 PL 模型的标记嵌入层初始化。

(ii) ReGVD 利用 GNN（如 GCN [13] 或 Gated GNN [14]），使用 GNN 层之间的残差连接（第 2.3 节）

(iii) ReGVD 检查总和池与最大池之间的混合，为源代码生成图嵌入（第 2.4 节）。该图嵌入被送入一个全连接层，然后再送入一个软最大层，以预测代码漏洞。

ReGVD产生了63.69%的最高精度，分别比CodeBERT和GraphCodeBERT获得了1.61%和1.39%的绝对改进



## PROPOSE

问题定义：

样本如下图，

![image-20240311092609547](https://s2.loli.net/2024/03/11/Ot7jAFmcP3NyqvQ.png)

我们将数据样本定义为{(c𝑖, y𝑖)|c𝑖 ∈ C, y𝑖 ∈ Y}𝑛 𝑖=1，其中C表示原始源代码的集合，Y = {0, 1}表示标签集，1表示存在漏洞，0表示不存在漏洞，𝑛为实例个数。

在这项工作中，我们将漏洞检测视为一种归纳文本分类问题，并利用GNN解决该问题。

因此，我们为每个源代码c𝑖构建一个图g𝑖 (V, 𝑿, 𝑨) ∈ G，

其中V表示图中的𝑚个节点；

$𝑿 ∈ R_{𝑚×𝑑}$是节点特征矩阵，其中每个节点$v_𝑗 ∈ V$由一个𝑑维实值向量$𝒙_𝑗 ∈ R^𝑑$表示；

𝑨 ∈ {0, 1}𝑚×𝑚是邻接矩阵，其中$𝑨_{v,u}$等于1表示节点v和节点u之间存在边，否则为0。

我们旨在学习一个映射函数𝑓：G → Y来确定给定的源代码是否存在漏洞。映射函数$𝑓$可以通过最小化损失函数与模型参数$𝜽$上的正则化来学习，

即：$min  ∑︁^𝑛_{𝑖 =1} L (𝑓 (g_𝑖 (V, 𝑿, 𝑨), y_𝑖 |c_𝑖 )) + 𝜆∥𝜽 ∥_2 ^2$，其中L(.)为交叉熵损失函数，𝜆为可调整权重。

![image-20240311094014010](https://s2.loli.net/2024/03/11/7Za5ASRNJfBn1bh.png)

其中L是交叉熵损失函数，并且是可调整的权重

### 图的构造(是否现有方法)



我们将原始源代码视为一系列标记的平铺序列，并且在图1中说明了两种图构建方法[10, 29]，这两种方法中我们省略了自环，因为在我们的试点实验中，自环没有帮助提升性能。第一种是基于唯一标记的构建方法。我们将唯一标记表示为节点，将标记之间的共现（在固定大小的滑动窗口内）表示为边，得到的图具有邻接矩阵A。
$$
A_{v,u}=
\left\{\begin{matrix}
 1,如果v和u同时出现在滑动窗口内，并且v≠u。 \\
 0,其他
\end{matrix}\right.
$$
基于索引的构建。

给定一个由𝑙个标记$\{𝑡i\}^𝑙 _{i=1}$组成的平面序列，我们将所有标记表示为节点，即将每个索引i视为一个表示标记𝑡i的节点。节点的数量等于序列的长度。我们还考虑索引之间的共现关系（在一个固定大小的滑动窗口内），将其表示为边，而得到的图具有邻接矩阵𝑨，如下所示：
$$
A_{v,u}=\left\{\begin{matrix}1,如果i和j同时出现在滑动窗口内，并且i≠j。 \\ 0,其他\end{matrix}\right.
$$
节点特征初始化。

值得注意的是，最近诸如CodeBERT [5]这样的预训练的编程语言（PL）模型，显著提高了PL下游任务（例如漏洞检测）的性能。为了利用预训练的PL模型的优势并进行公平比较，我们只使用预训练的PL模型的标记嵌入层来初始化节点特征向量，以报告我们的最终结果。

使用长度为3的固定大小滑动窗口的两种图构造方法的说明。

![image-20240311084547482](https://s2.loli.net/2024/03/11/UPflnCoE2vaxQqc.png)



#### 具有残差连接的图神经网络

GNNs 的目的是通过递归聚合邻近节点的向量表示来更新节点的向量表示 [13, 24]。在数学上，给定一个图 g(V,𝑿,𝑨)，我们可以将 GNN 简单地表述如下：

![image-20240314152510790](https://s2.loli.net/2024/03/14/yBmhj4Capx3LqZ5.png)

其中，H(𝑘) 是第𝑘 次迭代/层的节点矩阵表示；H(0) = 𝑿 。最近的文献[26]中提出了很多 GNN，其中图卷积网络（Graph Convolutional Networks，GCNs）[13]是应用最广泛的一种，而门控图神经网络（Gated graph neural networks，简称 "GGNNs"）[14]也适合我们的数据结构。我们的 ReGVD 利用 GCNs 和 GGNNs 作为基础模型。GCNs 的形式如下：

![image-20240314152814072](https://s2.loli.net/2024/03/14/OLvyh2HEWuC8NP1.png)

其中 𝑎~v,u~ 是拉普拉斯重归一化邻接矩阵（因为我们省略了自环）中节点 v 和 u 之间的边常数，其中 D 是 𝑨 的对角节点度矩阵； 𝑾 (𝑘) 是权重矩阵； 𝜙 是非线性激活函数，例如 ReLU。 GGNN 采用 GRU [2]，展开固定数量时间步的递归，并且无需约束参数以确保收敛：

![image-20240314152651800](https://s2.loli.net/2024/03/14/V2QwB7Jds6A9Me3.png)

残差连接[8]用于将低层学到的信息整合到高层，更重要的是允许梯度直接通过各层，以避免梯度消失或梯度爆炸问题。受此启发，我们按照 [1] 的方法，在 GNN 各层之间调整残差连接，并为不同层固定相同的隐藏大小。具体而言，ReGVD 将 GNN 重新定义为
$$
H^{(𝑘+1)} = H^{(𝑘)} + GNN\big(𝑨,H^{(𝑘)}\big)
$$

### 图形级读出池层

图层级读出层用于为每个输入图生成图嵌入。ReGVD利用求和池化产生更好的图分类结果[27]。此外，ReGVD利用最大池化来利用节点表征上的更多信息。然后，ReGVD考虑求和和最大池化的混合，以产生图嵌入eg。

![image-20240311105125411](https://s2.loli.net/2024/03/11/q9hWSlLAM24PtVK.png)

其中，e~v~是节点v的最终向量表示，其中$𝜎(w^T h_v^{(𝐾)}+b )$充当对节点进行软注意力机制的作用，$h_v^{K}$是节点v在最后一个𝐾层的向量表示；MIX(.)表示一个任意的函数。ReGVD考虑了三个MIX函数，分别是SUM，MUL和CONCAT：

![image-20240311105425744](https://s2.loli.net/2024/03/11/9yBKheSAfzl7sm1.png)



之后，ReGVD将eg馈送到单个完全连接层，然后是softmax层，以预测源代码是否易受攻击，如：$\hat{y}_g=softmax(W_1e_g+b_1) $

最后，如第2.1节所述，通过最小化交叉熵损失函数来训练ReGVD。我们在图2中说明了所提出的

在此之后，ReGVD将eg输入到一个全连接层中，随后是一个softmax层，用于预测源代码是否存在漏洞，表达式为：$\hat{y}_g=softmax(W_1e_g+b_1) $

 最后，ReGVD通过最小化交叉熵损失函数（如2.1节所述）来进行训练。我们在图2中描绘了提出的ReGVD方法。

![image-20240311101418653](https://s2.loli.net/2024/03/11/Y8lco4ACxgMsHut.png)

池化(作用) 有向  

### 实验和结果

#### 实验设置

##### 数据集

使用CodeXGLUE[17]的真实世界基准进行功能级别的漏洞检测。该数据集由Zhou等人[30]首次创建，包括27318个手动标记的易受攻击或不易受攻击的函数，这些函数是从两个大型且流行的C编程语言开源项目（即QEMU和FFmpeg）的安全相关提交中提取的，并且功能多样化。然后，Lu等人[17]将这些项目合并，然后拆分为训练/验证/测试集。

##### 训练设置:

构建了一个2层模型,batch size:128,使用Adam 优化器(Adam optimizer)训练100 epochs

设置相同的hidden size 给hidden GNN层 改变值 {128,256,384}

改变滑动窗口(sliding window)大小:{2,3,4,5}

Adam initial learning rate(lr) {1e^-4^,5e^-4^,1e^-3^}

针对最佳模型检查点报告测试集上的最终精度，该检查点在验证集上获得最高精度。

•BiLSTM[9]和TextCNN[11]是应用于文本分类的两个众所周知的标准模型。

•RoBERTa[16]是在BERT[4]的基础上构建的，方法是删除下一个句子目标，并在具有较大小批量和学习率的大规模数据集上进行训练。

•Devign[30]从原始源代码构建一个多边缘图，然后使用门控GNN[14]更新节点表示，最后使用基于一维CNN的池化（“Conv”）进行预测。我们注意到周等人[30]没有公布Devign的正式实施。因此，我们使用相同的训练和评估协议重新实现Devign。

•CodeBERT[5]是一个预训练模型，也是基于6种编程语言（Python、Java、JavaScript、PHP、Ruby、Go）的BERT，使用屏蔽语言模型[4]和替换的令牌检测[3]目标。

•GraphCodeBERT[6]是一种新的预训练PL模型，扩展了CodeBERT以考虑进入训练目标的代码数据流的固有结构。

表1显示了所提出的ReGVD的准确性结果，以及CodeXGLUE用于漏洞检测的真实世界基准数据集上的强大和最新基线。我们注意到，最近的模型CodeBERT和GraphCodeBERT都获得了有竞争力的性能，并且比Devign表现得更好，这表明了预训练的PL模型的有效性。更重要的是，与CodeBERT和GraphCodeBERT相比，ReGVD分别获得了1.61%和1.39%的绝对改进这表明了ReGVD在学习源代码内部的局部结构以区分漏洞方面的优势（w.r.t仅使用预训练的PL模型的令牌嵌入层）。

ReGVD (GGNN + UniT + CB) 63.62

ReGVD (GCN + UniT + G-CB) 63.69

ReGVD产生了63.69%的最高准确率，这是CodeXGLUE漏洞检测数据集上最先进的新结果。

由于Devign还使用门控GNN来更新节点表示，并且对于设置（Idx+G-CB）获得了61.31%的最佳精度；因此，我们考虑了ReGVD设置（GGNN+Idx+G-CB），而不使用残差连接进行公平比较，其中ReGVD实现了63.51%的精度，比Devign的精度高2.20%。更普遍地说，我们从三个剩余的ReGVD设置（不使用残差连接）的结果中得到了类似的结论，即ReGVD中使用的图级读出层优于Devign中使用的读出层。

它表明，残余连接有助于提高GNN在七种设置下的性能，

此外，与使用完整训练数据的基线相比，我们的模型在**有限的训练数据下实现了令人满意的性能**。例如，ReGVD在60%的训练集下获得61.68%的准确率

### 结论:

我们将漏洞识别视为一个归纳文本分类问题，并引入了一个简单而有效的图神经网络模型ReGVD来检测源代码中的漏洞。

ReGVD将每个原始源代码转换为图，其中ReGVD仅利用预先训练的编程语言模型的令牌嵌入层来初始化节点特征向量。

然后，ReGVD利用GNN层之间的残差连接以及和池和最大池的混合来学习图表示

。为了证明ReGVD的有效性，我们进行了广泛的实验，将ReGVD与CodeXGLUE的基准漏洞检测数据集上的强大和最新基线进行了比较。实验结果表明，所提出的ReGVD明显优于基线模型，在基准数据集上获得了63.69%的最高准确率。ReGVD可以被视为一个通用的、实用的、与编程语言无关的模型，可以在v上运行