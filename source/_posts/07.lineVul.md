---
title: LineVul
date: 2024-04-22 09:53:28
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

# LineVul: A Transformer-based Line-Level Vulnerability Prediction

软件系统中普遍存在软件漏洞，这些漏洞会导致死锁、信息丢失或系统故障等各种问题。因此，在关键安全软件系统中，提前预测软件漏洞至关重要。已经提出了基于机器学习/深度学习的各种方法来预测文件/函数/方法级别的漏洞。最近，提出了一种名为IVDetect的基于图神经网络的方法来预测函数级别的漏洞。然而，IVDetect方法仍然不准确且粗粒度。在本文中，我们提出了一种基于Transformer的行级漏洞预测方法LineVul，以解决现有IVDetect方法的若干限制。通过对一个包含188k+个C/C++函数的大规模真实世界数据集的实证评估，我们展示了LineVul在函数级别预测上实现了（1）160%-379%更高的F1度量；（2）12%-25%更高的前10准确性；以及（3）比基线方法在20%召回率下减少了29%-53%的工作量，突显了LineVul在更准确和更具成本效益的行级漏洞预测方面的重大进展。我们的额外分析还表明，LineVul对于预测受到前25个最危险CWE（常见弱点架构）影响的易受攻击函数也非常准确（75%-100%），突显了LineVul在实际应用场景中的潜在影响。

## 引言

最近，李等人提出了一种名为IVDetect的方法，以解决对精细化漏洞预测的需求。IVDetect利用基于特征注意力图卷积网络（FA-GCN）的方法来预测功能级漏洞，并使用GNNExplainer来确定漏洞的精细位置。李等人发现，IVDetect方法的F-measure达到了0.35，优于现有的最先进方法。然而，IVDetect还存在以下三个局限性。最近，李等人提出了一种名为IVDetect的方法，以解决对细粒度漏洞预测的需求。IVDetect利用了一种FA-GCN（即特征注意力图卷积网络）方法来预测功能级漏洞，并使用GNNExplainer来定位细粒度漏洞的位置。李等人发现，IVDetect方法达到了0.35的F-measure，超过了现有技术的表现。然而，IVDetect具有以下三个局限

首先，IVDetect的训练过程仅限于项目特定的数据集。由于IVDetect使用的训练数据有限，语言模型可能无法捕捉到令牌与其周围令牌之间最准确的关系。因此，IVDetect对源代码的向量表示仍然不够优化。

• 其次，IVDetect方法基于循环神经网络（RNN）的架构仍然无法有效捕捉源代码的有意义的长期依赖性和语义。IVDetect依赖于基于RNN的模型在预测步骤中生成用于其图模型的向量表示。然而，基于RNN的模型通常难以学习源代码的长序列。这种限制可能使生成的向量表示缺乏意义，导致不准确的预测。

• 第三，IVDetect的子图解释仍然粗粒度。IVDetect利用图神经网络解释器（GNNExplainer）识别对预测结果做出最大贡献的子图。虽然这种子图解释能帮助开发人员缩小漏洞代码所在的范围，但这些子图仍然包含许多行代码。因此，安全分析师仍需手动确定这些子图中哪些行代码实际上是有漏洞的。

在这篇论文中，我们提出了一种基于Transformer的细粒度漏洞预测方法LineVul，旨在解决IVDetect存在的三个重要局限性。

首先，我们采用了具有自注意力层的BERT架构[15]来生成代码的表示，能够利用点积运算捕捉长序列内的长期依赖关系。

其次，我们利用CodeBERT预训练语言模型生成源代码的向量表示，而不是使用项目特定的训练数据。

第三，我们利用BERT架构的注意力机制来定位易受攻击的代码行，而不是使用GNNExplainer来识别对预测结果有贡献的子图，这种方法比IVDetect更细粒度。

最后，我们通过一个实验证明了我们的LineVul方法与七种基准方法（即IVDetect [30]、Reveal [12]、SySeVR [32]、Devign [65]、Russell et al. [43]、VulDeePecker [33]和BoW+RF）进行了比较，并在粗粒度（即函数级）和细粒度（即行级）漏洞预测场景下进行了评估。

通过对包含91种CWE（通用弱点枚举）的188k+个C函数进行广泛评估，我们回答了以下三个研究问题：

（RQ1）我们的LineVul在函数级漏洞预测方面有多准确？

结果显示，我们的LineVul达到了0.91的F-度量值，比现有最先进的方法提高了160%至379%，并且中值提高了250%。同样地，我们的LineVul精确率达到了0.97，召回率达到了0.86，分别比基准方法提高了322%和19%。

（RQ2）我们的LineVul在行级漏洞定位方面有多准确？

结果显示，我们的LineVul在Top-10准确度方面达到了0.65，比其他基准方法准确率提高了12%至25%。此外，LineVul的中位数IFA仅为1，而基准方法的中位数IFA为3-4。

（RQ3）我们的LineVul在行级漏洞定位方面的成本效益如何？

结果显示，我们的LineVul在20%召回率下的工作量为0.75，比其他基准方法减少了29%至53%。此外，LineVul在1%LOC召回率下的召回率为0.24，比其他基准方法提高了26%-85%。

这些结果使我们得出结论：相较于现有的漏洞预测方法，LineVul在准确性、成本效益和细粒度方面更加出色。因此，我们预期我们的LineVul能够帮助安全分析师以更具成本效益的方式找到易受攻击的代码行。此外，我们建议在未来的研究中使用注意力机制来提高基于Transformer模型的可解释性，因为本文已经展示了使用注意力机制在行级漏洞定位方面的重大优势，它优于其他独立于模型的技术（如DeepLift、LIG和SHAP）。

创新与贡献。据我们所知，本文的主要贡献有两点：（1）我们提出了一种基于Transformer的行级漏洞预测方法LineVul，解决了现有漏洞预测方法的各种限制；（2）实验结果证实，与现有的漏洞预测方法相比，我们的LineVul在准确性、成本效益和细粒度方面更加优秀。

开放科学。为了支持开放科学社区，我们在GitHub上发布了研究数据集、脚本（数据处理、模型训练和模型评估）以及实验结果（https://github.com/awsm-research/LineVul）。

论文结构。第2节讨论了IVDetect方法及其局限性。第3节介绍了我们的LineVul方法。第4节介绍了我们的三个研究问题的动机、研究数据集和实验设置，而第5节介绍了实验结果。第6节介绍了我们LineVul的消融研究。第8节揭示了有效性的威胁。第9节得出了结论。

## 背景

软件漏洞是软件实现中的缺陷或弱点，由软件设计方式或编码方式导致。在计算机安全中，这类软件漏洞可能导致系统崩溃，或允许攻击者通过越过计算机系统内的特权边界来控制系统。因此，已提出了两种自动漏洞预测方法：基于程序分析（PA）和基于机器学习/深度学习（ML/DL）。

基于PA的技术使用预定义的模式来检测软件漏洞。因此，PA方法只关注特定类型的漏洞。例如，FlawFinder [5] 支持通用弱点枚举（CWE），将C/C++程序作为输入并按风险级别生成漏洞列表。RATS [9] 是另一个静态程序分析工具，可以检测缓冲区溢出和TOCTOU（检查时间与使用时间）竞态条件等漏洞。Cppcheck [2]是用于C/C++代码的静态分析工具，使用独特的代码分析重点检测未定义行为和危险编码结构。Checkmarx [1]提供未编译源代码的自动扫描，可集成到DevOps中，使开发人员能够在开发过程中识别安全漏洞。然而，基于PA的技术需要安全专家手动制定预定义模式，这需要耗费时间。

ML/DL-based方法利用机器学习（ML）和深度学习（DL）技术自动学习漏洞模式来检测软件漏洞。具体而言，代码程序会被转换为向量表示，以便模型从先前的有漏洞程序中学习漏洞的隐含模式。最近，已经将几种DL模型应用于漏洞预测任务。例如，VulDeePecker [33] 利用程序切片上的符号表示，Devign [65] 利用代码属性图（如AST、CFG、DFG）上的图嵌入，SySeVR [32] 则依赖于数据依赖引导的语义信息，Reveal [12] 则采用了带有三元组损失函数的图嵌入进行表示学习，Russell等人 [43]则利用CNN和RNN提取表示。尽管这些DL模型能够生成更好的表示，但它们仍然专注于粗粒度的漏洞预测，即在文件级别或函数级别提供漏洞预测。

IVDetect：一种先进的细粒度漏洞预测及其局限性
基于PA和ML/DL的方法都不能检测细粒度漏洞。因此，开发人员仍然需要检查大量的代码行，以查找和修复代码中的漏洞。最近，Li等人提出了IVDetect——一种基于图的细粒度漏洞预测方法，包括以下三个步骤：
第一步：代码表示学习。IVDetect利用GloVe词嵌入（全局词向量表示）捕捉标记之间的语义相似性，并使用GRU模型将向量序列汇总为一个特征向量。

**GloVe（Global Vectors for Word Representation）是一种无监督学习算法，用于获取单词的向量表示。是Word2Vec模型的扩展，有助于有效地学习单词向量。训练是在来自语料库的聚合全局词-词共现统计数据上执行的，并且生成的表示显示了词向量空间的有趣线性子结构。**



IVDetect从给定的代码语句生成四个特征向量：

1）一系列子标记捕捉词法信息，

2）变量名称和类型作为图模型中的节点信息，

3）数据依赖上下文，以及

4）控制依赖上下文。

此外，还使用Tree-LSTM生成AST树的表示。在获取了所有五个特征向量（即𝐹1，...，𝐹5）之后，**IVDetect使用Bi-GRU和注意力层为每个特征向量𝐹𝑖学习权重向量𝑊𝑖。**

最后**，将每个特征向量乘以计算得到的权重向量：𝐹 ′ 𝑖 = 𝑊𝑖 𝐹𝑖** 。



第二步：使用FA-GCN进行漏洞预测。

对于给定的输入方法𝑚，IVDetect首先将𝑚处理成一个由多个语句组成的程序依赖图（PDG），对于每个语句，通过第一步的过程生成五个特征向量。

FA-GCN在PDG的所有节点（语句）上滑动一个小窗口，并利用联合层将所有生成的特征向量链接成一个特征矩阵F𝑚，其中每一行对应于PDG中的一个小窗口。

然后，计算对称归一化拉普拉斯矩阵[29] L𝑚，并将其与特征矩阵F𝑚通过卷积结合起来，生成方法𝑚的表示矩阵M𝑚。最后，FA-GCN使用空间金字塔池化层进行归一化处理，然后通过一个全连接层将矩阵M𝑚转换为向量𝑉𝑚，并使用两个隐藏层和一个softmax函数进行分类，为𝑚生成预测得分。这些分数用作漏洞分数来排列函数。

步骤3：GNNExplainer进行细粒度漏洞预测。IVDetect利用GNNExplainer [64]和掩码技术，解释哪些子图对FA-GCN模型的漏洞预测贡献最大。GNNExplainer的目标是在方法𝑚的整个PDG 𝐺𝑚中找出一个子图G𝑚，使得使用整个图𝐺𝑚和最小图G𝑚之间的预测分数差异最小化。为此，GNNExplainer学习一组边掩码𝐸𝑀，从中得到最小图G𝑚。应用一个边掩码𝐸𝑀后，GNNExplainer会检查FA-GCN模型是否产生相同的结果（即预测为漏洞）。如果是，则边掩码中的边不重要，不包括在G𝑚中。否则，边是重要的，包括在G𝑚中。然后，IVDetect利用从GNNExplainer学到的最佳子图G𝑚作为解释，以检测细粒度漏洞。然而，存在以下限制。

限制1：IVDetect的训练过程仅限于特定项目的数据集。向量表示的质量严重依赖于所使用的代码语言模型。对于IVDetect方法，Li等人[30]利用了GloVE（见IVDetect的第一步），这是一种无监督学习算法，用于获取单词的向量表示。然而，他们的Glove语言模型仅在特定项目的数据集上进行训练，没有在大型代码库上进行预训练，这可能无法生成最有意义的代码表示。因此，IVDetect对源代码的次优向量表示可能导致预测不准确。

限制2：IVDetect方法基于RNN的架构仍然无法有效捕捉源代码的有意义的长期依赖性和语义。IVDetect在第一步中依赖于基于RNN的架构来生成代码表示，但在处理长序列时会遇到问题。基于RNN的模型逐个处理序列标记，模型在处理每个标记时会考虑上一个标记的上下文向量和隐藏向量。隐藏向量用于捕捉标记之间的短期依赖关系，而上下文向量用于捕捉长期依赖关系。然而，由于其有限的记忆能力，上下文向量在处理长序列（例如，一个包含500个标记的序列）时很难捕捉足够的长期依赖关系。因此，这个限制可能使生成的特征表示变得不太有意义，进一步影响漏洞预测模型的准确性。

限制3：IVDetect的子图解释仍然过于粗粒度。第三，在第3步中，IVDetect利用GNNExplainer生成PDG子图解释作为精细的漏洞预测。此类子图解释可能包含多行代码，它们对于有效减少手动代码检查工作的效果不够精细。例如在图1中，易受攻击的函数𝑢𝑛𝑃𝑟𝑒𝑚𝑢𝑙𝑆𝑘𝐼𝑚𝑎𝑔𝑒𝑇𝑜𝑃𝑟𝑒𝑚𝑢𝑙包含了一行易受攻击的代码（即第九行），其中变量类型定义错误，进而导致了易受攻击的CWE-787类型。IVDetect生成的PDG子图将第五、第七、第八和第九行标记为易受攻击模式。另一方面，我们的LineVul生成了一级解释，直接指出了实际易受攻击的代码行。

![image-20240401172310736](https://s2.loli.net/2024/04/01/DUS4yXGr6k8snCB.png)

## LINEVUL: 基于行级漏洞预测方法

本节中，我们介绍了我们的LineVul方法的设计原理和体系结构。
设计原理。为了解决IVDetect的三个关键限制，我们提出了我们的LineVul的体系结构，即基于Transformer的行级漏洞预测方法。首先，我们采用了具有自注意力层的BERT架构[15]，而不是使用基于RNN的模型生成代码表示，这些自注意力层能够使用点积操作捕获长序列中的长期依赖关系。其次，我们利用CodeBERT预训练语言模型生成源代码的向量表示，而不是使用项目特定的训练数据。预训练的CodeBERT语言模型使用了一个经过优化的鲁棒BERT预训练方法[34]在20GB的代码语料库（即CodeSearchNet）上进行了预训练。因此，我们的方法能够更好地捕捉给定代码输入的词库和逻辑语义，并生成更具意义的向量表示。第三，我们利用BERT结构的注意机制来定位易受攻击的行，而不是使用GNNExplainer来识别对预测贡献的子图，这种方法比IVDetect方法更加精细。
我们将我们的LineVul方法设计为两个步骤：预测易受攻击的函数和定位易受攻击的行。图2展示了我们LineVul方法的概览架构。

![image-20240401172326927](https://s2.loli.net/2024/04/01/DCabijYdGKfTlg6.png)

### 3.1 函数级别的漏洞预测

函数级别的漏洞预测包括两个主要步骤：

1. BPE子词分词。
在第一步中，我们利用字节对编码（BPE）方法[44]构建我们的分词器，分为两个主要步骤。首先，生成合并操作以确定单词应如何拆分，然后根据子词词汇应用合并操作。具体来说，BPE将所有单词分成字符序列，并识别出最常见的符号对（例如，连续两个字符的组合）应该合并成一个新的符号。BPE是一种算法，它将把罕见的单词分成有意义的子词，并同时保留常见的单词（即不会将常见的单词分成更小的子词）。例如，在图1中，函数名𝑢𝑛𝑃𝑟𝑒𝑚𝑢𝑙𝑆𝑘𝐼𝑚𝑎𝑔𝑒𝑇𝑜𝑃𝑟𝑒𝑚𝑢𝑙将分成一个子词列表，即["un", "Prem", "ul", "Sk", "Image", "To", "Prem", "ul"]。常见的单词"Image"得到了保留，其他罕见的单词被拆分。使用BPE子词分词将有助于在记号化各种函数名称时减小词汇量，因为它将罕见函数名称拆分为多个子组件，而不是直接将完整的函数名称添加到词典中。在这篇论文中，我们在CodeSearchNet [20]语料库上应用BPE方法，生成适用于源代码语料库的训练语言模型的子词分词器。
2. LineVul模型构建。
在第二步中，我们基于BERT架构构建了一个LineVul模型，并利用了Feng等人[17]预训练的初始权重。首先，在第2a步中，LineVul对子词分词后的函数进行单词和位置编码，以生成每个单词及其在函数中的位置的嵌入向量。然后，在第2b步中，将该向量输入BERT架构，BERT是由12个Transformer编码器块组成的堆叠。每个编码器由一个多头自注意层和一个全连接前馈神经网络组成。最后，在第2c步中，将输出向量输入到一个线性层中，以对给定函数进行二分类。我们下面对每个步骤进行详细描述。

2a. 字词编码和位置编码。
源代码由多个记号组成，每个记号的含义在很大程度上依赖于上下文（即周围的记号）和其在函数中的位置。因此，捕捉代码上下文及其在函数中的位置对于函数级漏洞预测非常重要。此步骤的目的是生成编码向量，以捕捉代码记号的语义含义及其在输入序列中的位置。为此，对于每个分词记号化的记号，我们生成两个向量：(1) 词编码向量，用于表示给定代码记号与其他代码记号之间的有意义的关系，以及(2) 位置编码向量，用于表示给定记号在输入序列中的位置。

记号编码向量根据词嵌入矩阵$W^{|𝑉 |×𝑑} _{𝑡𝑒}$ 生成，其中|𝑉 |是词汇量大小，𝑑是嵌入尺寸。

位置编码向量根据位置编码矩阵$W^{𝑐×𝑑}_{𝑝𝑒} $生成，其中𝑐是上下文大小，𝑑是嵌入尺寸。

最后，将词编码向量和位置编码向量连接起来，以生成Transformer编码器块的输入向量。

2b. 12个双向自注意力的Transformer编码器堆叠。
在这一步中，编码向量被输入到12个仅编码器的Transformer块（即BERT架构[15]）堆叠中。每个编码器块由两个组件组成，即双向多头自注意力[15]层和全连接前馈神经网络。以下我们简要描述多头自注意力和前馈神经网络。

多头自注意力层用于计算每个代码记号的注意力权重，生成一个注意力向量。双向自注意力的使用允许每个记号同时关注左侧和右侧的上下文。生成的注意力权重被用来指示Transformer模型应关注哪些代码语句。通常，自注意力机制用于获取全局依赖性，其中注意力权重表示序列中每个代码记号受所有其他词汇影响的程度，使我们的LineVul方法能够捕捉每个代码记号之间的依赖关系，从而生成更有意义的表示。

自注意机制[59]采用了信息检索的概念，通过点乘操作计算每个代码标记与其他标记之间的相关分数，其中每个标记与其他标记仅交互一次。自注意机制依赖于三个主要组成部分：查询（Q）、关键字（K）和值（V）。查询是当前代码标记的表示，用于根据关键字存储在关键字向量中的其他标记对其进行评分。通过求取查询向量和关键字向量之间的点乘得到每个标记的注意力分数。然后，通过使用Softmax函数将注意力分数归一化为概率，以获得注意权重。最后，通过将值向量和注意权重向量之间的点乘来更新值向量。我们在LineVul中使用的自注意力是一种缩放的点积自注意力，其中注意力分数除以√ 𝑑𝑘 。我们采用的自注意机制可以总结为以下方程式：

![image-20240401161430139](C:/Users/ch_Z/AppData/Roaming/Typora/typora-user-images/image-20240401161430139.png)

为了捕捉输入序列更丰富的语义含义，我们使用了多头机制来实现自注意力，这使得模型能够同时关注不同位置的不同代码表示子空间中的信息。对于 𝑑 维度的 𝑄，𝐾 和 𝑉 ，我们将这些向量分割为 ℎ 个头，每个头具有 𝑑/ℎ 维度。在完成所有自注意力操作后，每个头将被再次连接起来输入到一个包含两个线性转换和中间的ReLU激活的全连接前馈神经网络中。多头机制可以通过以下方程来总结：

![image-20240401161524151](https://s2.loli.net/2024/04/01/2NF8CBSxhdEvMck.png)

其中，𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛(𝑄𝑊𝑄𝑖, 𝐾𝑊𝐾𝑖, 𝑉𝑊𝑉𝑖) 的意思是使用注意机制来计算得到𝑎𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛，而𝑊𝑂用于将拼接后的结果进行线性投影到期望的维度上。

- 2c 单一线性层。在堆叠的Transformer编码器块中，使用多个线性转换和非线性激活函数（比如ReLU）构建，因此最终编码器输出的表示是有意义的。我们只需要一个单一的线性层将代码表示映射为二进制标签，即ˆ 𝑦 = 𝑊𝑇𝑋 + 𝑏。

### 行级漏洞定位

  给定被LineVul预测为有漏洞的函数，我们利用Transformer体系结构内部的自注意机制来进行行级漏洞定位，以定位出有漏洞的行。直觉是对预测做出最大贡献的标记很可能是有漏洞的标记。
  对于函数中的每个子单词标记，在第三步中，我们总结了每个12个Transformer编码器块的自注意分数。获得子单词标记的自注意分数后，我们将这些分数集成到行分数中。我们通过换行控制字符（即\n）将整个函数分成许多标记列表（每个列表代表一行）。最后，对于每个标记列表的分数，我们将其总结为一个注意力行分数，并按降序排列行分数。

## 实验设计

在这一部分中，我们介绍了我们三个研究问题的动机，我们研究的数据集以及我们的实验设置。

### 研究问题

为了评估我们的LineVul方法，我们提出以下三个研究问题。
（RQ1）我们的LineVul在功能级漏洞预测方面的准确性如何？最近，李等人[30]提出了IVDetect，一种先进的细粒度漏洞预测方法。然而，如2.1节所述，IVDetect有三个关键限制，导致预测结果不准确且粗粒度。因此，我们提出了我们的LineVul方法来解决这些挑战。因此，我们调查我们的LineVul方法的准确性是否超过了最先进的功能级漏洞预测方法。
（RQ2）我们的LineVul在行级漏洞定位方面的准确性如何？行级漏洞预测有助于帮助开发人员确定易受攻击行的具体位置，而不是浪费时间检查非易受攻击行。尽管IVDetect可以识别易受攻击函数的子图，但这些子图仍然包含许多代码行需要安全分析人员检查，这仍然是粗粒度的。因此，我们调查我们的LineVul在行级漏洞预测方面的准确性。
（RQ3）我们的LineVul在行级漏洞定位方面的成本效益如何？漏洞预测的主要目标之一是通过以最少的工作量揭示最多的漏洞，以帮助安全分析人员以经济有效的方式找到易受攻击行的位置。因此，在安全分析人员决定实践中采用先进方法时，需要检查源代码的工作量成为一个关键问题。因此，我们调查我们的LineVul在行级漏洞预测方面的成本效益。

### 数据集

我们使用Fan等人提供的基准数据集，原因如下。首先，是为了与IVDetect方法进行公正比较。其次，是为了评估我们的逐行漏洞方法，因为Fan等人的数据集是唯一提供逐行真实情况（即函数中哪些行是有漏洞的）的漏洞数据集。另一方面，其他现有的漏洞数据集（如Devign [65]、Reveal [12]）只提供函数级别的真实情况，而不是行级别的，对于我们的范围来说不太适用。Fan等人的数据集是最大的漏洞数据集之一，包括来自348个开源Github项目的91种不同的CWE（Common Weakness Enumeration）从2002年到2019年，共有188,636个C/C++函数，其中有5.7%（即10,900个有漏洞的函数）是漏洞函数，总共有5,060,449行代码，其中0.88%（即44,603个有漏洞的行）是漏洞行。在这10,900个有漏洞的函数中，漏洞行的比例从2.5%（第一四分位数）到20%（第三四分位数）之间变化，中位数为7%。

### 实验设置

**数据分割。**

与Li等人[30]类似，我们采用相同的数据分割方法，即整个数据集分为80％的训练数据，10％的验证数据和10％的测试数据。
**函数级模型实现。**
为了实现我们的函数级漏洞预测方法LineVul，我们主要使用两个Python库，即Transformers [62]和PyTorch [13]。Transformers库提供了基于Transformer的模型架构和预训练权重的API访问，而PyTorch库支持在训练过程中的计算（例如反向传播和参数优化）。我们下载了由Feng等人[17]预训练的CodeBERT分词器和CodeBERT模型。我们使用我们的训练数据集微调预训练模型，以获得适合我们的漏洞预测任务的权重mox 。模型在NVIDIA RTX 3090显卡上进行了微调，训练时间约为7小时10分钟。如公式1所示，我们使用交叉熵损失来更新模型，并在函数级别的预测值和实际标签之间进行优化，其中𝑥是类别的数量，𝑝是实际的概率分布（独热编码），𝑞是预测的概率分布。为了获得最佳的微调权重，我们使用验证集按周期监视训练过程，并根据与验证集的最佳F1分数选择最佳模型（而不是测试集）。

![image-20240401162310046](C:/Users/ch_Z/AppData/Roaming/Typora/typora-user-images/image-20240401162310046.png)

线级模型实现。为了实现我们的LineVul方法用于线级漏洞预测，我们在推理过程中使用了经过微调的模型返回的自注意力矩阵。我们对每个标记的点乘注意力得分进行了总结，因此，每个标记都有一个注意力得分。我们将标记整合到行中，并总结了每个标记的得分，以获得行的得分。然后，我们使用行的得分对行进行优先级排序，其中较高的行得分表示该行很可能是一个易受攻击的行。

微调的超参数设置。对于我们的LineVul方法的模型架构，我们使用了CodeBERT的默认设置，即12个Transformer编码器块，768个隐藏单元大小和12个注意力头。我们采用了Feng等人提供的相同的微调策略[17]。在训练过程中，学习率设置为2e-5，并按照线性调度进行衰减，即在整个训练过程中学习率线性衰减。我们使用反向传播与AdamW优化器[35]进行微调Transformer-based模型，以更新模型并最小化损失函数。

## 实验结果

### RQ1）我们的LineVul在函数级漏洞预测中有多准确？

 方法。为了回答这个问题，我们专注于函数级漏洞预测，并将我们的LineVul与其他七个基准模型进行比较，这些模型描述如下：
(1) IVDetect [30] 利用特征注意力图卷积网络（GCN）进行漏洞预测，使用五种特征表示（即子标记序列、AST子树、变量名和类型、数据依赖上下文和控制依赖上下文）来自源代码；
 (2) ReVeal [12] 利用门控图神经网络（GGNN）学习源代码的图属性；
 (3) Devign [65] 利用门控图神经网络（GGNN）自动学习源代码的图属性（即AST、CFG、DFG和代码序列）；
 (4) SySeVR [32] 使用代码语句、程序依赖和程序切片作为特征，采用几种基于RNN的模型（LR、MLP、DBN、CNN、LSTM等）进行分类；
 (5) VulDeePecker [33] 利用双向LSTM网络进行语句级漏洞预测；
 (6) Russell等人[43] 利用基于RNN的模型进行漏洞预测。
 (7) BoW+RF（LineDP/JITLine）使用词袋模型作为特征，并结合随机森林模型进行软件缺陷预测[38, 60]。
与Li等人[30]类似，我们用Precision、Recall和F1-score三个二分类指标评估我们的LineVul。Precision衡量的是正确预测为可疑函数的函数比例及预测为可疑函数的函数数量。

根据我们的模型计算得出，脆弱性的召回率被定义为正确预测为脆弱性的函数比例与实际脆弱性函数数量之比，计算公式为 𝑇 𝑃 𝑇 𝑃+𝐹𝑃 。而准确率则是精确率和召回率的调和平均值，计算公式为 2×准确率×召回率 准确率+召回率 。为了表示预测标签，我们使用了0.5的概率阈值。这些测量值的取值范围在0到1之间，其中1表示最高准确率。
结果部分，根据我们的三个评估指标（F1值、精确率和召回率），Figure 3展示了我们的LineVul和七个基准方法的实验结果。
我们的LineVul在F1值上达到了0.91，比现有方法提升了160%-379%，中位数提升了250%。从F1值来看，Figure 3显示LineVul达到了最高的0.91，而现有方法只有0.19-0.35的F1值。这表明LineVul在F1值方面比现有方法提高了160%-379%，中位数提升了250%。从精确率来看，Figure 3显示LineVul达到了最高的0.97，而现有方法只有0.12-0.48的精确率。这表明LineVul在精确率方面比现有方法提高了102%-708%，中位数提升了439%。从召回率来看，Figure 3显示LineVul达到了最高的0.86，而现有方法只有0.17-0.86的召回率。这表明LineVul在召回率方面比现有方法提高了16%-406%，中位数提升了65%。
换句话说，我们的结果表明，使用Transformer架构和语义、语法特征，要比使用源代码的图属性的现有方法表现更好。我们的发现与许多最新研究的发现不同，这些研究发现使用图属性（如数据依赖图、抽象语法树、控制流图和数据流图）通常比使用语法和语义特征更有效用于脆弱性预测[12, 29, 65]。这是因为以往的研究中使用的基线方法（如RNN、LSTM、GRU）(1)是在项目特定数据集上进行训练的；(2)在获取源代码的长期依赖性方面存在问题，正如第2.1节所讨论的（参见限制1和2）。与以往的研究不同，我们的结果证明了我们的LineVul方法比现有方法更准确，突出了在函数级别上使用CodeBERT预训练的语言模型以及使用Transformer架构来捕捉源代码的长期依赖性所带来的重大优势，从而大幅提高了脆弱性预测方法的性能。

### （RQ2）我们的LineVul在行级漏洞定位方面有多准确？

**方法**。
为了回答这个问题，我们着重评估行级漏洞定位的准确性。因此，我们从我们的方法正确预测的易受攻击函数开始。然后，我们执行第3步（见第3.2节）来确定被预测为易受攻击函数的哪些行可能会存在漏洞。因此，给定函数中的每一行都会有自己的分数（即行级分数）。由于RQ1中的其他方法并不是为行级定位设计的，所以我们不会将我们的方法与它们进行比较。相反，我们将我们的LineVul方法与另外5种常用于深度学习模型的模型无关技术进行比较，具体如下：
（1）层集成梯度（LIG）[48]是一种公理化路径归因方法，通过近似从给定基线到输入的路径（直线）上对模型输出的梯度积分进行属性分配，从而为每个输入特征分配一个重要性分数；
（2）显著性[47]在输入处对网络进行一阶泰勒展开，梯度实际上是模型线性表示中每个特征的系数。这些系数的绝对值可以表示特征的重要性；
（3）DeepLift [11, 46]将每个神经元的激活与其参考激活进行比较，并根据差异分配贡献分数；
（4）DeepLiftSHAP [36]扩展了DeepLift算法，并使用DeepLift方法近似计算SHAP值；
（5）GradientSHAP [36]通过从基线分布中随机抽样来计算梯度期望，从而近似计算SHAP值；
（6）CppCheck [2]是C和C++编程语言的静态代码分析工具。
为了评估我们的LineVul方法在行级漏洞定位方面的能力，我们使用以下两个描述如下的度量标准：
1）Top-10准确度测量了在至少一个实际易受攻击行出现在前10名中的易受攻击函数的百分比。直觉上讲，如果行级建议在前10名中没有出现，安全分析员可能会忽略它们，就像任何推荐系统一样[37]。因此，Top-10准确度可以帮助安全分析员更好地了解行级漏洞定位方法的准确性。
2）初始误报（IFA）度量了安全分析员需要检查的错误预测行数（即将非易受攻击行错误预测为易受攻击行或误报），直到找到给定函数的第一个实际易受攻击行。IFA被计算为安全分析员需要检查的误报总数，直到找到第一个实际易受攻击行。低的IFA值表示安全分析员在检查误报时只需要花费较少的工作量。
**结果**。图4展示了我们的LineVul和五种基线方法根据我们的两个评估指标（即Top-10准确度和IFA）的实验结果。

我们的LineVul模型在Top-10准确度上达到了0.65，比其他基准方法的准确度提高了12%至25%。关于Top-10准确度，图4显示LineVul的Top-10准确度达到了0.65，而最先进的方法的Top-10准确度为0.52至0.58。关于IFA，图4显示LineVul的中位数IFA最低，为1，而基准方法的中位数IFA为3至4。这一发现表明，LineVul相比基准方法在线级漏洞定位方面提升了67%至75%，中位数改善率为67%。这些结果验证了我们的LineVul方法比基准方法更准确地进行线级漏洞定位。

换句话说，我们的结果表明，注意机制优于其他模型无关技术。在线级缺陷预测文献中，之前的研究通常使用基于LIME的模型无关技术来解释DL/ML-based缺陷预测模型的预测结果。然而，这些模型无关技术被认为是外在的模型无关技术（即，在模型训练之后应用模型无关技术来解释黑盒的DL/ML模型），而不是内在的模型无关技术（即，DL/ML模型本身是可解释的，因此不需要事后应用外在的模型无关技术）。尽管深度学习被广泛认为是复杂且难以解释的，但本论文是首次尝试利用注意机制来解释基于Transformer模型的预测，并突出了注意机制在线级漏洞定位中的巨大优势。

（RQ3）我们的LineVul在线程级漏洞定位上的成本效益如何？

方法。为了回答这个问题，我们重点评估了我们的LineVul方法在线程级漏洞定位上的成本效益。在实际情景中，最具成本效益的线程级漏洞预测方法应该帮助安全分析师以最小的努力找到最多的实际易受攻击的代码行。因此，让我们假设测试集中的18,864个函数（总计504,886行代码）是安全分析师需要检查的函数。为了衡量我们方法的成本效益，我们首先从LineVul方法获取预测结果。然后，我们根据预测概率对预测的函数进行排序。在预测为易受攻击的函数中，我们根据我们方法第三步得到的线程分数，按降序排列代码行。因此，得分最高的代码行（即可能易受攻击）将排在前面。然后，我们使用以下指标评估成本效益：
1）Effort@20%Recall测量了安全分析师为找到实际20%易受攻击代码行而需要花费的工作量（以代码行数为度量）。它的计算方式为用于定位实际20%易受攻击代码行的总代码行数除以测试集中的总代码行数。较低的Effort@20%Recall值表示安全分析师可能需花费更少的工作量来找到实际20%易受攻击代码行。
2）Recall@1%LOC测量了在给定的工作量（即给定测试集中前1%的代码行）下，可以找到的实际易受攻击代码行的比例（即预测正确）。Recall@1%LOC的计算方式为测试集中前1%代码行中被正确定位的易受攻击代码行总数除以测试集中的实际易受攻击代码行总数。较高的Recall@1%LOC值表示一个方法能将许多实际易受攻击代码行排在前面。
结果。图5展示了我们的LineVul和五种基线方法的实验结果，根据我们的两个评估指标（即Effort@20%Recall和Recall@1%LOC）。
我们的LineVul在Effort@20%Recall方面达到了0.75，比其他基线方法低29%-53%。在Effort@20%Recall方面，图5显示LineVul达到了最低的Effort@20%Recall值（0.75%），而基线方法的Effort@20%Recall值在1.06%-1.60%之间。这意味着安全分析师只需检查测试数据集中总代码行数的0.75%（0.75%*504,886=3,786行代码）就能找到实际20%易受攻击代码行（即20%Recall）。因此，这一结果表明我们的方法可能帮助安全分析师用较少的工作量找到相同数量的实际易受攻击代码行。
在Recall@1%LOC方面，图5显示LineVul取得了最高的Recall@1%LOC值（0.24），而基线方法的Recall@1%LOC值在0.13-0.19之间，这表明LineVul相比基线方法在该指标上有26%-85%的显著改进，中位数改进率达85%。这一发现意味着我们的方法可能在相同的工作量下帮助安全分析师找到更多实际易受攻击代码行。

## 讨论

### 为什么能表现这么好

我们对功能级漏洞预测进行了消融研究，以量化我们的LineVul方法的各个组成部分的贡献。总的来说，我们的LineVul方法由三个组件组成：BPE+PretrainingCode+BERT。为了了解每个组件的贡献，我们对每个组件进行了如下修改（用下划线标出）：
• Word-Level+PretrainingCode+BERT：移除BPE子词标记化，改用词级标记化。
• BPE+No Pretraining+BERT：移除预训练，改用非预训练权重初始化BERT。
• Word-Level+No Pretraining+BERT：移除BPE和源代码预训练组件，改用词级标记化和非预训练权重初始化BERT。
我们发现，LineVul中的BPE组件是最重要的。在LineVul中，BPE组件对F-度量的贡献为53.8%。当将BPE组件改为词级标记化，并进行比较（BPE+Pre+BERT和Word-level+Pre+BERT），我们观察到性能从0.91下降到0.42，降低了53.8%。这一发现表明，相比于词级标记化，BPE子词级标记化对源代码的预处理非常有益。我们怀疑源代码通常包含比自然语言（例如英语）更不常见的关键词（例如变量名、标识符）。因此，当使用词级标记化时，代码的语言模型可能无法为这些不常见的关键词生成最有意义的向量表示。相反，当使用BPE子词级标记化时，这些不常见的词（例如['unPremulSkImageToPremul']）会被分解成常见的子词（例如['un'，'Prem'，'ul'，'Sk'，'Image'，'To'，'Prem'，'ul']）。Karampatsis等人在一项针对不同建模选择对源代码语言模型性能影响的研究中发现，利用BPE模型来进行源代码的语言建模具有优势。与他们的结果类似，我们发现使用BPE不仅可以减小唯一词汇的大小，还可以帮助代码的语言模型更好地理解给定子词与其周围子词之间的关系，从而生成更有意义的向量表示，提高准确性。
在LineVul中，预训练组件对F-度量的贡献为12.1%。当比较（BPE+Pre+BERT和BPE+No Pre+BERT）两者的区别在于是否有预训练组件时，我们观察到性能从0.91下降到0.80，降低了12.1%。这是因为预训练的代码语言模型已经学习了来自百万GitHub代码库的令牌关系，因此生成的向量表示比没有预训练的方法更有意义。这一发现证实了使用预训练代码语言模型（即CodeBERT）生成向量表示优于仅在项目特定数据集上训练的方法。
在LineVul中，BPE组件与预训练组件相结合对F-度量的贡献为57.1%。当比较（BPE+Pre+BERT和Word-level+No Pre+BERT）两者的区别在于BPE和预训练是否被修改时，我们观察到性能从0.91下降到0.39，降低了57.1%。

最后但同样重要的是，我们发现我们的LineVul利用了BPE和预先训练，在所有变体中提供了最好的F-measure，比IVDetect提高了160%，突显了LineVul在行级漏洞预测方面的显著进展。

### 我们的LineVul在预测前25个最危险的CWE（常见弱点枚举）方面有多准确？

我们的LineVul能够正确预测到87%的受到前25个最危险的CWE影响的易受攻击函数。CWE是一个列出软件中可能导致安全问题的弱点的列表，其风险严重程度提供指导，以便组织和安全分析人员最好地保护他们的软件系统。为了更好地理解我们的LineVul在实际使用场景中的重要性，我们进行了进一步的调查，以了解我们在前25个最危险的CWE方面的准确性。前25个最危险的CWE是在前两个日历年中经常遇到且影响最大的问题。此类弱点很危险，因为通常很容易找到、利用，并且可以允许对手完全接管系统、窃取数据或阻止应用程序正常运行。由于并非所有前25个最危险的CWE都包含在研究的数据集中，表2列出了包含在数据集中的CWE的结果。我们计算的准确性是真阳率（TPR），重点关注LineVul正确预测的易受攻击函数。我们发现，LineVul在数据集中的CWE类型不同，准确率介于75%（CWE-787越界写入）至100%（CWE-22路径遍历，CWE-77不正确中和）之间。

## 7 相关工作

### 7.1 基于深度学习的漏洞预测

传统上，基于机器学习的漏洞预测方法是通过使用软件度量作为特征（例如，代码复杂性）提出的[45, 66]。软件度量的使用在缺陷预测研究中也被广泛采用[24, 25, 49, 50, 53–57, 63]。然而，这类软件度量的收集是手动且耗时的。因此，多个基于深度学习的方法已被提出，以自动从历史数据中学习漏洞模式[12, 30–33, 39, 43, 65]。
因此，我们采用了基于循环神经网络（RNN）的体系结构（即LSTM），以自动学习源代码的语义和句法特征[14, 43]。例如，Russell等人[43]提出了一种基于RNN的体系结构，用于自动提取源代码的特征，以进行漏洞预测。Dam等人[14]提出了一种基于LSTM的体系结构，用于自动学习源代码的语义和句法特征。然而，基于RNN的方法通常假设源代码是一系列的标记，而不考虑源代码的图结构（例如，抽象语法树），这导致了不准确的预测。
因此，Li等人[33]提出了VulDeePecker，这是一种基于RNN的模型，它从源代码的不同类型的图属性（例如，数据依赖图）中进行学习。然而，VulDeePecker方法仍然以顺序方式学习图属性，而没有利用图神经网络。因此，最近一种图神经网络已被用于学习源代码的图属性，以进行漏洞预测。例如，Zhou等人[65]利用图神经网络学习源代码的四种图属性，即抽象语法树、控制流图、数据流图和句法特征。Chakraborty等人[12]提出了Reveal，这是一种门控图神经网络（GGNN），用于学习源代码的图属性。
尽管这些研究集中于文件/函数级别的漏洞预测，但我们的LineVul关注的是行级漏洞预测问题，这个问题目前仍然很少有人探索。

### 7.2 Line-Level漏洞预测

尽管有各种各样的漏洞预测方法被提出，但它们主要关注的是文件、函数、方法级别的粒度，这仍然是粗粒度的。因此，Li等人提出了基于程序切片技术的VulDeeLocator，用于缩小漏洞定位的范围。此外，Li等人还提出了IVDetect，它利用图神经网络（GNN）进行函数级预测，并使用GNNExplainer来确定哪个子图对预测最有贡献。然而，安全分析师仍然需要手动确定子图中哪些行实际上是有漏洞的。
类似地，行级缺陷预测最近受到研究界的高度关注。例如，Pornprasit和Tantithamthavorn以及Wattanakriengkrai等人提出了一种基于机器学习的方法，采用LIME模型不可知技术（BoW+RF+LIME）来预测哪些行在未来可能有缺陷。然而，这些方法只学习了文件中代码标记出现的频率（即词袋模型），而没有考虑源代码的词法和语义（即代码标记的顺序）。
据我们所知，本文是首次利用BERT架构内部的注意力机制用于行级漏洞预测。

### 7.3 可解释性软件工程中的人工智能（AI） 

人工智能模型在软件工程领域的可解释性成为了一个研究的重大挑战[51]（请参考http://xai4se.github.io），因为从业者通常不信任预测结果[52]，这妨碍了人工智能软件开发工具在实践中的应用。最近，可解释的人工智能在缺陷预测领域受到了积极的研究[52, 58]。例如，近期的研究展示了一些成功的案例研究，使得缺陷预测模型更实用[38, 60]、可解释[22, 28]和可行动[40, 41]。然而，这些研究仅关注解释传统机器学习模型，而不是复杂的黑盒深度学习模型。

最近，研究人员开始探索在不同软件工程任务中人工智能模型的可解释性（即利用注意力权重为预测结果提供有意义的“解释”）。例如，Fu和Tantithamthavorn[18]提出了基于GPT-2的敏捷用户故事点估计方法，通过利用集成梯度注意力机制来解释GPT-2模型，并了解JIRA问题报告中的哪些词对敏捷用户故事点估计有贡献。类似地，Pornprasit和Tantithamthavorn[39]提出了一种用于行级缺陷预测的分层注意力网络（HAN）架构，通过利用HAN架构的注意力机制来理解源代码中哪些代码标记对缺陷文件的预测有贡献。然而，Jain等人[21]认为学习到的注意力权重经常与基于梯度的特征重要性度量不相关，而Wiegreffe等人[61]认为这种注意力权重的准确性/可靠性可以提供有意义的解释，这取决于定义和实验设计的严谨性。

据我们所知，本文是首次利用BERT架构的注意力机制进行行级漏洞预测。这一概念与Wiegreffe等人[61]在人工智能领域的发现完全契合。然而，对于行级漏洞预测，这个概念仍然是新颖的，因为之前的研究[18, 39]只关注解释敏捷用户故事点估计和缺陷预测，而不是基于CodeBERT的行级漏洞预测。我们在RQ2和RQ3中的结果验证了使用自注意机制在行级漏洞预测方面的优于其他模型无关技术。

对构建有效性的威胁与数据集选择相关。在进行实验时，我们使用了Fan等人[16]的数据集。其他数据集[12, 65]未被选择，因为它们只提供了函数级别的基准，而不适用于我们的研究范围。因此，我们使用了与IVDetect相同的数据集进行公平比较。

此外，我们的行级预测结果（RQ2和RQ3）不与IVDetect [30]进行比较，因为它们的解释是基于子图而不是行。由于局部解释的粒度不同，因此比较是不可行的。此外，LIME [42]在先前的缺陷预测研究中被广泛使用[22, 23, 38, 40, 41]，但由于其最适用于机器学习技术而不是复杂的深度神经网络，我们没有使用它。为了减轻这一威胁，我们将我们的方法与许多其他适用于深度神经网络的先进模型无关技术进行了比较，例如Layer Integrated Gradient [48]、Saliency [47]、DeepLift [46]和基于SHAP的技术[36]。我们的实验结果仍然证实了我们LineVul中使用的自注意力超过了其他基线方法。

### 8.内部有效性的威胁

与微调我们的LineVul模型时的超参数设置有关。我们使用了冯等人[17]指定的默认超参数设置。由于调节超参数对于由数百万参数组成的基于BERT的模型来说是非常昂贵的，我们只调节了学习率，并将其最终设置为2𝑒−5。

我们的方法的窗口大小限制为512个标记。因此，我们的方法可能无法完全学习超过512个标记的任何函数。然而，为了最大化使用CodeBERT预训练模型的好处，最好不要扩展窗口大小。因此，扩展我们方法的窗口大小可以在未来的工作中进行探索。

在RQ1中，我们重新使用了Li等人[30]的IVDetect结果，我们无法验证其准确性。虽然Li等人[30]提供了一个用于未来研究的复制包，但我们仍努力复现了IVDetect方法的结果。不幸的是，我们无法重新运行他们的实验脚本。其他人也有这种担忧[6]。为了减轻这一威胁，我们不得不在RQ1中重新使用IVDetect的结果，以确保在实现基线方法时不存在潜在的偏见。尽管如此，我们严格遵循了IVDetect的实验设置，以确保我们使用了相同的数据分割策略进行公平比较（80%用于训练，10%用于验证，10%用于测试）。此外，本文未考虑基于时间的评估场景，因为数据集是在函数级别上而不是提交级别上。为了减轻这些威胁，我们公开了我们的复制包，以提高我们工作的透明度。

在RQ2中，对于超过10行的函数大小，Top-10准确率才有意义。我们观察到有16%的易受攻击函数（1,840/10,900）少于10行。因此，对于大多数易受攻击函数（84%），Top-10准确率仍然有意义。为了减轻这个威胁，我们尝试了其他𝑘值（即Top-3和Top-5准确率）。我们发现我们方法中使用的注意机制仍然表现出色（请参阅我们复制包中的附录）。因此，𝑘值不对我们结果的有效性构成任何威胁。

对于外部有效性，我们的LineVul方法的推广性是一个问题。我们使用了大规模的行级漏洞数据集（即Fan等人的数据集）来保证与IVDetect方法[30]的公平比较。因此，未来的工作可以探索其他行级漏洞数据集。

## 9 结论

在本文中，我们提出了一种基于Transformer的漏洞预测方法LineVul，用于预测哪些函数会存在漏洞，以及哪些代码行是存在漏洞的。通过对一个包含188,000多个C/C++函数的大规模真实数据集进行实证评估，我们展示了LineVul在以下方面的表现：（1）在函数级别预测上，F1-measure提高了160%-379%；（2）在代码行级别预测上，Top-10准确率提高了12%-25%；（3）在触发20%召回率的情况下，工作量减少了29%-53%。我们的结果证实LineVul比现有的漏洞预测方法更准确、更细粒度。因此，我们期望LineVul可以帮助安全分析人员以一种具有成本效益的方式找到存在漏洞的代码行。