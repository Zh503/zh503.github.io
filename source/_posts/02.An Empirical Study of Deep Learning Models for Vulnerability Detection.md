---
title: An Empirical Study of Deep Learning Models for Vulnerability Detection
date: 2024-04-17 17:25:25
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
---
## 摘要

近年来，代码的深度学习模型在漏洞检测方面取得了很大的进展。在某些情况下，基于深度学习的模型表现超越了静态分析工具。尽管已经提出了许多出色的模型，但我们对这些模型仍然没有很好的理解。这限制了模型在漏洞检测方面的进一步发展，包括模型的鲁棒性、调试和部署。在本文中，我们对两个广泛使用的漏洞检测数据集（Devign和MSR）进行了调研和复现了9个最先进的深度学习模型。我们在三个方面，即模型能力、训练数据和模型解释上研究了6个研究问题。我们通过实验证明了同一模型在不同运行中的变异性以及不同模型输出之间的低一致性。我们比较了针对特定类型漏洞进行训练的模型和同时针对所有漏洞进行训练的模型。我们探讨了深度学习可能认为“难以处理”的程序类型。我们研究了训练数据规模和组成对模型性能的影响。最后，我们研究了模型的解释，分析了模型用于做出预测的重要特征。我们相信我们的发现可以帮助更好地理解模型结果，提供有关准备训练数据的指导，并提高模型的鲁棒性。我们的所有数据集、代码和结果都可以在https://doi.org/10.6084/m9.figshare.20791240上找到。

## 引言

近年来，深度学习漏洞检测工具取得了令人瞩目的成果。最先进的模型报告了0.9的F1得分[15]，[35]，并且优于静态分析器[6]，[12]。这些结果令人兴奋，因为深度学习可能为软件保障带来革命性的变化。因此，IBM、谷歌和亚马逊等工业公司对开发这种工具和数据集表现出了极大的兴趣，并进行了大量的投资[19]，[27]，[30]，[46]。尽管前景看好，但深度学习漏洞检测还没有达到计算机视觉和自然语言处理的水平。我们的大部分研究都集中在尝试新兴的深度学习模型，并使其适用于像Devign或MSR数据集这样的数据集[13]，[27]，[47]。然而，我们对这个模型了解甚少，例如，模型能否很好地处理哪种类型的程序，是否应为每种漏洞类型构建不同的模型，是否应该为所有漏洞类型构建一个模型，怎样才是一个好的训练数据集，以及模型在做出决策时使用了哪些信息。了解这些问题的答案可以帮助我们更好地开发、调试和实践这些模型。然而，考虑到深度学习的黑盒特性，这些问题非常难以回答。本文并不打算为这些问题提供完整的解决方案，而是探索这些目标的一种尝试。本文调查并复现了一系列最先进的深度学习漏洞检测模型，并提出研究问题和研究，以理解这些模型，旨在提炼出更好地设计和调试未来模型的经验和指南。据我们所知，这是第一篇系统调查和比较各种最先进的深度学习模型的论文。在过去，Chakraborty等人[7]曾对VulDeePecker [24]、SySeVR [23]和Devign [47]等四种现有模型进行了探索，并指出用合成数据训练的模型在实际测试集上的准确率较低，并且模型利用变量名等虚假特征进行预测。

我们构建了我们的研究问题，并将其分类为三个领域，即模型能力、训练数据和模型解释。具体而言，我们的第一个目标是了解深度学习在处理漏洞检测问题方面的能力，尤其是关于以下研究问题：

• RQ1 模型在漏洞检测结果上是否达成一致？不同模型的运行结果以及不同模型之间的变异性是什么？

• RQ2 是否有某些类型的漏洞更容易被检测到？我们应该为每种类型的漏洞构建单独的模型，还是应该构建一个能够检测所有漏洞的模型？

• RQ3 是否存在某些代码特征使当前模型更难正确预测程序的行为，如果存在，那些代码特征是什么？

我们的第二个研究关注于训练数据。我们的目标是了解训练数据的大小和项目组成对模型性能的影响。具体而言，我们构建了以下研究问题：

RQ4：增加数据集大小是否有助于提高漏洞检测模型的性能？

RQ5：训练数据集中的项目构成对模型性能有何影响？

最后，我们的第三个研究领域是模型解释。我们使用了最先进的模型解释工具进行了调查：

RQ6：模型在预测过程中使用了哪些源代码信息？这些模型在重要特征上是否达成一致意见？

为了回答研究问题，我们对最先进的深度学习模型进行了调查，并成功在其原始数据集上复现了11个模型（详见第二部分）。这些模型采用了不同的深度学习架构，如图神经网络（GNN）、循环神经网络（RNN）、长短时记忆网络（LSTM）、卷积神经网络（CNN）和Transformer。为了比较这些模型，我们设法让9个模型在Devign和MSR这两个流行的数据集上工作。我们选择了这两个数据集，原因如下：（1）这两个数据集都包含真实世界的项目和漏洞信息；（2）大多数模型在论文中都是使用Devign数据集进行评估和调优的；（3）MSR数据集包含310个项目，数据有关于漏洞类型的注释，这对于我们的研究问题很有必要。我们通过精心设计的实验（第三部分）和威胁考虑（第四部分）发现了我们的6个研究问题的答案。总之，我们的研究贡献包括：

1）我们对深度学习漏洞检测模型进行了全面调查。

2）我们提供了一个复现包，包括11个最先进的深度学习框架的训练模型和数据集，具有各种研究设置；

3）我们设计了6个研究问题，以了解模型的能力、训练数据和模型解释性；

4）我们进行了研究，并通过实验获得了关于研究问题的结果；

5）我们为深入研究模型的可解释性准备了有趣的示例和数据。

## 模型及其再现概览

为了收集最新的深度学习模型，我们研究了从2018年到2022年的论文，并使用了微软的CodeXGLUE排行榜1和IBM的缺陷检测D2A排行榜2。我们与所有能找到的开源模型一起工作，并成功复现了11个模型。完整的模型列表以及我们未能复现某些模型的原因在我们的数据复制包中给出。

如表I所示，复现的模型涵盖了各种深度学习体系结构。Devign [47]和ReVeal [7]在属性图上使用GNN，将控制流、数据依赖和AST整合在一起[47]。ReGVD [31]在标记上使用了GNN。Code2Vec在AST上使用了多层感知器（MLP）。VulDeeLocator [22]和SySeVR [23]基于RNN和双向LSTM的序列模型。最近的深度学习检测使用了预训练的转换器，包括CodeBERT [14]、VulBERTa-CNN [16]、VulBERTa-MLP、PLBART [2]和LineVul [15]。

对于我们的研究问题，我们使用了Devign [47]和MSR [13]数据集。我们研究了这11个模型的原始论文中使用的数据集，表I中标为"Dataset"的部分。我们发现，Devign数据集已经在11个模型中的8个进行了评估和调整。它是一个平衡的数据集，包含大约相同数量的易受攻击和非易受攻击的例子，总共有27,318个数据点（每个例子也称为一个数据点）。LineVul使用了MSR数据集，这是一个较新的可用数据集。它是一个不平衡的数据集，包含10,900个易受攻击的例子和177,736个非易受攻击的例子。这些例子都标有它们的源代码项目和它们的Common Weakness Enumeration（CWE）条目，表示漏洞的类型。我们利用数据集的这些特征来回答我们的某些研究问题。

![image-20240326103418071](https://s2.loli.net/2024/03/26/FumeihvagpXkjD7.png)

我们按照表II中的原始数据集和设置复现了这些模型的结果。列A、P、R和F表示深度学习漏洞检测中常用的度量标准，包括准确率、精确率、召回率和F1值。我们的复现结果与原始论文相比，一般可以在2%的误差范围内计算。例外是ReVeal，作者确认我们的结果修正了原始论文中的数据泄露错误，以及Devign，我们使用了Chakaborthy等人发布的第三方复现结果[7]，因为原始的Devign代码未开源。

为了能够比较这些模型，我们改进了模型的实现，以支持Devign和MSR数据集。在进行研究问题的实验时，我们排除了VulDeeLocator和SeSyVR，因为它们无法轻松地修改为Devign和MSR数据集。因此，我们在研究这些研究问题时使用了其余的9个模型。

对于我们的研究问题，我们使用了Devign [47]和MSR [13]数据集。我们研究了这11个模型在它们原始论文中使用的数据集，这些数据集显示在表格I的数据集栏目下面。我们发现，在这11个模型中，Devign数据集在8个模型中被评估和调优过。它是一个均衡的数据集，包含大致相同数量的易受攻击和非易受攻击的示例，总共有27,318个数据点（每个示例也被称为一个数据点）。LineVul使用了MSR数据集，这是一个较新的可用数据集。它是一个不平衡的数据集，包含10,900个易受攻击的示例和177,736个非易受攻击的示例。这些示例都标有它们的源代码项目和它们的常见弱点枚举（CWE）条目，这表示了漏洞的类型。我们利用这些数据集的特征来回答我们的一些研究问题。

我们使用原始数据集和设置复现了这些模型的结果，结果显示在表格II中。A、P、R和F列代表了深度学习漏洞检测中常用的指标，包括准确率、精确率、召回率和F1值。总体而言，我们的复现结果与原始论文的结果相差不超过2%。但是，ReVeal是个例外，作者证实我们的结果修复了原始论文中的数据泄露错误。而Devign则使用了Chakaborthy等人发布的第三方复现，因为原始的Devign代码没有开源。

为了进行模型之间的比较，我们改进了模型的实现，支持Devign和MSR数据集。在进行研究问题的实验时，由于VulDeeLocator和SeSyVR不能轻松修改用于Devign和MSR数据集，我们排除了它们。因此，我们使用了其余的9个模型进行研究。

## 研究问题和结果

我们将研究问题分为三个方面，即模型能力、训练数据和模型解释。请参阅分别的第III-A至III-C小节。对于每个研究问题，我们介绍了动机、研究设置和我们的发现。

![image-20240326104222451](https://s2.loli.net/2024/03/26/l1aDFYpiwcmrTRz.png)

###### 模型在原始数据集上的重现。复制结果以 3 个随机种子的平均值报告。-"表示论文中没有报告某个指标的结果。数字以百分比表示。

### A. 深度学习模型的能力

**研究问题1**：模型在漏洞检测结果上是否一致？不同运行时的模型和不同模型之间有哪些变异性？

**动机**：众所周知，使用不同的随机种子进行训练时，深度学习模型的性能表现可能会有所变化。在这个研究问题中，我们旨在衡量在漏洞检测中，这种变异性实际上存在多少。此外，我们还想要探索在不同深度学习模型之间以及具有相似体系结构的模型之间，存在多少一致性。我们希望我们的研究结果可以让开发人员和研究人员了解到，这些工具报告的数字背后可能存在的不确定性。

**研究设置**：我们使用了Devign数据集相同的训练/验证/测试数据分区，使用了3个不同的随机种子训练了模型。我们选择这个数据集是因为几乎所有的模型都在其上调整了超参数。我们测量了稳定输入的百分比，即具有相同二进制标签的输入（对于3个随机种子而言）。然后，我们比较了这些稳定输入在不同模型之间的一致性。

**研究结果**：在表III中，我们报告了整个数据集、全部稳定输入和测试数据集下的稳定输入的百分比。我们还报告了在测试数据集上，F1得分在3个种子之间的变异性，即stdev-testF1。

我们的结果显示，平均而言，34.9%的测试数据（总数据的30.6%）根据训练时所使用的种子产生了不同的预测结果。在处理属性图的GNN模型中，可变性排名前两位；特别是对于ReVeal，50%的测试数据在多次运行中的输出结果有所改变。与GNN和变换器模型相比，Code2Vec的可变性最小。有趣的是，我们发现不稳定的输入与更多的错误预测相关——对于稳定的输入，在所有种子上共有19%的错误预测，而不稳定的输入则有47%。

尽管许多示例在多次运行中产生了不同的预测结果，但我们发现F1测试分数的变化并不大，平均标准偏差为2.9。也就是说，对于大多数模型来说，我们预计在多个随机种子上进行多次性能测量时，有95%的性能测量结果将在平均性能上下5.8%的范围内。

![image-20240326104156544](https://s2.loli.net/2024/03/26/h9J7AV3ZEuUPyMx.png)

###### 表格3 Devign 数据集上 3 个随机种子的变异性

表格IV显示，深度学习模型学习到了不同的分类器，因为只有7%的测试数据（以及7%的总数据）被所有模型所认同。三个GNN模型在20%的测试样例（以及25%的总体数据）上达成了一致，而三个表现最佳的转换器模型（LineVul、PLBART和VulBERTa-CNN）在34%的测试数据（以及44%的总体数据）上达成了一致。然而，当我们比较了所有5个转换器模型时，只有22%的测试样例（以及29%的总体数据）达成了一致。不同模型之间的低一致性意味着，在没有基准标签的情况下，通过将模型进行比较作为神谕的差分测试方法可能存在限制用途。

![image-20240326104143541](https://s2.loli.net/2024/03/26/pikdzRnPw2t9eMc.png)

###### 表格IV 不同模型之间的一致性

**研究问题2**：某些类型的漏洞是否更容易检测？我们应该为每种类型的漏洞建立模型，还是建立一个可以检测所有漏洞的模型？

**动机**：在传统的软件保障技术（如程序分析）中，我们使用不同的算法来检测不同类型的漏洞。某些类型的漏洞，如无限循环，比其他类型的漏洞，如内存泄漏，更难以检测，因为前者需要跟踪符号值并进行循环推理，而后者只需要检查内存释放是否在其分配之后调用。在这个研究问题中，我们希望了解对于深度学习漏洞检测器来说，是否也存在某些类型的漏洞比其他类型更容易检测。考虑到不同类型的漏洞有不同的语义和根本原因，我们还想了解我们是否应该为每种类型的漏洞或者漏洞的整体（不分开分类）构建模型，就像大部分现有工作所做的一样。

**研究设置**：在这里，我们基于漏洞类型研究模型，因此我们使用了MSR数据集。MSR数据集中的示例带有CWE 4的注释。我们根据这些CWE类型将漏洞分组为5个类别，即缓冲区溢出、值错误、资源错误、输入验证错误和权限升级，如表V中的漏洞类型所示。我们的准则是：（1）每个组包含具有相似根本原因和语义的错误；（2）每个组都有足够大的数据集来有效地训练模型。列“总计”列出了从MSR数据集中收集到的示例数量，包括所有有CWE注释的易受攻击和修复过的示例。

具体而言，缓冲区溢出是由于读取或写入缓冲区范围之外的内存引起的，例如CWE125“越界读取”和CWE-787“越界写入”。我们的数据集中给出了将完整的CWE列表映射到这5个组的方法。值错误包括CWE-190“整数溢出”，CWE-369“除以零”和CWE-682“错误计算”的示例。此类错误是由于通过数据处理或算术运算传播不正确的值引起的。资源错误是由于错误释放或使用资源（如内存或文件指针）引起的，通常使用类型状态分析[36]来检测。CWE示例包括CWE-415“重复释放”和CWE-404“不正确的资源关闭”。输入验证错误是由于使用未经验证的外部输入，例如CWE-134“使用外部可控格式字符串”和CWE-89“未正确中和SQL命令中使用的特殊元素”（“SQL注入”）。这些错误通常使用污点分析[40]来检测。最后，权限升级是由于缺少适当的权限检查而允许未经授权的实体执行特权命令或查看特权数据，例如CWE-264：“权限、特权和访问控制”和CWE-255：“凭证管理错误”。

![image-20240326104309121](https://s2.loli.net/2024/03/26/LntsPGWyIzicSX3.png)

我们按照80%/10%/10%的比例将每个漏洞类型的数据集分为训练、验证和测试数据集。我们使用了5组漏洞训练了5个模型，以及一个综合模型，该模型使用了所有漏洞类型的数据进行训练，以进行比较。这反映了现实世界的情况，即使用特定漏洞类型进行训练的模型可能更加专注，但综合模型能够使用更多数据进行训练。我们报告了每个模型在相同漏洞类型下的性能，以及在不同漏洞类型下的交叉性能。相同漏洞类型性能报告了在训练和测试数据具有相同漏洞类型时的测试F1分数。交叉漏洞类型性能报告了在训练和测试数据具有不同漏洞类型时的测试F1分数。

在这个实验中，VulBERTa-CNN、VulBERTa-MLP和一些Code2Vec的模型没有报告有效的结果，因为它们总是在测试数据上预测相同的类别。

**结果**：我们在图1中呈现了我们的结果。柱形图报告了相同缺陷类型设置下的F1分数，圆圈报告了跨缺陷类型的表现。每种缺陷类型与4个跨缺陷类型的测试集相关联，因此每个柱状图有四个圆圈，除了合并模型有五个圆圈，每个圆圈代表对合并模型上的某个缺陷类型进行测试。

分析相同缺陷类型的表现，我们发现模型并不总是一致认为哪种类型的漏洞最容易，不同类型的漏洞在不同模型中的F1分数最高。有趣的是，输入验证和资源错误（橙色和红色柱形图）的性能通常比其他类型低。相反，缓冲区溢出和值错误（蓝色和紫色柱形图）通常报告比其他类型更好的性能。在传统程序分析中，这些类型更难检测，因为它们需要跟踪变量的值，并且有时需要推理循环。

Devign和ReVeal在属性图上使用了GNN架构。它们的柱形图显示了相似之处。对于其他模型而言，资源错误（红色柱形图）在5种漏洞类型中表现最差。一个可能性是资源分配和释放可能在代码中相隔很远，Transformer模型无法捕捉到这种长距离的依赖关系。另一个可能性是这种错误涉及多种资源，训练数据集可能不包含足够的数据让模型提取模式。

综合模型（棕色柱形图）通常比针对特定漏洞类型训练的模型性能较差，但对于某些漏洞类型，如输入验证和资源错误，综合模型可能表现更好。例如，对于CodeBERT，综合模型的F1比其他5个模型都高。棕色柱形图内的圆圈显示了权限提升和资源错误的准确性相对较低，但对于所有漏洞类型，综合模型的性能较类型特定模型更好。

分析跨缺陷类型的表现，我们发现除了LineVul外，跨缺陷类型的检测通常表现较差，这意味着不同的漏洞类型代表了不同的数据分布。LineVul似乎很好地处理了值错误。当应用其他漏洞训练的模型时，值错误的性能比相同缺陷类型的性能更高。

**研究问题3**：在当前的漏洞检测模型中，具有一定代码特征的程序是否更难以被正确预测？如果是的话，这些代码特征是什么？

**动机**：在这里，我们研究了是否可以对不能被良好预测且对深度学习模型来说“困难”的程序进行特征化，并且不同的模型是否对这些困难达成共识。了解我们无法处理的程序可以为我们未来的改进工作提供一个良好的目标。在程序分析中，我们知道某些特征很难处理，比如循环和指针。我们想知道这些特征是否对深度学习也很困难。

**研究设置**：在第一步中，我们准备了一个代码特征清单进行研究。我们认为与程序分析工具进行比较，了解哪些类型的程序很难处理是很有趣的。因此，我们的方法是列出对程序分析很重要的代码特征，然后检查它们是否对深度学习工具也产生了影响。
我们总共获取了12个代码特征。其中一些与控制流相关，例如while、for、if、goto、call和switch的结构，以及break、continue、return的无条件跳转；一些与数据结构和指针相关，例如数组和指针（包括字段访问）；最后一些是辅助结构，如注释和宏。基于这个特征清单，我们使用树句法分析器(tree-sitter 5 parser)计算每个函数中代码特征的频率。
为了了解是否某些代码特征使得深度学习模型更难预测，我们使用了多元逻辑回归（LR）模型（参见公式1）将代码特征与函数正确预测的可能性联系起来。如果具有某些代码特征的函数更可能被正确预测，我们认为它对深度学习来说更容易，反之亦然。在公式1中，给定一个具有特定特征构成的函数，Y表示深度学习模型预测其正确的概率。$x_i$表示函数中每个代码特征的计数。$β_i$是从数据中学习到的系数。每个$β_i$与一个代码特征$x_i$相关。当$β_i$为负时，值$β_i * x_i$会降低正确预测的概率，因此我们将这些特征称为模型难以处理的困难特征。同样，具有正系数的代码特征被称为容易特征。同时，较大的$β_i$意味着代码特征$x_i$计数的增加会大幅增加正确预测的概率，反之亦然。
$$
Y = σ(∑ _i β_i ∗ x_i + β_0) --------(1)
$$
我们在验证集上训练了逻辑回归模型，并使用训练好的模型从测试集中找出难易例子。为了量化测试集中的例子的难度，我们使用了逻辑回归模型中的逻辑输入，即通过sigmoid函数计算的logit：$l(x) = ∑_ i β_i ∗ x_i$。

我们将这个量的否定称为困难分数。具有更高困难分数的函数被预计比具有较低困难分数的函数更有可能被错误预测。为了评估这个LR模型的效果，我们从测试集中选择了难度分数排在前10%和后10%的案例，并对它们进行了排序。然后，我们通过比较LR模型在我们选择的简单和困难数据集上的性能来评估LR模型的预测结果。

值得注意的是，最初我们尝试了统计显著性测试和基于相关性的方法来将代码特征与模型准确性联系起来。然后，我们意识到这些方法一次只考虑一个特征。例如，具有3个循环、400个指针和500个宏的函数表现良好，而具有300个循环、300个指针和100个宏的函数表现不佳。我们无法确定性能差异是由循环、指针还是宏引起的。另一方面，LR模型一次考虑了多个代码特征，并考虑了这些特征之间的组合效应。

![image-20240326105129856](https://s2.loli.net/2024/03/26/7fMBdarkyNCxQw9.png)

###### 在 Devign 数据集上，根据 LR 模型难度分值选择的评估集上的性能比较，3 个随机种子的平均值。"原始 "是在原始测试集上的性能，如表 II 所示。

![image-20240326105154030](https://s2.loli.net/2024/03/26/bCMFrP8yNehpgI3.png)

###### 在 Devign 数据集中的稳定示例上训练的 LR 模型的系数

结果：图2显示，所有9个模型在简单数据集上的表现都优于困难集。所有模型的简单/困难表现之间的平均差异为10.3%。对于大多数模型（9个模型中的7个），原始测试集的表现位于困难集和简单集的表现之间。这些结果表明，LR模型和难度评分在选择深度学习模型的困难和简单示例方面是有效的。

图3绘制了针对每个深度学习模型训练的LR模型中每个代码特征的系数。我们发现，所有模型的call、length和pointers特征的点都被聚集在一起，这意味着所有模型都对这些特征的重要性达成一致。有趣的是，所有这些点都位于接近0的位置，这表明这些特征没有很大的影响。另一方面，for、goto、if、jump、switch和while的特征在不同模型之间有所变化。这些都是与控制流相关的结构。

我们还观察到，对于所有的模型，数组和switch与正系数相关联，而对于大多数模型，if、goto和while的系数属于负数范围。特别是，if在所有模型中的系数都是负数。程序中if、goto和while的数量多意味着其具有较高的圈复杂度[29]，而这类型的程序对于程序分析来说也是具有挑战性的。特别是基于属性图的模型（如Devign）使用了控制流信息，因此对于、goto、jump和while的特征都是负数（较难）。

B.训练数据

研究问题4：增加数据集大小是否有助于改善漏洞检测模型的性能？

动机：获取高质量的漏洞检测数据很困难。过去，我们使用了静态分析和挖掘变更提交等自动标记方法。这些方法可能引入错误的标签[7]。我们还使用了手动标签[47]，但制作速度较慢[25]。这个研究问题帮助我们了解当前可用的数据集是否足够大来训练模型，以及增加数据集大小是否能显著提高模型性能。

研究设置：为了调查这个研究问题，我们结合了Devign和MSR数据集，即不平衡数据集。由于Devign中使用的项目与MSR中使用的项目重叠，我们排除了82个重复的示例，其中提交ID匹配。这样总共产生了194,285个示例的数据集。由于一些已发布的模型最初是在平衡模型（如Devign）上进行调整的，所以我们还构建了一个平衡数据集，其中包含45,363个示例，通过获取MSR中的所有易受攻击的示例，然后随机下采样相同数量的非易受攻击的示例而得到。对于每个数据集，我们保留10%的数据作为所有模型的测试集。然后，我们准备了剩余数据的10%、20%...90%、100%来训练10个模型，观察当数据集大小增加时，测试集的F1分数如何变化。此外，我们还准备了两个小型数据集，分别使用总数据量的1%和5%来实验，以确定模型学习所需的最小数据量。

研究结果：我们在图4中总结了我们的结果。图4a和图4b显示了类似的趋势。一般来说，随着数据增加，所有模型的性能都有所提高。然而，这种改善并不显著。将100%的数据与10%进行比较，对于平衡数据集，测试集的F1得分在所有模型上取平均时没有差别。对于不平衡数据集，F1得分平均提高了0.16。在图4a中，各模型中只有LineVul在每次增加10%的数据时一直有不断的改进。其他模型在增加训练数据集时波动，这表明增加数据并不总是有益的。例如，对于VulBERTa-MLP，F1值在增加数据集大小的过程中平均下降了0.1。使用100%数据集训练的模型性能比使用10%数据集训练的模型性能下降了0.08。看来除了数据集大小外，还有其他因素在性能方面起了更重要的作用。

![image-20240326105807988](https://s2.loli.net/2024/03/26/2TpdE8NXJ5PsQuj.png)

在图4b中，ReVeal是随着数据集增加而改善最多的模型。在使用100%数据集时，ReVeal接近最佳模型LineVul。然而，Devign使用了类似构建GNN的架构，却没有显示出额外数据的好处。使用小数据集进行的实验（包括1%和5%的总数据量）表明令人惊讶的是，除了CodeBERT之外，对于大多数模型，只需使用5%的数据（约2268个数据点和1134个易受攻击的示例）就可以达到良好的性能。当使用平衡数据进行学习时，这一点出现得稍晚一些。例如，ReGVD和CodeBERT需要总数据量的50%（96.4k）和30%（57.8k）。其他模型需要大约5-10%的数据（9.7k-19.4k）来达到高点。有趣的是，这个数据集中有10.8%的易受攻击的示例；也就是说，模型需要大约1048-2095个易受攻击的示例才能达到良好的性能，与平衡数据集的设置相当。

![image-20240326105815847](https://s2.loli.net/2024/03/26/dMvBiD47Je5nxlO.png)

**问题5**：培训数据集中项目的组成如何影响漏洞检测模型的性能？

**动机**：在这个问题中，我们旨在进一步了解如何为漏洞检测组合一个良好的培训数据集。具体而言，我们想知道培训数据集中的项目多样性是否有助于漏洞检测。我们还想了解不同的项目是否确实代表不同的分布，以便当测试和培训数据来自同一项目时，模型可以显著提高性能；而当培训和测试数据来自不同的项目时，模型是否能够推广到未见过的项目。

**研究设计**：我们为这项研究设计了两个实验。在第一个实验中，我们准备了一个非多样性的培训数据集和一个多样性的培训数据集，并将使用这两个数据集训练的模型在同一测试集上进行比较。在MSR数据集中，我们发现Chrome包含76k个示例，是所有310个项目中最大的。我们将它用作非多样性数据集。我们在5折交叉验证设置中进行了这个实验，以消除在选择项目时可能存在的潜在偏差。对于每一折，我们从MSR数据集中随机抽取了10k个示例作为测试集。然后我们排除了Chrome和测试集中使用的项目，并从剩余项目中随机抽取了76k个示例（与Chrome相同数量）。多样性数据集在5个折叠中的平均项目数量为50.6个。

在第二个实验中，我们准备了一个混合项目的设置，其中测试集与训练集分开，不考虑源项目，并且训练集和测试集中的一些示例可能来自同一项目。这是我们深度学习论文评估的设置。我们还构建了一个跨项目的设置，测试集示例必须来自与训练集中表示的项目不同的项目。这个设置可以帮助我们了解当使用未见过测试项目的现成训练的深度学习漏洞检测模型时，是否会有显著的性能降低。

我们还在5折交叉验证设置中使用了MSR数据集。对于每一折，我们首先通过将所有来自随机选择的项目的示例包括在内来构建跨项目设置的测试集，直到集合中至少包含10k个示例。由于每个项目的示例数量不同，结果集略大于10k个示例。然后，我们通过将剩余的示例随机分成测试集（10 k）、验证集（10 k）和训练集（其余示例，约158 k）来构建混合项目设置的测试集。我们使用158 k个训练示例和10 k个验证集来训练模型，然后在跨项目设置和混合项目设置的测试集上运行。

**结果**：第一次实验的结果见图5。我们使用箱线图来总结5折交叉验证的结果。令人惊讶的是，我们发现对于所有模型来说，多样化的训练集与只包含Chrome的训练集相比，并没有带来任何好处。事实上，6个模型中有5个模型在非多样化数据上训练后报告了更高的中位性能。

对于第二次实验，图5b显示混合项目在所有模型中表现得明显优于交叉项目（F1得分的平均差异和最大差异分别为0.11和0.32）。这意味着通过观察来自同一项目的数据确实可以帮助预测其他同一项目的数据。与直接使用已经训练好的现成模型相比，漏洞检测可以极大地受益于定制训练模型。对于LineVul来说，5个折叠在交叉项目设置中报告了非常不同的性能，这表明对于给定的目标测试集，某些项目比其他项目更适合用于训练。结果还暗示模型可能会从数据集的项目特定属性（如风格、语言特征或命名约定）中学习检测漏洞的能力。我们相信这有助于进一步研究关于bug普遍性的因果检测。

**C.深度学习的内部原理**

**RQ6** 模型用什么代码信息进行预测？这些模型对于重要特征的判断是否一致？

**动机**：最近的深度学习漏洞检测工具取得了很高的性能，例如LineVul报告了91%的F1得分。我们想知道为什么这些工具能够表现出色，以及模型是否使用了漏洞的语义方面来进行决策。例如，为了检测缓冲区溢出，一种基于语义的程序分析工具会识别依赖语句并对字符串长度和缓冲区大小进行推理。我们还想调查不同的模型是否对重要特征达成一致意见。

**研究设置**：我们调查了一组最先进的深度学习解释工具，尤其是GNN和Transformer架构。我们使用了GNNExplainer [44] 来解释 Devign 和 ReGVD，以及 LIT [33]、[37]、[39] 来解释 LineVul、VulBERTaCNN、VulBERTa-MLP、CodeBert 和 PLBART。在我们的数据复现包中，我们记录了为什么其他模型无法与 GNNExplainer 和 LIT 一起工作，以及我们尝试过的其他解释工具。

为了解释这些模型，GNNExplainer 和 LIT 都提供了衡量代码特征重要性的分数。GNNExplainer 为图中的每条边给出一个分数，而 LIT 则为程序的每个符号给出一个分数。为了比较 GNNExplainer 和 LIT 的结果，我们对工具的输出进行了以下归一化处理。对于 GNNExplainer，我们通过取其相邻边的平均分数来计算每个节点的分数，就像[21]中所做的那样。每个节点中的符号都使用这个分数。对于 GNNExplainer 和 LIT，我们通过将同一行内所有符号的分数相加来计算每个源代码行的分数，遵循文献[15]的做法。对于测试数据集中的每个示例，我们选择了分数最高的前10行，就像[15]、[21]中所做的那样，形成了重要特征集合，记为 I。我们认为这10行是模型用来做出决策的最重要的代码特征。

为了衡量模型A和B报告的两个重要特征集合$I_A和I_B$的相似度，我们计算了交集$I_{AB} = I_A ∩ I_B$。我们还使用Jaccard指数[20]作为另一种度量标准，其定义如下：

![image-20240326111020654](https://s2.loli.net/2024/03/26/3e1ilbc5awQYrgo.png)

为了报告相似性，我们首先针对测试集中的每个程序计算$I_{AB}和J(I_A,I_B)$，然后分别取$I_{AB}和J(I_A,I_B)$的平均值。

我们从以下几组中抽取样本进行手动检查: 1) 示例存在漏洞，模型正确检测到（正确）; 2) 示例不存在漏洞，模型预测为存在漏洞（假阳性）; 3) 示例存在漏洞，模型预测为不存在漏洞（假阴性）。
研究结果: 在表VI中，我们报告了每对模型中重要特征集的相似性。我们的结果显示，Linevul和ReGVD在所有模型对中具有最大的重叠。在排名前10的重要特征中，这两个模型平均共享了6.88行。有趣的是，尽管模型在个别预测上可能存在很多分歧（见表IV），它们使用的代码信息是重叠的。所有模型对的重要特征中至少有3行是共同的。作为唯一基于属性图的GNN模型，Devign与其他模型的重叠较低，与PLBART的重叠最低，平均为3.38行。与其他Transformer模型相比，PLBART使用了不同的Transformer架构，并且与其他Transformer模型的重叠也较低。 

![image-20240326111424685](https://s2.loli.net/2024/03/26/7oJOPyHs9Zx2n3h.png)

###### 表 VI：用$I_{AB}（蓝色）和J(I_A,I_B)（黑色）$测量的每两个模型之间重要特征集的相似性。最大值和最小值用粗体表示。

我们还使用与表VI相同的方法分析了纠正后的预测示例。我们发现纠正后的示例中重要特征集的重叠更多，比如Linevul和ReGVD仍然具有最多的重叠，在重要特征集中共享了7.29行。

![image-20240326111504720](https://s2.loli.net/2024/03/26/dIA5DTBtXWZMl81.png)

###### 表七:经常突出显示的代码特性



![image-20240326111538978](https://s2.loli.net/2024/03/26/KYdBFuTGw8D3Oqj.png)

###### 清单 1：LineVul 成功检测到的内存泄漏。LIT 报告的前 10 行用黄色标出。

通过我们的手动检查，我们观察到模型通常将for、if、while等代码行以及函数签名作为重要特征。模型还经常将alloc、memset和memcpy等内存操作以及包含error或printf的错误消息所在行突出显示为重要特征。为了确认这一观察结果，我们使用这些关键词对代码进行了分析，并在表VII中报告了结果。以error为例，不失一般性地，前7行报告了每个模型在重要特征集中出现错误的概率（重要特征集中error的总数/重要特征集中行数的总数）。在行 Func 中，我们展示了函数中出现error的概率（error的总数/函数中行数的总数）。通过比较这两个值，我们发现重要特征集中出现error的概率平均是程序中出现error的概率的2.79倍，如行 I/F 所示。这意味着错误更倾向于被选入重要特征集。在所有特征中，error、print和alloc的排名最高。

我们的第二个观察结果是，Transformer模型有时会在没有看到根本原因的情况下进行预测。这是因为Transformer模型接受固定大小的输入，而有些代码，有时包括根本原因在内，会被截断。有趣的是，这些模型仍然能够以高的F1得分正确预测函数是否存在漏洞。

第三，我们检查了所有模型都错过的漏洞，并研究了用于检测这些漏洞的重要特征集。我们发现这些漏洞非常与应用程序相关。错过这些漏洞可能是因为此类漏洞缺乏足够的训练数据。

![image-20240326111840147](https://s2.loli.net/2024/03/26/WUAQ9nqC3EPcaxL.png)

###### 清单 2：由于虚假特征，非易受攻击代码被预测为易受攻击代码。

在列表1中，我们展示了一个例子，其中预测是正确的，但使用的特征并不是因果关系。该例子包含一个内存泄漏漏洞，而LineVul将该例子预测为存在漏洞。在第14行分配给name的内存永远不会被释放。第23行的补丁展示了修复方法。LIT报告的重要特征集（前10行）用黄色高亮显示。我们可以看到它包括我们讨论过的“模式”，包括第1行的函数签名，包含ERROR的行，例如第13行和第16行，以及第21行的if语句。我们还看到对于这个项目，变量name_len很重要，并且包含了多次。然而，这10行中没有涵盖到第14行的内存分配，而它对于理解此漏洞是重要的。

该示例表明，模型试图捕获漏洞的模式，而不是对值进行推理，并且在代码中捕获长距离的语义依赖非常困难。但我们在其他示例中也观察到有时将控制结构和内存语句（见表VII）突出显示为重要部分，可能是漏洞的相关语句的一部分，因此它们对于检查错误的根本原因是有用的。

列表2展示了一个非漏洞函数的示例，该行漏洞错误地预测为有漏洞。模型突出显示了函数签名（第2行），带有“ERROR”的行（第7和第10行），初始化例程（第5行），if语句（第6和第9行）以及字段赋值（第15-17行），并将该函数预测为有漏洞。这表明基于这些结构的模式做出决策可能会导致错误。

## 对有效性的威胁

我们的观察来自可用的模型和数据集，并不能概括深度学习漏洞检测的普遍情况。为了减轻这种风险，我们使用了一个平衡的数据集（Devign）和一个不平衡的数据集（MSR）。这两个数据集都包含了真实世界的漏洞。在评估中，大多数模型都使用了Devign，所以我们需要它来复现这些模型（见表一）。然而，我们的数据集可能仍然不能代表真实世界的漏洞分布。我们包括了我们能找到和复现的所有模型。

在RQ2中的分组存在偏见，因为不同的研究人员可能会以不同的方式划分漏洞类型。在这里，两位具有领域知识的作者分别检查了CWE列表，并进行了讨论和达成了一致的分组。为了减轻特定项目组成可能带来的偏见，RQ5采用了5倍交叉验证。对于RQ6，我们选择了SOTA模型解释工具；然而，这些技术可能无法完美地识别模型使用的重要特征。对于RQ2、RQ4和RQ5的实验需要模型与我们的自定义数据一起工作，而这些数据并没有随着模型一起提供。对于我们观察到的任何可疑数据，例如当一个模型报告全部为0或1时，我们尝试了不同的随机种子。当调整无法解决问题时，我们在结果中排除了这样的模型。

## 相关工作

有几项研究使用基于机器学习的漏洞检测模型进行了实证研究。Chakaborthy等人[7]研究了4个深度学习模型，并探讨了合成数据集、数据重复和数据不平衡等问题，并指出了虚假特征的使用，并利用这些问题改进了他们的模型设计。Tang等人[38]旨在确定哪种神经网络架构、向量表示方法和符号化方法最佳。他们调查了2个模型。Mazuera-Rozo等人[28]对二进制分类和错误类型（非二进制）分类进行了评估，使用了1个浅层模型和2个深层模型。在我们完成研究后，我们找到了两项相关的实证研究。Lin等人[26]评估了6个深度学习模型对9个软件项目的泛化能力。Ban等人[4]在跨项目设置中评估了6个机器学习模型（其中一个是神经网络），涉及3个软件项目，并研究了训练2种错误类型与训练单个错误类型的情况。

最近，出现了许多漏洞检测模型，包括多种架构，如MLP [9]、RNN [22][24]、[45]、CNN [34]、[42]、Transformer [2]、[11]、[12]、[14][16]、[32]、[41]和GNN [5]–[8]、[10]、[17]、[18]、[21]、[31]、[35]、[43]、[47]。例如，Devign使用基于属性图的门控图神经网络[1]。LineVul [15]使用了在大量不同开源项目上预训练的Transformer模型。ReVeal [7]应用了SMOTE来处理数据不平衡问题，并使用三元组损失函数来学习如何最大化分离易受攻击和非易受攻击的代码。

在这些论文中，大多数模型都是在内部数据上进行评估的，其中训练集可能包含与测试集重叠的项目和错误类型。Russell等人[34]、Li等人[24]和Xu等人[43]训练他们的模型来检测特定类型的漏洞，并发现某些漏洞比其他漏洞更难以检测。Hin等人[18]通过每次排除一个项目来评估他们的模型在跨项目设置中的性能，并发现性能稍有下降。大多数模型评估比较了不同的基准线，使用F1等指标，但没有量化预测一致性。据我们所知，我们的工作是首次尝试对模型无法良好预测的程序和代码特征进行描述的工作。

## 结论和今后的工作

为了理解深度学习漏洞检测模型，我们进行了一个实证研究，包括6个研究问题。我们实验证明，平均而言，34.9%的测试数据在多次运行中预测结果不同，只有7%的预测结果在9个模型间达成一致。基于特定类型的漏洞检测通常表现优于针对所有漏洞构建的模型。模型性能并未显著提高随着数据集的增加，对于均衡和不均衡的数据集来说，模型在使用约1k个易受攻击的示例后开始表现良好。我们开发了一个逻辑回归模型，可以找到模型难以正确预测的程序。解释工具显示，模型使用常见特征进行预测，每个重要特征前10行共有3.38-6.88行。我们报告了模型经常强调的代码模式作为重要特征。在未来的工作中，我们计划进一步研究这些模式。