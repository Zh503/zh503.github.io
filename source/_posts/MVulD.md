---
title: MVulD
date: 2024-05-28 15:28:44
tags:
  - 有代码
categories:
  - 学习笔记
  - 论文译文
---

## Function-level Vulnerability Detection Through Fusing Multi-Modal Knowledge

### 摘要

软件漏洞会影响软件系统的正常运行。最近，有很多基于深度学习的方法被提出，这些方法在函数级别检测漏洞时，使用了一种或几种不同的表示方式（如文本表示、图表示），并取得了不错的效果。然而，现有的一些研究并没有完全利用这些多样的表示方式，特别是图像表示方式利用不足，而那些使用图像表示函数的漏洞检测方法也没有充分利用图像中的图结构信息。
在本文中，我们提出了MVulD，这是一种基于多模态的函数级漏洞检测方法。它利用函数的多种表示方式（包括文本表示、图表示和图像表示）来检测漏洞。具体来说，MVulD使用预训练模型（UniXcoder）来学习文本代码的语义信息，使用图神经网络提取图表示，并采用计算机视觉技术获取图像表示，同时保留函数的图结构信息。我们对25,816个函数进行了大规模实验。实验结果表明，MVulD在F1-分数、准确率、精度和PR-AUC方面分别提高了30.8%-81.3%、12.8%-27.4%、48.8%-115%和22.9%-141%，超越了四个最先进的基线方法。

索引术语：漏洞检测、计算机视觉、深度学习、多模态代码表示

### 引言

软件漏洞让软件系统变得不可靠，针对漏洞检测已经提出了很多方法。这些方法可以分为三类：基于程序分析、基于机器学习和基于深度学习的方法。每种方法在漏洞检测上都有其优势。例如，基于程序分析的方法 [1], [2] 专注于发现特定类型的漏洞，基于机器学习的方法 [3]–[5] 通过人工设计的指标学习漏洞特征，而基于深度学习的方法 [6]–[9] 则构建深度学习模型，自动学习指标和检测模型。其中，基于深度学习的方法在函数级别的漏洞检测中表现更佳 [10], [11]。

对于一个函数，它通常有多种表示形式：源代码 Token、抽象语法树（AST）、控制流图（CFG）、控制依赖图和数据依赖图。这些不同的表示形式已经部分应用于漏洞检测。例如，一些研究仅采用单一表示形式（如仅使用源代码 [7], [12]、仅使用抽象语法树 [13] 或使用不同的图表示 [6], [9], [14]–[16]）。甚至有些研究 [17], [18] 仅应用计算机视觉技术进行软件漏洞检测，且在漏洞检测（VD）上取得了良好效果。同时，一些研究 [9], [15] 尝试融合函数的多种表示形式以提高漏洞检测效果。例如，同时使用多种代码表示（如 AST、CFG、PDF 和代码序列 [16]），并将它们嵌入到深度学习模型中。

尽管已有方法通过利用不同的函数表示在函数级别的漏洞检测上取得了不错的效果，但仍存在一些局限性：根据先前研究 [19]，不同模态的函数表示能力不同。然而，现有研究未充分利用这些模态，尤其是被忽视的图像模态也被证明对漏洞检测有用，但它尚未与其他表示融合。计算机视觉技术可以帮助检测以图像表示的函数中的漏洞。然而，现有研究生成的图像 [17], [18] 仅考虑节点的重要性，而忽略节点的相对位置关系。这样会破坏函数的整体结构，而这是非常重要的。

为了充分利用多种代码表示的语义信息，本文提出了一种新颖的基于多模态的函数级漏洞检测方法，称为 MVulD。该方法利用了源代码的文本信息、图像信息和图形信息，以及代码结构和图像内位置之间的映射信息。具体来说，我们采用预训练模型（即 UniXcoder [20]）来提取文本表示的语义信息。对于基于图的表示，我们提取函数的代码属性图（CPG），并采用基于图的模型作为编码器进行推理。至于图像表示，CPG 被转换为图像，并使用基于 Transformer 的计算机视觉模型（即 SwinV2 [21]）作为图像编码器，以获取全局信息。最终，这三维不同的代码表示被融合以生成函数的多模态特征，用于构建最终的分类模型。

我们通过对 25,816 个函数进行大规模研究（参见 V-A 节）来评估 MVulD 的有效性，并与四个最先进的基线方法在四个性能指标上进行比较。实验结果表明，我们提出的方法具有优越性。更具体地说，MVulD 获得了 0.272 的 F1 分数、0.880 的准确率、0.183 的精度和 0.231 的 PR-AUC，分别比基线方法提高了 30.8%-81.3%、12.8%-27.4%、48.8%-115% 和 22.9%-141%。我们还研究了 MVulD 在最危险的 Top-25 CWEs（参见 V-B 节）上的实际有效性，结果也显示其具有较高的准确性。最终，本文的主要贡献如下：

- 我们提出了一种有效的基于多模态的函数级漏洞检测方法 MVulD，充分融合了三种重要模态（即文本语义、图形结构和图像信息）进行漏洞检测。
- 我们在 25,816 个函数上进行了大规模实验，实验结果表明，MVulD 显著优于最先进的基线方法。

### 相关工作

漏洞检测（VD）是安全领域中非常关键但具有挑战性的任务，已经提出了多种方法来检测漏洞，可以广泛划分为三类：基于程序分析（PA）的方法、基于机器学习（ML）的方法和基于深度学习（DL）的方法。

基于PA的方法根据人工专家手动生成的预定义漏洞模式来检测漏洞。由于专家无法生成所有不同漏洞的模式，基于PA的漏洞检测器（例如RATS [22]、Checkmarx [1]和FlawFinder [2]）只能检测有限类型的漏洞。

基于ML的方法通过对特定特征训练机器学习模型来检测漏洞。这些方法实际上是半自动的，因为它们需要人工制定的度量标准作为特征来描述漏洞，这需要大量时间来收集。

基于DL的方法可以从源代码中自动学习特征进行漏洞检测，可以根据其代码表示技术进一步分为三种类型。 （1）基于标记的方法。这些方法将源代码视为文本，并利用自然语言处理技术来检测漏洞。 （2）基于树的方法。与将源代码视为自然语言句子不同，基于树的方法利用程序中包含的结构信息。 （3）基于图的方法。为了获得源代码的更全面表示，一些方法提取不同类型的图表示（即控制流图（CFG）、控制依赖图（CDG）和数据依赖图（DDG））并利用图神经网络（GNN）进行漏洞检测。

同时，一些研究采用计算机视觉技术创造性地表示函数或源代码文件。然而，这些作品生成的图像破坏了研究函数的图结构，这对理解语义至关重要。

除了利用一个函数的表示，一些作品转而使用多种表示（例如AST、CFG、DFG、DDG和代码序列）进行漏洞检测任务。然而据我们所知，尚无人尝试将源代码的图像特征与其他模态（即文本或图）的特征融合以检测漏洞。因此，我们希望探讨这种图像特征、文本特征和图特征结合的潜力。

### 方法

我们提出了一种多模态方法MVulD（如图1所示），它包含四个主要阶段： 1）图提取旨在获取函数的结构表示， 2）图像生成有助于将结构图转换为图形表示， 3）多模态特征融合建立各种模态之间的关系，以获得丰富的代码表示， 4）分类将用于检测函数是否具有漏洞。MVulD的详细内容将在后续子节中介绍。

#### A. 图提取

在我们的研究中，我们提取了函数的代码属性图(CPG) [15]，这是一种结合了抽象语法树(AST)、控制流图(CFG)和数据流图(PDG)特性的联合数据结构。每种图表示都为源代码提供了独特的视角，强调程序的不同方面。特别是，AST忠实地编码了语句如何嵌套以生成程序，CFG提供控制流信息，而PDG提供数据流信息。遵循先前的工作[18, 19]，我们使用Joern程序[15]提取这三种类型的图。特别地，在将函数的源代码解析为Joern时，我们可以得到CPG，一个节点表示语句集合、边表示语句间流程信息的多图。

![image-20240528194849918](https://s2.loli.net/2024/05/28/zFawmBDc5ThXb73.png)

#### B. 图像生成

随着深度学习技术的快速发展，计算机视觉（CV）在许多应用中取得了巨大成功，例如物体检测[28]–[31]和图像识别[31]–[35]。最近，一些研究者[17], [18]采用CV中的新颖技术来解决软件工程中的漏洞检测任务，并确实取得了令人鼓舞的成果。因此，我们希望将代码转换为图像，并充分利用CV中的新技术来更好地嵌入一个函数。以往的工作以不同方式将函数转换为图像。例如，Wu等人[18]使用语句的嵌入向量作为图像中的值，而Chen等人[17]使用代码字符的ASCII值作为图像中的值。在某种程度上，这两种图像生成方式都会损害函数的信息。此外，当可视化此图像时，开发者不易识别生成的图像与分析的函数之间的相关性。与以往工作不同，我们直接根据CPG的信息绘制研究函数的图像。因此，在可视化此图像时，开发者可以轻松看到其结构（AST、CFG和PDG）以及内部的语句节点。

在图像生成阶段，我们采用名为Graphviz[37]的工具将Joern生成的CPG转换为图像。为了表示函数中的每个语句节点，我们使用带有不同颜色的编号圆形节点，每个节点内的数字对应于每个语句的行号。同时，为了更好地区分图像中三种结构信息之间的差异，我们采用不同的颜色和不同的线型来绘制两个语句节点之间的连接线。

#### C. 多模态特征融合

每种模态在表示源代码的能力上各有不同，融合多种模态可以促进对源代码的理解[19]。在我们的研究中，我们设计了四种编码器：全局图像编码器、代码编码器、位置编码器和多模态图编码器，以获取三种类型的代码特征（即全局图像特征、函数级别的文本特征和图特征），并将它们结合起来，得到最终的丰富多模态代码表示。以下是每个编码器的详细介绍。

全局图像编码器。为了获取全局图像特征，MVulD采用了一个名为SwinV2[21]的大规模视觉模型作为全局图像编码器的主要部分，该模型在ImageNet[38]上进行了预训练，并在各种任务（如图像分类[39][41]、目标检测[28]–[31]和语义分割[33]，[42]–[44]）中表现出色。更准确地说，对于给定的图像I，SwinV2将其作为输入并输出矢量化的特征表示。输出特征向量的维度为1,024，然后通过一个全连接层投影到512，以获得最终的全局图像特征，可以表示为If ∈ R1×D，其中D等于512。

代码编码器。除了函数的结构信息外，源代码的语义信息也非常重要。与编程语言相关的预训练模型[20]，[45]–[47]在软件工程中被广泛使用，并且确实取得了很大成功，因为它们对编程语言领域的令牌有很好的理解。Guo等人[20]提出的UniXcoder是一个统一的预训练模型，它结合了代码注释和AST中的语义和语法信息，我们将其作为MVulD中的代码提取器，以嵌入函数级别和语句级别的代码特征。更准确地说，给定一个函数的源代码，MVulD首先将函数分解为单独的语句。然后，整个函数和单独的语句（代码行）通过UniXcoder[20]的预训练BPE（字节对编码）标记器进行标记化。随后，UniXcoder将输入函数转换为函数级别和语句级别的768维向量。也就是说，MVulD的代码编码器总共生成n+1个代码表示，即一个整体函数的嵌入和所有代码行的n个嵌入。

类似于获取函数最终图像表示的过程，MVulD进一步通过一个全连接层将获取的函数级代码特征进行投影，以得到最终编码的文本特征。最终的函数级文本特征可以表示为Tf ∈ R1×D，而语句级文本特征Tnode = {t1, t2, ..., tn}将作为图（即CPG）的初始节点嵌入。

位置编码器。第二阶段生成的图的图像展示了结构信息，但忽略了图像中节点（即代码中的语句）之间的关系，这些关系可以提供重要的关联信息和空间信息，从而有助于更好地理解函数的语义。因此，应该获取生成代码图像中每个节点的位置信息。我们采用广泛使用的开源字符识别（OCR）技术来提取节点的边界框，并设计了一个位置编码器来获取位置特征嵌入。具体来说，MVulD使用了一个名为East [29]的精确场景文本检测器来获取每个文本实例（即每个节点内的行号）的相应边界框。在获取边界框时，MVulD应用Python-tesseract2进一步提取图像中每个节点（即语句编号）的行号，这可以用来对齐位置特征嵌入与其相应的文本语句的语义特征嵌入。在节点没有边界框的情况下（例如，文本无法被OCR识别），应用零填充策略。之后，每个节点的检测边界框可以用图像大小归一化的左下角（x1, y1）和右上角（x2, y2）坐标来描述。

因此，整个图像的输入可以表示为：bboxesinput = {bbox1, bbox2, ..., bboxn}，其中bboxi = {x1, y1, x2, y2}，n是图像中节点的数量。同时，MVulD的位置编码器将输入表示转换为最终编码的位置特征嵌入：bboxesf（bboxesoutput）= {bbox′ 1, bbox′ 2, ..., bbox′ n}。

多模态图编码器。图神经网络（GNNs）[6]、[9]、[16]、[19]已证明能够对给定图中节点间的关系进行建模，以学习结构信息和语义信息。图注意力网络（GAT）[48]和图卷积网络（GCN）[49]是两种主流的GNN。为了获取丰富的图特征，MVulD主要通过结合GAT和GCN构建多模态图编码器。我们首先将GAT应用于CPG。由于我们的CPG是有向图，GAT能够通过注意力机制灵活处理节点间的非对称关系和方向性。在GAT之后，我们将丰富的声明特征嵌入与从图像中提取的位置嵌入一起输入到GCN中。GCN在需要推理的图像相关任务中已成功应用，如图像字幕生成[50]、[51]和图像-句子检索[52]、[53]，这可以通过在图像的局部邻域执行卷积操作来进一步增强节点表示。

在第一步中，我们以n个声明嵌入（即Tnode）作为输入，采用GAT模型在基础CPG上对其进行优化。具体来说，GAT利用注意力机制聚合每个节点的邻域信息，并以增量方式嵌入相邻声明之间的边信息以传播信息。GAT中的聚合策略可以描述如下。

![image-20240528195348644](https://s2.loli.net/2024/05/28/8j1XESJMIObdrtg.png)

其中，l 表示当前状态，h(l) 是当前层的节点嵌入向量，W(l) 是可学习的权重矩阵，a 是另一个可学习的权重向量，而 σ 定义了激活函数。经过 GAT 过程后，会利用全连接层获取输出节点表示：Tgat = {t'1, t'2, ..., t'n}。

在第二步中，我们根据图像构建一个新的图 G=(V, R)，其中 V 是图像中检测到的节点集合，R 是通过计算每对节点的亲和力边得到的。我们将 V 初始化为 Tgat 和对应的边界框嵌入 bboxesf，可以这样表示：V = {(t'1, bbox'1), (t'2, bbox'2), ..., (t'n, bbox'n)}，V ∈ R^n×D。R 可以使用以下公式构建：

![image-20240528195505860](https://s2.loli.net/2024/05/28/NPcOjAGnl4L9Sop.png)

其中V是节点嵌入，R是相似度矩阵，Wg是GCN的可学习权重矩阵，Wr是残差权重矩阵，l是GCN层的数量。经过GCN处理后，我们可以得到增强后的节点嵌入：VG = {vg1,vg2, ..., vgn}，VG ∈ Rn×D。

经过这两步后，全局结构信息被附加到了每行代码（即每个节点）上。最终的图特征表示VGf是通过所有节点信息的平均来获取的，可以表示为：

![image-20240528195538412](https://s2.loli.net/2024/05/28/OWAF17HN9CVe3kt.png)

在进行分类之前，MVulD简单地将来自各自编码器的三个获得特征If、VGf和Tf串联在一起，以获取多模态代码特征F=[If，VGf，Tf]。

D. 分类MVulD的目标是检测函数是否易受攻击，这是一个典型的二元分类任务。通过将最终表示F通过一个全连接层（即最终分类层）和softmax层，可以得到给定输入函数的类别标签的概率分布。在训练阶段，我们使用交叉熵损失来指导MVulD的优化过程，通过比较模型预测概率与真实标签之间的差异。目标是使交叉熵尽可能小，从而使预测结果更接近真实情况。

### 第四部分：实验设置

#### A. 研究问题

我们关注以下两个研究问题：

• RQ-1：MVulD 在函数级别的漏洞检测中与基线方法相比表现如何？

• RQ-2：MVulD 在检测前25个最危险的CWE（常见漏洞枚举）方面表现如何？

#### B. 数据集

我们选择了Big-Vul数据集[54]，因为它是从348个开源GitHub项目中收集的最大的漏洞数据集之一，涵盖了91种不同的漏洞类型。我们还对原始数据集进行了三个过滤步骤（即：(1) 移除不正确截断的函数；(2) 移除未能被Joern[15]解析的函数；(3) 过滤掉LOCs<=100（即占据95%）的函数以避免噪声），以获得有效的函数，详细信息显示在表I中。最后，我们将最终数据集（LOCs<=100）随机分为训练集（80%）、验证集（10%）和测试集（10%）。

![image-20240528195820527](https://s2.loli.net/2024/05/28/3J4GRcY9qUjQgrw.png)

#### C. 基准模型

为了更清晰地展示当前最先进方法（SOTA）与MVulD之间的性能差异，我们考虑了四种顶尖方法。具体而言，我们选取了三种基于图的方法（即IVDetect、Devign和Reveal）以及一种预训练方法（即UniXcoder[20]，它同时考虑了抽象语法树（AST）和代码注释）。IVDetect[6]考虑了五种特征表示（即子令牌序列、AST、变量名和类型、数据依赖上下文以及控制依赖上下文），Devign[16]则关注四种代码语义表示（即AST、控制流图（CFG）、程序依赖图（PDG）和代码序列），而Reveal[9]则侧重于函数的代码属性图（CPG）。

### 实验结果

![image-20240528200023756](https://s2.loli.net/2024/05/28/rDk4qICa318p9jo.png)

针对函数级别的漏洞检测，已提出多种基于深度学习的方法，这些方法采用不同的代码表示技术。Siow等人[19]证实了不同的代码表示蕴含着不同的程序语义。同时，一些研究[17]、[18]尝试将源代码可视化为图像，并将其输入计算机视觉模型以进行漏洞检测。然而，这些方法在充分利用各种不同模态进行漏洞检测方面存在局限。因此，MVulD整合了基于令牌的特征、基于图的特征以及图像特征，以提升其在漏洞检测中的有效性。我们希望探究MVulD在利用多模态特征时能达到何种程度的检测性能。

为了全面比较四个基线模型与MVulD之间的性能差异，我们在训练集上训练所有模型，并使用验证集按轮次监控训练过程，基于最佳F1分数选择最优模型，而测试集则用于测试。我们还考虑了五种常用的性能指标：准确率、精确率、召回率、F1分数和PR-AUC。此外，为了消除随机性的潜在偏差，我们在基线模型和我们的MVulD中均设置了相同的种子，并统一了用于图提取阶段的Joern[15]版本。

![image-20240528200137986](https://s2.loli.net/2024/05/28/mcCZ9IXKETSln4k.png)

评估结果在表II中给出，最佳性能以粗体显示。根据结果，我们发现我们的MVulD在几乎所有性能指标上都明显优于所有基线方法。具体来说，MVulD获得了0.272的F1分数、0.880的精度、0.183的精确度和0.231的PR-AUC，分别比基线提高了30.8%-81.3%、12.8%-27.4%、48.8%-115%和22.9%-141%。然而，MVulD在召回率方面平均下降了16.1%。由于UniXcoder在召回率上表现最好，我们通过比较UniXcoder和MVulD在不同类型的漏洞上的表现进行了深入分析。在实验中，我们删除了只有单个漏洞实例的六个CWE，因为它们可能无法充分反映模型的真实检测性能。然后，我们使用真正例率（TPR）作为评估指标，它衡量方法准确检测到的漏洞函数数量与实际漏洞函数的比例。在表III中，我们按照漏洞数量对调查的漏洞类型进行了排序，并只展示了 UniXcoder和MVulD性能不同的类型。结果显示，对于CWE-415和CWE-189，我们的MVulD（5/7和12/16）能找到更多漏洞实例，而UniXcoder为（3/7和11/16）。然而，对于剩余的CWE类型，UniXcoder的表现优于MVulD。例如，UniXcoder能正确检测CWE-772和CWE-310，而MVulD不能。

**针对RQ-1的回答**：MVulD在函数级别的漏洞检测上能够实现超越当前最先进基准的优异性能，尤其是在F1分数、准确率、精确度和PR-AUC方面取得了压倒性的成果。这还表明，多模态特征能为MVulD的检测性能带来显著提升。

**B. [RQ-2]:针对前25个最危险CWE的有效性**

2022年常见弱点枚举（CWE）前25个最危险的软件弱点列表（CWE Top 25）展示了当前最常见且影响深远的软件弱点。这些未解决的弱点与软件系统相关，可能导致隐私风险和可利用的漏洞，使攻击者能够完全控制系统、窃取数据或阻止应用程序运行。为了探究MVulD在实际漏洞检测场景中的有效性，我们进一步研究了MVulD对前25个最危险CWE的检测准确性。

在第四节B部分提到的测试集中，我们仅选择属于前25个最危险CWE的函数作为研究数据集，并按其CWE类型进行分组。由于并非所有前25个最危险CWE都被包含在内，我们最终在表IV中收集了13种CWE类型。之后，我们选择在验证集上具有最高F1分数的MVulD来评估我们方法对这些获取的CWE的准确性。准确性衡量了我们的方法能够正确检测到的脆弱函数，这可以通过TPR（真阳性率）来计算。

![image-20240528200410070](https://s2.loli.net/2024/05/28/j1LG2NfcDKPsF7x.png)

表IV从查全率(TPR)的角度展示了我们的MVulD在各类CWE中的性能。根据这些结果，我们可以得出以下结论：1）MVulD准确地检测出223个受Top-25最危险CWE影响的漏洞中的118个，占比为52.9%。2）对于Top-1 CWE，MVulD的查全率高达83.3%，而针对Top5 CWE的准确性为53.8%。3）在CWE-787（越界写入）、CWE-125（越界读取）和CWE-119（内存缓冲区边界内操作限制不当）方面，MVulD分别达到了83.3%、51.9%和61.4%的准确性，显示出它在检测内存相关漏洞方面的优势。

然而，MVulD未能识别某些类型的漏洞，如CWE-89、CWE-862、CWE-400和CWE-611。这类CWE缺乏易受影响的实例可能是MVulD准确性较低的原因。

回答RQ-2：总体来说，MVulD能够正确检测出Top-25最危险CWE影响下的52.9%的漏洞函数。这表明MVulD有能力在实际应用中发现漏洞。

### 六、结论

本文中，我们提出了MVulD，这是一种基于深度学习的新颖方法，能够从不同的知识资源中学习多模态代码特征，以检测函数级别的漏洞。通过利用UniXcoder编码文本特征，GNN模型编码图形特征，以及SwinV2编码图像特征，MVulD在与真实世界数据集（即Big-Vul）上的其他基线方法相比，达到了新的最先进水平。此外，还进行了详尽的实验，进一步研究了不同模态的功能有效性，结果表明，多样化的代码表示都是不可或缺的，并且可以被MVulD有效利用，以捕捉丰富的程序语义并进行漏洞检测。