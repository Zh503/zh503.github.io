---
title: CSGVD
date: 2024-04-22 09:53:28
permalink: /pages/b591ca/
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---
# CSGVD: A deep learning approach combining sequence and graph embedding for source code vulnerability detection✩



| Model          | URL                                                          |
| -------------- | ------------------------------------------------------------ |
| CodeBERT       | https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Defect-detection |
| GraphCodeBERT  | https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Defect-detection |
| CoTexT         | https://github.com/salesforce/CodeT5  /https://github.com/justinphan3110/CoTexT |
| CodeT5         | https://github.com/salesforce/CodeT5                         |
| PLBART         | https://github.com/wasiahmad/PLBART                          |
| Russell et al. | https://github.com/VulDetProject/ReVeal                      |
| ReGVD          | https://github.com/daiquocnguyen/GNN-ReGVD                   |
| Devign         | https://github.com/saikat107/Devign                          |
| 数据集链接     | Dataset link: https://github.com/microsoft/ CodeXGLUE        |

为了保证软件的安全性，检测潜在漏洞至关重要。传统的静态漏洞检测方法的性能受到预定义规则的限制，过度依赖开发者的专业知识。现有的基于深度学习的漏洞检测模型通常只使用单一的序列或图嵌入方法来提取漏洞特征。基于序列嵌入的模型忽略了代码中固有的结构化信息，而基于图嵌入的模型缺乏有效的节点和图嵌入方法。因此，我们提出了一种新颖的基于深度学习的方法，名为CSGVD（Combining Sequence and Graph embedding for Vulnerability Detection），将函数级漏洞检测视为图二分类任务。首先，我们提出了一个PE-BL模块，该模块继承并增强了预训练语言模型的知识。通过使用序列嵌入，它将代码的局部语义特征提取为控制流图中的节点嵌入。其次，CSGVD使用图神经网络提取图的结构化信息。最后，我们提出了一种平均双仿射注意力池化（M-BFA）方法，更好地将节点信息聚合为图的特征表示。实验结果表明，CSGVD优于现有的最先进模型，在CodeXGLUE的真实世界基准数据集上，漏洞检测准确率达到了64.46%。

## 引言

现代软件系统常常受到各种各样的软件漏洞的困扰。根据最近几年Common Vulnerabilities and Exposures（CVEs）的漏洞报告（Anon, 2022a），软件漏洞的数量一直在迅速增加。随着漏洞的增加，网络安全攻击将会有更多可能性，造成严重的经济和社会损害。因此，漏洞检测对于确保软件系统的安全和保护社会经济稳定至关重要。
传统的静态检测方法（Anon, 2022c,b,d,f,i）是基于静态分析理论和预定义的匹配规则，过于依赖开发人员的专业知识，很难检测未知的漏洞。因此，在实际应用环境中它们通常表现不佳。
随着深度学习技术的进步，研究人员越来越多地专注于使用深度学习技术来检测漏洞。Russell等人（2018）将源代码视为自然语言序列，然后使用CNN（卷积神经网络）来提取代码语义特征以进行漏洞检测。Li等人（2018）使用代码小工具作为输入，训练一个BiLSTM（Hochreiter和Schmidhuber，1997）网络来进行漏洞检测。Cheng等人（2021）首先通过考虑控制和数据依赖关系生成PDG。然后，从感兴趣的程序点（系统API调用或算术运算符）开始进行前向和后向切片，产生相应的XFG，即PDG的子图（程序依赖图）。最后，他们将XFG作为输入来训练切片级漏洞模型。Nguyen等人（2022）利用滑动窗口生成基于标记之间的关系图，使用残差图神经网络进行漏洞检测任务。Zhou等人（2019）利用代码属性图和门控图神经网络（Li等人，2016）

在本文中，我们提出了一个简单而有效的神经网络模型，名为CSGVD，用于进行漏洞检测任务。CSGVD将源代码的漏洞检测形式化为函数级别的二元图分类任务，接受源代码的控制流图作为输入。此外，我们提出了一种新颖且高效的节点嵌入和图嵌入方法。大量实验证明，CSGVD在CodeXGLUE（Lu等人，2021）的基准缺陷检测数据集上显著优于现有的最先进模型。

总之，本文的贡献如下：
- 我们提出了一个简单而有效的带有残差连接的图神经网络模型CSGVD。大量实验表明，CSGVD在CodeXGLUE的基准缺陷检测数据集上明显胜过现有的最先进模型。
- 我们提出了用于节点嵌入的PE-BL模块，代替Word2Vec和Doc2Vec，利用预训练语言模型的词嵌入层权重来初始化CSGVD的嵌入层，并使用BiLSTM来聚合节点内的局部语义信息。
- 我们提出了均值双仿射注意力池化（M-BFA）用于图嵌入，灵感来自双仿射注意力机制（Yu et al., 2020a）。结果显示它能够提升模型的性能。



## CSGVD 框架

在这个部分中，首先，我们总结了问题定义。然后，我们详细介绍了CSGVD的总体框架。最后，我们展示了我们如何整合预训练语言模型并开发了图构建方法。

### 2.1. 问题定义

我们将源代码漏洞检测形式化为函数级别的二元图分类任务，即确定原始源代码中给定函数是否存在漏洞。我们定义数据样本为{(ci, yi) | ci ∈ C, yi ∈ Y}N i=1，其中C是原始源代码的集合，Y = {0, 1} 表示标签集，1 表示存在漏洞，0表示不存在，N是实例数。我们将漏洞检测视为图分类问题，并利用原始源代码的控制流图(Control Flow Graph, CFG)。因此，我们为每个源代码ci构建图cfgi(V, X, A) ∈ G，其中V表示图中的一组n个节点；X ∈ Rn×d 是节点特征矩阵，其中每个节点vi ∈ V 用一个d维向量xi ∈ Rd 表示；A ∈ {0, 1}n×n 是邻接矩阵。当Ai,j等于1时，表示节点i和节点j之间存在边，否则为0。我们的目标是学习一个映射函数f : G → Y 来确定给定源代码是否存在漏洞。映射函数f可以通过最小化损失函数并对模型参数θ进行正则化来学习：
$$
\mathrm{Min}\sum{\mathcal{L}(f(cfg_{i}(\nu,X,A),y_{i}\mid}\;c_{i})+\lambda||\theta||_{2}^{2}
$$
其中，L(·) 是交叉熵损失函数，λ 是一个可调节的权重。
![image-20240422100941387](https://s2.loli.net/2024/04/22/bMRG3HLkQdpD7Yi.png)

### 2.2. 方法概述

 在本节中，我们提出了一种名为CSGVD的结合序列和图嵌入神经网络模型，用于识别函数级代码是否存在漏洞。在CSGVD中，一个基本的见解是，识别语句之间的控制依赖关系足以作为函数级漏洞检测任务的上下文信息。此外，我们使用序列嵌入方法提取代码的局部语义特征，作为图的节点嵌入表示。同时，我们构建了一个基于图神经网络的架构，更好地利用语句内部和语句之间的结构关系，如图1所示。
整体结构主要分为两部分，左边是特征提取，右边是神经网络模型。神经网络架构如图2所示。在接下来的章节中，我们将详细描述神经网络的各个层。

#### 2.2.1. 特征提取 

要训练神经模型，我们需要将原始的函数级源代码转换成神经网络模型可接受的数据格式。在我们的工作中，我们使用 Joern1 (Anon, 2022g) 来解析源代码并提取我们需要的控制流图。由于 Joern 提取的图太大了，我们通过行来合并提取的节点。通过压缩图形，并将原始的控制流图转换为语句级的控制流图，压缩后的图中的节点数量将少于或等于代码行数，这将大大减少计算时间和资源。

例一：当使用 Joern 来解析一个示例 ci 的语句，比如 for (expression_1; expression_2; expression_3)（1），Joern 会将这个语句拆分为三个不同的节点（如表1所示）。这可能会导致与示例 ci 相对应的控制流图 cfgi 变得非常庞大。为了减小 cfgi 的大小，我们将合并这些位于原始代码文件同一行的节点作为一个新节点 vnew。同时，我们将使用原始语句对应的行作为节点 vnew 的内容。此外，vnew 还将继承所有的边关系。



#### BiLSTM

双向长短期记忆网络（Bidirectional Long Short-Term Memory，BiLSTM）是一种用于序列建模的循环神经网络（RNN）变体。它结合了长短期记忆网络（LSTM）的能力来捕获序列中长期依赖关系的优点，以及双向性的特点，能够同时考虑序列中每个时间步的过去和未来信息。

BiLSTM由两个独立的LSTM网络组成，一个按时间顺序处理输入序列，另一个按相反的顺序处理输入序列。这两个网络的输出在每个时间步都被连接起来，以提供对当前时间步的双向上下文信息。这样，BiLSTM可以利用当前时刻之前和之后的所有信息来预测当前时刻的输出。

BiLSTM的主要优点包括：

1. **捕获长期依赖关系：** 由于LSTM单元的设计，BiLSTM可以有效地捕获序列中的长期依赖关系，即使序列很长，也能够保持梯度的稳定性，避免梯度消失或爆炸的问题。
2. **双向信息：** BiLSTM能够同时考虑当前时刻之前和之后的信息，因此可以更好地理解输入序列的整体语境，提供更丰富的上下文信息。
3. **适用于多种任务：** BiLSTM可用于各种序列建模任务，包括文本分类、命名实体识别、序列标注、机器翻译等。
4. **灵活性：** BiLSTM可以很容易地与其他神经网络结构组合使用，如卷积神经网络（CNN）或注意力机制，以进一步提升性能。

总的来说，BiLSTM在处理序列数据时表现出色，特别是在需要考虑序列上下文信息的任务中，它已成为许多自然语言处理和时间序列分析任务的标准模型之一。

![image-20240422105526958](https://s2.loli.net/2024/04/22/VaIhbLZ6yPRmckX.png)

#### 2.2.2. 节点嵌入 

对于后续任务来说，生成给定源代码的信息丰富、全面的代码表示是非常重要的。如图2所示，我们提出了一个PE-BL模块，由嵌入层和BiLSTM层组成。具体来说，我们并没有采用传统的嵌入层，而是引入了一个预训练的编程语言模型 CodeBERT（Feng等人，2020）来初始化嵌入层。我们使用它训练过的词嵌入权重初始化自己的嵌入层权重。此外，由CodeBERT使用的字节对编码（BPE）（Sennrich等人，2016）标记器也可以缓解OOV问题。



我们以源代码的单个函数作为原始输入。我们将函数拆分为一组语句S = {s1, s2, s3, . . . , sn} 和语句级CFG，其中si对应CFG的节点vi。每个语句首先通过CodeBERT的预训练BPE标记器进行标记化：
$$
tokensi = BPE − Tokenizer(si)。
$$
然后，CSGVD使用一个嵌入层，该层利用CodeBERT的词嵌入层权重来初始化自身权重，以获得每个标记的向量表示$e_{i j}\ \in\ E_{i}\,=\,\{e_{i1},\,e_{i2},\,e_{i3},\,\cdot\,\cdot\,,\,e_{i n}\}$：
$$
Ei = Embedding(tokensi)。
$$
最后，使用一个双向LSTM来融合代码的本地语义信息，得到语句si对应节点vi的向量表示xi：
$$
\overrightarrow{h}_{i},\overleftarrow{h_{i}}\,=\,B i L S T M(E_{i})
$$

$$
x_i=Sum(\overrightarrow{h}_{i},\overleftarrow{h_{i}})
$$

其中$\overrightarrow{h}_{i},\overleftarrow{h_{i}}$是BiLSTM 的最终输出

#### 2.2.3. 剩余图神经网络 

在我们的研究中，我们关注控制依赖信息，为此构建了一个具有剩余连接性的图神经网络模型。与顺序神经网络不同，图神经网络（GNNs）利用信息扩散机制来学习图结构数据，根据图的连接性更新节点状态。如图2所示，图卷积网络用于从图中学习控制流信息。GCN层首先将来自BiLSTM的n个输出语句嵌入以及每个节点之间的边输入。源代码的图结构信息，包括节点和边的信息，被提取并输入到GCN中。特别地，我们在图中的每个节点上添加了自环链接。CSGVD将通过节点状态和相邻节点之间的控制流关系递增地传播信息。该模型结构由两个具有剩余连接性的图卷积网络组成。总体而言，剩余GCN通过在公式（6）中不同的GCN层之间使用跳跃连接来定义，其中l表示当前层，$H^{(l)} = {h^{(l)}_1 , h^{(l)}_2 , h^{(l)}_3 , . , h^{(l)}_n } $是第l个层的隐藏状态矩阵，A是邻接矩阵。
$$
H^{(l+1)} = GCN (H^{(l)}, A) + H^{(l)}\\
Specially, in CSGVD,\\
H^{(0)} = X\\
H^{(1)} = GCN(H^{(0)}, A) \\
\text {where in}\quad X = {x_1, x_2, x_3, . . . , x_n}\quad  \text{is  the node embedding matrix}.   
$$

![image-20240422110131759](C:\Users\hao\AppData\Roaming\Typora\typora-user-images\image-20240422110131759.png)

#### 2.2.4. 图嵌入

使用具有残差连接的多层GNN进行图嵌入，我们在聚合相邻节点的节点信息的同时，获取控制流图中每个节点的隐藏表示。在执行图分类任务之前，我们还需要聚合节点的信息，以获得图的向量表示。因此，如图3所示，受双仿射注意机制的启发，我们提出了平均双仿射注意（M-BFA）池化方法。首先，我们假设存在一个超节点vs，它在图的信息聚合中起着主导作用。其次，我们计算每个节点与vs之间的注意力分数。最后，对每个节点进行加权聚合，作为图的向量表示。具体计算步骤如下方方程所示：
$$
h_{m e a n}=\frac{\sum_{i=1}^{n}h_{i}}{n}
$$

$$
h_{fi}=h_{i}^{T}\cdot W
$$

$$
e_{i}=h_{fi}^{T}\cdot h_{m e a n}+h_{i}^{T}\cdot u
$$

$$
a_{i}=\frac{\exp{(e_i)}}{\sum_{j=0}^{n}\exp{(e_j)}}
$$

$$
h_{g}=\sum_{i=0}^{n}a_{i}\cdot h_{fi}
$$

其中，W 是一个可学习的权重矩阵，u 是一个可学习的权重向量，hi 是节点 vi 的最终隐藏状态，而 hg 表示图的向量表示。特别地，我们选择所有节点的隐藏表示的平均 hmean 作为超级节点 vs 的隐藏表示。

![image-20240422105752665](https://s2.loli.net/2024/04/22/CtRrHknFvw2KiNP.png)

##### M-BFA

均值双仿射注意力池化（Mean Bi-Affine Attention Pooling）是一种用于自然语言处理（NLP）任务的注意力机制。这种池化方法被设计用于提取句子级别的语义信息，尤其适用于文本分类、文本匹配等任务。

在均值双仿射注意力池化中，首先对输入的文本序列进行表示学习，通常通过预训练的词嵌入模型（如Word2Vec、GloVe或BERT）来获得每个词的词向量表示。然后，利用这些词向量表示计算句子级别的语义信息。

具体来说，均值双仿射注意力池化包括以下几个步骤：

1. **双仿射注意力计算：** 首先，通过一个双仿射模型计算每个词与其他词之间的注意力权重。这个双仿射模型会考虑每对词之间的相互作用，以及它们之间的语义关系，从而确定它们之间的注意力权重。
2. **加权平均池化：** 接下来，利用计算得到的注意力权重，对所有词的表示进行加权平均，得到整个句子的表示。这样可以将句子级别的语义信息编码为一个固定长度的向量。
3. **池化输出：** 最后，将加权平均得到的句子表示作为池化输出，用于后续的任务，如文本分类或文本匹配。

通过这种方式，均值双仿射注意力池化能够有效地捕捉输入文本序列中词与词之间的语义关系，从而提取出句子级别的语义信息，为各种NLP任务提供了有力的语义表示。







2.2.5. 分类器学习

CSGVD使用多层感知器（MLP）作为分类层，这是最常见的分类器。在这项工作中，我们的目标是训练一个能够从语句级别的控制流图中学习图表示的模型。可以构建一个两层MLP，如方程（14）–（15）所示，来预测一个给定函数是否存在漏洞。
$$
o = softmax(σ (U \cdot h_g ) \cdot V ) \\
y = argmax(o)
$$
其中U和V是两个可学习的权重矩阵，σ(·)是一个激活函数，而y∈{0, 1}表示最终的预测结果。

## 实验

数据集使用 CodeXGLUE

我们构建了一个2层图神经网络模型，将batch size设置为128，dropout设置为0.5，并使用Adam优化器和线性学习率调度器来训练模型，learning rate为5e−4，最多可训练100epochs。所有隐藏层 LSTM, GNN, and MLP, 隐藏大小设置为 768,

我们将我们的模型与以下强大的最新基线进行比较： 

## 结果

根据第3.3节提出的五个问题的结果，本节展示了与分析对应的实验结果。在下表中，每个实验结果使用10次实验的平均分数。我们的实验在一台搭载NVIDIA RTX 3090 GPU和Intel(R) Core(TM) i9-10900X CPU（工作频率为3.70 GHz）的Ubuntu 18.04桌面工作站上进行。表3展示了本文中复制的模型和使用的代码仓库的URL。

### 4.1. 研究问题1：CSGVD的表现如何？

为了探索CSGVD的表现，我们分别将其与基于序列嵌入和图嵌入的两种模型进行比较。根据Zeng等人（2022年）的研究，他们发现CodeXGLUE公告板上发布的实验结果并未得到准确复现。为了公平比较，本文复现了Zeng等人（2022年）提到的一些模型。实验结果如表4所示。在上述表中，有基于序列嵌入的九个模型：BiLSTM（Hochreiter和Schmidhuber，1997），TextCNN（Kim，2014），RoBERTa（Liu等人，2019），CodeBERT（Feng等人，2020），Russell（Russell等人，2018），CoTexT（Phan等人，2021），CodeT5（Wang等人，2021a），PLBART（Ahmad等人，2021）和GraphCodeBERT（Guo等人，2021）。这些基于序列嵌入的方法不能有效利用代码的结构化信息，如控制流信息、数据流信息等。由于缺乏结构化信息，得到的漏洞特征不足，导致预测性能较差。相反，CSGVD使用PE-BL模块和图神经网络来保留代码中的序列信息，并更好地融入其固有的控制流信息。CSGVD将代码序列ci根据控制流信息划分为多个本地块S，每个块在控制流图cfgi中充当节点。在本地块内，CSGVD使用PE-BL聚合本地上下文信息，以保留本地块内的序列信息。然后，使用图神经网络沿着控制流方向执行选择性的全局信息聚合，而不是像前面提到的模型那样每个令牌都从所有其他令牌中聚合信息。结果，CSGVD实现了更高的准确率、召回率和F1得分分别为64.46%、58.99%和60.39%。至于表中的两个基于图嵌入的模型，Devign整合了代码属性图信息，包括控制流和数据流信息。它使用Word2Vec和令牌的平均值来获取节点的向量表示。代码内节点的本地语义信息被忽略，节点的信息无法有效表达。在ReGVD中，边是基于滑动窗口的令牌关系，它们仍然本质上是自然语言序列的关系，缺乏代码中固有的控制流等结构化关系。CSGVD使用代码的控制流信息作为模型的输入。使用BPE分词器对代码进行分词，利用预训练语言模型进行权重初始化。BPE分词器缓解了OOV问题，预训练语言模型增强了嵌入的性能。同时，CSGVD使用双向LSTM来聚合节点内的代码的本地语义信息，以更好地获取节点的向量表示。此外，正如第4.2节所示，从预训练模型中得到的嵌入知识可以更好地增强本地信息的表示。从表4的结果来看，相比Devign，CSGVD在准确率、精确度、召回率和F1得分上分别提升了4.41%、2.02%、19.07%和12.52%。与ReGVD相比，CSGVD在准确率、召回率和F1得分上分别提高了2.75%、21.78%和13.22%。而且CSGVD在与原始ReGVD论文提供的63.69%结果相比也有0.77%的准确率提高。

### 4.2. RQ2: 不同的节点嵌入和初始化方法会如何影响模型性能？

考虑到预训练语言模型在自然语言处理领域取得的优异结果，现在许多研究人员也开始关注代码处理中的预训练(Guo等，2021；Feng等，2020；Phan等，2021；Wang等，2021a；Lachaux等，2021；Ahmad等，2021)。在将预训练模型应用于自然语言处理的下游任务之后，我们也将预训练模型引入到了我们的工作中，并提出了PE-BL模块来进行节点嵌入。与ReGVD类似，PE-BL模块只使用预训练语言模型的词嵌入层，以便与其他模型进行比较。与ReGVD相比，它将预训练模型的词嵌入层作为标记向量化工具使用，并不将其整合到训练模型中。相反，PE-BL模块使用预训练语言模型的词嵌入权重来初始化自嵌入层，并重新训练引入的嵌入权重。在我们的实验中，我们比较了三种不同的参数初始化方式。第一种方式是在训练集上训练我们的字符级词分词器，并使用随机初始化来初始化嵌入层参数，另外两种方式是使用CodeBERT和GraphCodeBERT来初始化我们的嵌入层权重。此外，我们还添加了Word2Vec和Doc2Vec方法来证明我们方法的有效性。如表5中多次实验的平均结果所示，使用预训练模型权重进行初始化的性能优于随机初始化。与随机初始化相比，使用CodeBERT初始化嵌入权重的模型在准确率、精确率、召回率和F1得分方面分别提高了1.61%、0.49%、7.22%和4.35%。使用GraphCodeBERT也是一个显著的改进。实验结果表明，预训练语言模型在代码处理中同样有效。与Word2Vec和Doc2Vec相比，PE-BL模块在多个指标上有显著改进，证明了PE-BL模块的有效性。同时，考虑到每行代码的长度不一致，我们通过几次实验验证了不同序列长度对模型性能的影响。图5显示了经过CodeBERT的BPE分词器处理后的节点序列长度分布。图6显示了不同序列长度的实验结果，从中我们可以观察到随着序列长度的增加，某些指标也会增加。

### 4.3. RQ3：不同的令牌融合方法如何影响模型性能？

在我们的实验中，我们将代码语句视为图中的节点，并且我们需要将多个令牌向量合并以获得代码语句的向量表示作为图中相应节点的向量表示。我们比较了五种不同的融合方法，包括三种常见的融合方法，“平均”、“求和”和“最大”，以及需要神经网络辅助的另外两种方法，即LSTM和双向LSTM。从表6的结果来看，双向LSTM具有更高的指标。与其他方法相比，双向LSTM可以更好地融合代码语句中的上下文信息。此外，使用双向LSTM来获得代码单个语句的向量表示可以提高后续图分类任务的性能。

### 4.4. RQ4: 不同的图神经网络模型如何影响模型性能？

为了验证不同图神经网络对漏洞检测任务的影响，我们比较了三种不同的图神经网络，GCN，GAT（Velickovic等，2018）和残差GCN。为了进行公平比较，图神经网络层被统一为两层，GAT的头部设置为8，并且模型的其他参数保持一致。如表7所示，与GCN相比，残差GCN在准确率、精确率、召回率和F1分数方面分别提高了1.43％、0.92％、4.33％和2.87％。与GAT相比，残差GCN在准确率和精确率上分别提高了1.09％和2.36％。结果显示，残差连接可以提高GCN的性能，并获得更好的图特征。

### 4.5. RQ5: 不同的图嵌入方法如何影响模型性能？

为了探究M-BFA对图嵌入的影响，我们选择了四种不同的节点融合方法进行比较，包括图级平均池化、图级总和池化、图级最大池化和ReGVD中提出的节点融合方法。如表8中的平均实验结果所示，M-BFA池化的指标分别为64.46％、61.87％、58.99％和60.39％。它比其他融合方法要好得多，表现出更好的节点信息融合能力。此外，实验证明，使用节点均值作为超节点的向量表示可以获得最佳结果。与其他方法相比，平均双仿射注意机制可以学习节点的重要性并增强图嵌入。

## 5.对有效性的威胁

第一个威胁与图数据的独特性有关。CSGVD只考虑控制流图作为输入，缺乏其他信息，如数据流图和抽象语法树，这可能限制了其检测相关漏洞的能力。另一个威胁与数据集相关。我们使用了一个用于函数级漏洞检测的C/C++数据集，主要来自两个开源项目FFmpeg和QEMU。罕见的数据集可能导致模型的泛化能力较差。此外，函数级数据样本只关注函数内部的信息，缺乏函数间的信息，这个缺陷导致模型无法捕捉宏观和函数间调用的信息，从而难以理解漏洞的潜在性质。
