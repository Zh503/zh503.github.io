---
title: VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection
date: 2024-05-16 11:09:25
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

##  摘要

本文介绍了VulBERTa，这是一种深度学习方法，用于检测源代码中的安全漏洞。我们的方法使用一个自定义的分词管道在开源C/C++项目的真实代码上对RoBERTa模型进行预训练。该模型学习了代码语法和语义的深层知识表示，我们利用这些知识来训练漏洞检测分类器。我们在几个数据集（Vuldeepecker、Draper、REVEAL和muVuldeepecker）和基准测试（CodeXGLUE和D2A）上评估了我们的方法在二进制和多类漏洞检测任务上的表现。评估结果显示，尽管VulBERTa在概念上相对简单，并且在训练数据量和模型参数数量方面成本有限，但它在不同数据集上实现了最先进的性能，并且优于现有方法。关键词—漏洞检测，软件漏洞，预训练，深度学习，表示学习。

## 引言

MITRE [1] 报告指出，自 2016 年以来，每年提交的软件 CVE 数量逐渐增加，反映了对软件生态系统整体安全性的威胁不断增加。因此，多年来在软件漏洞检测领域的研究呈现稳定增长 [2]，涵盖了静态分析、动态分析和基于机器学习的检测模型等漏洞检测方法谱系。

深度学习在软件漏洞方面取得了令人鼓舞的成果，特别是使用基于序列和图的技术，如双向 LSTM [3]–[5] 和图神经网络 [6]，[7]。这些技术试图从代码中显式地嵌入句法和语义信息，例如通过使用各种依赖和数据流分析来预处理源代码并提取各种代码片段、控制流图和依赖图，最终将其馈送给相应的神经网络。

在本文中，我们采用一种不同的方法，受到基于 Transformer 的神经架构 [8]–[12] 近期成功的启发，能够学习自然语言文本数据的深度表示知识。我们的目标是构建一个关于 C/C++ 的表示模型，嵌入语法和语义信息，而无需我们的直接干预，然后将该模型作为构建漏洞检测模型的基础，使用标准的神经架构。

我们提出了 VulBERTa，旨在从包含不同软件项目的大型代码库中学习 C/C++ 源代码的深度表示。为了促进学习内部代码表示，我们需要创建一个语言感知的可靠分词管道，解析和标记源代码，同时确保基本但关键的句法和语义信息对模型可用。在我们的分词管道中，我们实现了几个新颖特性，以增强现有字节对编码（BPE）[13] 分词器的分词能力。我们引入了一个自定义分词器，将 BPE 与自定义预定义代码标记结合起来构建我们分词器的词汇表。这些预定义标记基于 Clang [14] 的 AST 节点类型（标准关键字和标点符号）和常见的 C/C++ API 函数名称列表。我们的自定义分词管道创建了更好的代码表示，即使在编码后仍保持其原始句法结构。

VulBERTa 实现了一种基于 Transformer 的深度学习架构，称为 RoBERTa [15]。VulBERTa 通过掩码语言建模（MLM）[9] 构建其代码表示知识。我们在比现有方法 [16]，[17] 更少的样本（228 万）和模型参数（1.25 亿）上对 VulBERTa 进行预训练。然后，我们将预训练的 VulBERTa 模型与多层感知器（VulBERTa-MLP）和卷积神经网络（VulBERTa-CNN）交替连接，以微调漏洞检测模型。

我们对 VulBERTa 在不同数据集上进行评估，以测试我们预训练模型的性能和可迁移性。评估结果显示，我们在这些数据集上实现了最先进的检测性能。特别是，在 Draper [18] 数据集上，我们实现了 57.92% 的 F1 分数，优于现有方法，这是令人鼓舞的，因为该数据集由于不平衡和包含真实世界和合成样本的混合而被认为具有挑战性。VulBERTa 在更简单的 muVuldeepecker [5] 数据集上执行多类别分类任务表现良好，加权 F1 分数达到 99.59%。我们还在两个软件漏洞检测基准测试（CodeXGLUE 和 D2A）上测试了 VulBERTa，在使用更少的训练数据和更少模型参数的情况下，它优于大多数现有方法。这些结果表明，VulBERTa 在学习源代码的深度表示和利用该知识来检测软件漏洞方面是有效的。

总的来说，我们的主要贡献包括：  

• 一种自定义的标记化流程，结合了BPE算法和新颖的预定义代码标记（标准的C/C++关键词、标点符号和库API调用），提供更好的代码编码，同时保持源代码的语法结构。  

• 一个小型简化的预训练模型（VulBERTa），提供预训练嵌入权重的可转移性，可在较简单的架构（如MLP和CNN）中重复使用。  

• 软件漏洞检测模型 VulBERTa-MLP 和 VulBERTa-CNN，在不同数据集上实现了最先进的检测性能，并在两个基准测试（CodeXGLUE 和 D2A）中获得了前三名的位置。  

我们的代码和数据是开源的，可在 https://github.com/ICL-ml4csec/VulBERTa 获取。

## 相关工作(略)

## VulBERTa

在这一部分中，我们介绍了 VulBERTa，我们的预训练架构，用于在函数级别的粒度上检测 C/C++ 源代码中的漏洞。该架构分为三个关键组件：一种使用自定义词汇表解析和标记代码的标记化技术；一个构建代码表示模型的预训练会话；以及一个将模型细化以针对具体分类任务的微调会话。图1展示了 VulBERTa 训练管道的 8 个主要步骤。

![image-20240516101015045](https://s2.loli.net/2024/05/16/29zWyftVJvwC5aL.png)

A. 标记器
我们的标记化管道旨在保留句法结构和选定的语义标识符。它由解析器、标记器和编码器组成。这些组件相互堆叠，将原始源代码转换为神经网络可理解的结构。图2展示了 VulBERTa 的整体标记化管道，从原始代码到编码输出序列。接下来，我们描述管道的每个步骤。

![image-20240516101033438](https://s2.loli.net/2024/05/16/NDLZChtGvSfd634.png)

1) 解析器：我们使用多个正则表达式从每个函数的源代码中删除注释。然后，我们使用 Clang [14] 解析源代码，Clang 是一个强大的 C/C++ 解析器，可以解析代码而无需包含任何库或外部依赖项。Clang 允许我们保留源代码的句法结构，同时将其分解为代码标记序列。
2) 标记化：Clang 解析器生成的标记进一步通过经过修改以考虑我们预定义标记的 BPE 算法进行处理，以将解析的输入进一步分解为用于编码的细粒度标记。
字节对编码（BPE）是由 [13] 提出的一种子词标记化算法，用一个不在数据中出现的字节替换一对相似的连续字节。子词标记化还减少了遇到超出词汇表标记的可能性，因为大多数子词标记都包含在词汇表中。遵循了多个 BPE 的实现，如 [17]、[27] 中的实现，我们将词汇表大小定义为 50000，作为我们词汇表中的最大条目数。
预定义标记是我们明确包含在词汇表中的标记，因此它们不参与子词标记化过程。我们的目标是保留它们的句法或语义含义。我们考虑使用标记分桶、归一化和标准的 C/C++ 标记。我们发现，通过预定义 C/C++ 关键字、标点和标准 API 名称，我们在预训练期间能够保留更多关于源代码含义的信息。表 I 总结了我们的预定义标记，这些标记不参与 BPE 过程。完整列表包含 451 个预定义标记。其他标记包括文字和标识符，并传递给 BPE 进行标记化处理。

![image-20240516100526079](https://s2.loli.net/2024/05/16/EIr5nAxLb6DFhfs.png)

3) 编码器：编码是将代码标记转换为张量的过程。为了最大化和泛化整个数据集的学习，我们将预训练的最大序列长度设置为512，因为预训练数据集包含不同的代码库。与此同时，我们将精调任务的最大序列长度增加到1024，以便平均情况下可以包含超过90% 的实际样本而不截断。我们会在右侧对较短的序列进行填充，使用特殊的填充标记（<pad>）。

B. 预训练

预训练是初始训练阶段，我们在此阶段使用MLM目标对标准的RoBERTa [15]模型进行训练，以便学习关于不同软件项目中C/C++代码的信息性通用表示。我们将从这个预训练阶段获得的模型称为VulBERTa模型。结合不同的软件项目有助于学习过程，因为它进一步泛化了代码的表示知识，使其在不同的编码风格之间更具普遍性。这也有助于在预训练过程中增强模型的鲁棒性。我们将嵌入大小设置为768维，遵循RoBERTa-base。这是模型的核心嵌入知识，将对下游的精调任务有所帮助。

C. 精调

在精调阶段，我们进一步对预训练模型进行特定下游任务的训练，而在我们的情况下，这个任务是软件漏洞检测。图3展示了我们用于漏洞检测的精调流程。我们实现了两种不同的分类方法进行精调。第一种方法是在预训练模型之上使用标准的多层感知器（MLP），第二种方法使用了一个文本卷积神经网络（TextCNN），由于CNN架构的稳健性，这种方法更便宜且更快速进行精调。

![image-20240516101051962](https://s2.loli.net/2024/05/16/S4oBkK1utP6YFmx.png)

VulBERTa-MLP：我们实现了一个具有768个神经元的全连接层和一个输出层，根据我们的精调数据集是二元分类还是多类分类数据集，输出层有2或41个神经元。在精调过程中，我们重复使用来自VulBERTa的预训练权重，并继续进行数个epochs 的训练。这种方法是对预训练模型进行精调的最常见方法，因为它利用了整个VulBERTa架构，只需稍作修改。

VulBERTa-CNN：我们提取预训练VulBERTa模型的嵌入权重，并将它们用作混合TextCNN [30]的嵌入权重。TextCNN架构包括三个1维CNN，每个都有自己的最大池化层。输出被连接并展平，然后馈送到两个全连接层（256和128个神经元），再经过一个用于分类的输出层。由于嵌入已经在大型语言模型上进行了预训练，我们在训练任务期间冻结它们。这种技术使TextCNN模型能够继承和使用嵌入的表示知识，并集中于调整任务特定CNN层的权重。

## 数据集

本节描述了本文其余部分中使用的数据集。这些数据集包括来自各种代码库的函数级别的C/C++源代码，包括开源代码库和合成代码样本。我们将这些数据集分为两类，根据它们主要用于预训练或微调。下面提到的所有数据集均属于公共领域，可供下载。

A. 预训练数据集
对于预训练，我们在GitHub和Draper数据集上使用了掩码语言建模（MLM）任务。
1）GitHub：GitHub数据集包括从GitHub上的1060个开源代码库中提取的1,101,075个C/C++函数的源代码。我们使用公共的GitHub API和PyGithub [31]包来编译此数据集。首先，我们收集了所有包含C/C++源代码的代码库的名称，以及它们的星级数。然后，我们根据它们的星级对这些代码库进行排序，并开始从这些代码库中获取文件。由于API速率限制，这个过程大约花了两天的时间才完成。最后，我们使用Joern [19]，一个用于C/C++的开源代码查询引擎，来高效地从每个下载的文件中提取单个函数。这一步是必不可少的，因为我们的方法旨在检测函数级别的安全漏洞。
2）Draper：Draper数据集是由[18]首次介绍的软件漏洞检测数据集。该数据集包括从各个位置收集的1,274,366个C/C++函数，如Debian Linux发行版、开源GitHub代码库和Juliet测试套件 [32]。该数据集涵盖了高度文档化的生产代码到合成测试样本。

B. 微调数据集
对于微调任务，在我们的情况下是漏洞检测，我们选择了一些数据集，这些数据集是安全研究人员为了评估各自的漏洞检测方法而编制的。

1）Vuldeepecker：Vuldeepecker数据集是在[3]中介绍的一个漏洞检测数据集。它由来自国家漏洞数据库（NVD）[33]的真实样本和来自软件保障参考数据集（SARD）[34]项目的合成样本组成。这两个项目由美国国家标准与技术研究所（NIST）积极维护。该数据集经常被用作评估C/C++源代码漏洞检测技术的基准数据集。
2）Draper：这是我们在第IV-A2节中描述的相同数据集，但为了微调，我们包含了（二进制）标签。这个数据集经过三个静态分析器的检查，并由一组安全专家进行了标记。
3）REVEAL：REVEAL数据集是一个真实软件漏洞检测数据集，是在[25]中介绍的，以应对现有数据集中存在的大量数据重复和易受攻击类别的不切实际分布。这个数据集是一个包含来自两个开源项目的源代码的二进制检测数据集：Linux Debian内核和Chromium。
4）muVuldeepecker（MVD）：muVuldeepecker数据集是在[5]中介绍的多类漏洞检测数据集。与Vuldeepecker数据集非常相似，因为这个数据集也来自NVD和SARD。然而，主要区别在于这个数据集由代码小工具而不是通常的函数级源代码组成。
5）Devign：Devign数据集是一个最初在[6]中介绍的真实软件漏洞检测数据集。这个数据集由两个流行的开源软件项目QEMU和FFmpeg的函数级C/C++源代码组成。标记和验证是由一组安全研究人员手动完成的，经过了一个两轮的过程。
6）D2A：D2A数据集是由IBM研究团队策划和介绍的一个真实漏洞检测数据集[26]。这个数据集由几个开源软件项目组成，如FFmpeg、httpd、Libav、LibTIFF、Nginx和OpenSSL。它是使用差异分析技术创建的，以标记静态分析器报告的问题。

## 软件漏洞检测

在本节中，我们描述了如何对VulBERTa模型进行预训练，构建微调的VulBERTa-MLP和VulBERTa-CNN模型，并在多个漏洞检测数据集和基准测试中对它们进行评估。
A. 实验设置
1) 硬件和软件：我们在所有微调实验中使用PyTorch 1.7 [35]，搭载CUDA 10.2和Python 3.7。对于预训练，我们使用拥有48个vCPU、240GB RAM和2个NVIDIA Tesla A100 40GB GPU的Google Compute Engine（GCP）VMs。对于微调，我们使用一台拥有48核Intel Xeon Silver CPU、292GB RAM和2个NVIDIA GTX TITAN Xp GPU的机器。每个GPU都有12GB的视频内存，以适应不同的模型配置。
2) 性能标准：对于每个实验，我们报告了几个评估指标，包括每个数据集初始工作中使用的指标。这样，我们可以进行更公平的比较。这些指标包括真负例（TN）、假负例（FN）、真正例（TP）、假正例（FP）、准确率、精确率、召回率、F1分数、受试者工作特征曲线下面积（ROC-AUC）、精确率-召回率曲线下面积（PRAUC）和马修斯相关系数（MCC）。
3) 基线方法：在性能评估中，我们将VulBERTa与每个数据集现有方法的两种基线技术进行比较。这两种基线技术广泛用于分析基于序列的输入进行漏洞检测，并且例如在[6]和[17]中已经使用过。
（i）基线-BiLSTM：这种技术是LSTM的一种变体，它实现了两层双向LSTM [36]和几个全连接层，以从源代码序列中学习漏洞检测。双向LSTM同时学习代码序列的正向和反向关系。
（ii）基线-TextCNN：这是CNN的一个变体 [30]，其中输入数据是自然语言文本而不是图像。在这种情况下，我们使用源代码作为输入数据，并将其馈送到CNN中。这种技术部署了三个卷积层与池化，并将它们连接成一个单一层，然后将结果传递给几个全连接层。
4) 模型预训练：我们使用MLM预训练VulBERTa模型，使用Draper和GitHub数据集。我们尝试不同的RoBERTa配置（即小型、中型和基础型）以查看模型参数数量如何影响模型的预训练性能。每个预训练会话的持续时间在72到96小时之间，具体取决于模型配置。训练会话进行到500,000步，使用学习率调度程序随着训练损失趋于平稳逐渐降低学习率。根据结果，我们发现在500,000步训练后，基础模型给出了最低的损失。因此，我们选择了具有基础配置的VulBERTa模型（约125M参数）作为我们用于微调的参考预训练模型。
5) 模型微调：我们分别对预训练的VulBERTa-MLP和VulBERTa-CNN模型进行微调，使用漏洞检测作为微调目标，在IV-B节中描述的每个数据集上进行微调。我们将最大迭代次数设置为10，这已经足够多，因为模型在4-5次迭代后往往开始过拟合训练集。我们将学习率设置为0.00003，并使用学习率调度程序在训练损失趋于平稳时逐渐降低学习率。我们遵循每个数据集的原始划分，但如果划分信息不可用，我们将数据集划分为80/10/10（训练/验证/测试）。每个微调会话的持续时间在5到10小时之间，具体取决于数据集和模型的大小。

B. 选定数据集的评估
漏洞检测实验根据数据集进行分开。对于每个数据集，我们选择了原始论文中用于比较的首选评估指标（PEM）。表II显示了评估结果，我们突出显示了每个数据集的最高PEM分数。
1) Vuldeepecker：Vuldeepecker报告的精确度得分为91.9%。然而，使用VulBERTa-MLP，我们实现了95.76%的精确度得分，比原始得分高出3.86%。此外，我们的模型获得了更高的F1得分，为93.03%，而Vuldeepecker获得的得分为92.9%，显示出我们的模型在分类易受攻击和非易受攻击样本时是平衡的。低误报率（0.39%）和漏报率（9.14%）表明VulBERTa-MLP以低误分类率检测合成和真实世界代码中的漏洞。
2) Draper：[18]的作者使用多个评估指标在Draper数据集上评估他们的模型。我们选择MCC作为比较基础，因为它适用于不平衡数据集，而Draper数据集的易受攻击和非易受攻击类别是不平衡的。VulBERTa-CNN在该数据集上获得了55.86%的MCC分数。这比[18]中报告的性能提高了2.26%，这是显著的，因为我们可以在保持跨预测的类平衡的同时提供更好的检测。
3) REVEAL：尽管没有使用那里提出的数据再平衡技术，VulBERTa-MLP模型的F1得分为45.27%，高于[25]中报告的41.25%。相反，我们在微调过程中为每个类别（易受攻击和非易受攻击）分配权重，以减少类别不平衡问题而不改变数据集。我们的方法还获得了高达2.57%的真正阳性率（TPR）。这表明VulBERTa-MLP在正确检测易受攻击样本的同时，也能保持与非易受攻击类的平衡更有效。
4) muVuldeepecker：与之前的实验不同，这是一个多类别分类任务。muVuldeepecker数据集包含40个CWE的单独类别，因此每个正样本可以映射到特定的安全漏洞。相比于[5]中报告的96.28%，VulBERTa-MLP实现了99.59%的高加权F1得分。它还将假阴性率（FNR）从5.53%降低到0.41%，这是显著的，因为被检测为易受攻击的额外样本需要被分配到正确的类别。此外，查看特定类别的预测，如CWE-190和CWE-191（整数溢出和下溢），我们可以看到VulBERTa-MLP能够正确地分配超过90%的易受攻击样本到它们各自的类别中。
尽管使用后者的数据集和首选评估指标，我们的模型成功超越了比较模型的性能。这发生在各种数据集中，包括合成和真实世界数据，平衡和不平衡的类别，二元和多类别分类任务。

C. 基准测试评估

我们还对VulBERTa-MLP和VulBERTa-CNN在两个公开的基准测试上进行了评估，这些基准测试被社区用作比较不同源代码模型在标准化任务上的基础。在这两种情况下，漏洞检测任务的主要评估指标为准确率。

![image-20240516103819312](https://s2.loli.net/2024/05/16/iKlyP4VXB8nbzNA.png)

1）CodeXGLUE：CodeXGLUE [37] 基准测试是微软研究介绍的第一个也是最受欢迎的用于编程语言理解的基准测试。我们关注缺陷检测任务，其中包括在第IV-B5节中描述的Devign数据集上的漏洞检测。表III-A显示了在发表时的CodeXGLUE基准测试排行榜上的排名，包括我们的结果1。VulBERTa-MLP的准确率达到了64.75%，排名第3，略低于CoText和C-BERT。值得注意的是，VulBERTa-MLP的模型参数数量明显低于CoText的55.07%，并且是排名前两位模型数据的一小部分。令人印象深刻的是，VulBERTa-CNN的性能稍低，但模型规模不到CoText的1%和C-BERT的2%。

2）D2A：D2A [26] 是IBM研究介绍的漏洞检测基准测试。它基于D2A数据集，详见第IV-B6节。表III-B显示了在发表时的D2A基准测试排行榜上的排名，包括我们的模型2。VulBERTa-MLP在“function”任务（与我们方法相关的唯一任务）中以62.30%的准确率位居榜首，VulBERTa-CNN以60.68%的准确率位居第二。有趣的是，在这个数据集上，我们的两个模型都胜过了C-BERT，尽管后者具有更大的预训练数据集和更多的参数（与VulBERTa-CNN相比）。
D. 讨论

表II显示，VulBERTa-MLP在4个数据集中有3个获得最佳的PEM分数，VulBERTa-CNN在剩下的数据集中获得最佳的PEM分数。然而，如果我们比较我们的两个模型在全面的微调结果上，我们会注意到两者之间的差异微乎其微。同样，我们可以看到VulBERTa-MLP和VulBERTa-CNN在基准测试评估中有密切关系。两个模型始终排在一起，并在两个基准测试中取得了最先进的性能。一个可能的解释是，从预训练的VulBERTa模型中继承的代码表示知识对于漏洞检测起着至关重要的作用。

![image-20240516103709953](https://s2.loli.net/2024/05/16/ntXLyTurEQxU2wj.png)

模型规模和预训练数据规模通常在学习更好的代码表示方面起着重要作用。然而，VulBERTa仅包含1.25亿个参数，我们的预训练数据仅包含2.28百万个C/C++函数，例如，与CoText（3.75亿）和C-Bert（850万）相比。通过使用更小的模型和预训练数据提供了最新的检测性能，我们与这些方法不相上下。

根据我们对测试和实施不同标记化技术的初步分析，我们认为我们的标记化方法在使句法和语义信息易于简单神经架构访问方面起着重要作用。

事实上，模型的简洁性似乎是解决方案的一部分。我们简单的基于TextCNN的VulBERTa-CNN方法（仅有2百万参数)在Draper数据集上的MCC分数为55.86%，高于最近在[40]中提出的复杂的3GNN模型所获得的52%，后者使用了Crystal Graph Convolutional Network和Self Attention Pooling。

E.限制

尽管我们的研究取得了令人鼓舞的成果，但我们也发现了一些限制。在我们的方法中，一个常见且尚未解决的问题是漏洞检测数据集中偶尔存在标签不准确的情况。虽然深度学习在训练时应该对标签噪声具有抗干扰能力，但在测试过程中存在噪声会在一定程度上削弱定量性能结果。虽然我们的模型相对较小，但训练仍然昂贵。由于资源有限，我们无法探索更大规模的模型配置和组合，包括进行超参数调整。因此，不同的 VulBERTa 配置可能会取得更高的性能。最后，我们工作的主要限制在于缺乏系统性尝试在野外的开源项目中检测新型 0day 漏洞。这是因为手动审查误报的挑战，我们希望在未来的工作中利用可解释性技术来解决这一问题。

结论

我们提出了 VulBERTa，这是一个预训练模型，用于学习 C/C++ 代码的深度表示。我们模型的一个关键组成部分是一个自定义的标记化流程，旨在保留源代码中的句法和语义知识，而不需要过于复杂的神经架构。我们使用 VulBERTa 模型作为基础，微调了两个用于漏洞检测的模型，在几个数据集和基准测试中取得了最先进的性能。这些模型以其概念上的简单性和低复杂性脱颖而出，以参数数量衡量。 