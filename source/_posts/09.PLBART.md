---
title: PLBART
date: 2024-04-22 09:53:28
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

## PLBART

PLBART采用了去噪的序列到序列预训练方法，以利用编程语言（PL）和自然语言（NL）中的未标记数据。这种预训练使得PLBART能够对语言的语法和语义进行推理。同时，PLBART也学会了连贯地生成语言。

### 2.1 去噪预训练

 **数据与预处理** 

我们在大量Java和Python函数以及来自Github和StackOverflow的自然语言描述上对PLBART进行预训练。我们从Google BigQuery下载了与Java和Python语言相关联的所有GitHub仓库。3 我们按照Lachaux等人（2020年）的预处理流程提取Java和Python函数。我们从stackexchange下载了StackOverflow的帖子数据（包括问题和答案，不包括代码片段，日期：2020年9月7日）。4 预训练数据集的统计数据展示在表1中。我们使用sentencepiece模型（Kudo和Richardson，2018年）对所有数据进行分词，该模型是在预训练数据的1/5部分上学习的，用以生成50,000个子词标记。 从不同模态聚合数据的一个关键挑战是某些模态可能拥有更多的数据，例如我们的编程语言（PL）数据是自然语言（NL）的14倍。因此，我们按照Conneau和Lample（2019年）的方法混合并上/下采样数据，以减轻对PL的偏向。我们根据多项式分布（q1, q2, ..., qN）对预训练实例进行采样： 

![image-20240403151312151](https://s2.loli.net/2024/04/03/xmkWvZFDrbC7QML.png)

其中N是语言的总数，ni是第i种语言中的实例总数。我们将平滑参数α设置为0.3。

**架构**

PLBART采用了与BARTbase（Lewis等人，2020年）相同的架构，即序列到序列的Transformer架构（Vaswani等人，2017年），包括6层编码器和6层解码器，模型维度为768，12个注意力头（约1.4亿个参数）。唯一的区别是，我们在编码器和解码器顶部各增加了一层层归一化层，这遵循了Liu等人（2020年）的做法，该做法被发现能够稳定FP16精度下的训练。

**噪声函数**Noise function

在去噪自编码中，模型学习重建由噪声函数损坏的输入文本。重建原始输入需要模型学习语言的语法和语义。在本研究中，我们采用了三种噪声策略：token掩码、token删除和token填充（Lewis等人，2020年）。根据前两种策略，随机选择token并用掩码token替换或从输入序列中删除。在token填充中，采样一定数量的文本跨度并用单个掩码token替换。跨度长度从泊松分布（λ=3.5）中抽取。我们每个实例中掩码掉35%的token。

**输入/输出格式**

编码器的输入是一个带噪声的文本序列，而解码器的输入是原始文本，但位置偏移了一位。分别在每个编码器和解码器的输入前和后附加一个语言标识符（例如，、）。我们在表2中提供了几个示例。如果输入实例超过了512的最大序列长度，它们将被截断。

**学习**

PLBART在N种语言（在我们的案例中，N=3）上进行预训练，每种语言Ni都有一组未标记的实例集合Di = {x1, . . . , xni}。每个实例都通过噪声函数f进行损坏，我们训练PLBART从f(x)中预测原始实例x。从形式上讲，PLBART被训练以最大化损失函数Lθ： 

![image-20240403151740532](https://s2.loli.net/2024/04/03/SogDHTiJs6wbZkn.png)

其中mi是在语言i中采样的实例数量，而似然度P是按照标准的序列到序列解码方式进行估计的。

**优化Optimization**

我们使用8块Nvidia GeForce RTX 2080 Ti GPU对PLBART进行了100K步的训练。有效批处理大小维持在2048个实例。在优化过程中，我们使用了Adam优化器（ = 1e-6, β2 = 0.98），并采用了线性学习率衰减计划。训练开始时设置了0.1的dropout，在5万步时减少到0.05，在8万步时减少到0。这样做是为了帮助模型更好地拟合数据（Liu等人，2020年）。总训练时间大约为276小时（11.5天）。所有实验都是使用Fairseq库（Ott等人，2019年）完成的。

### 微调Fine-tuning PLBART

我们针对两大类下游应用对 PLBART 进行微调。

**序列生成**

PLBART具有编码器-解码器架构，其中解码器能够自回归地生成目标序列。因此，我们可以直接在序列生成任务上对PLBART进行微调，例如代码摘要、生成和翻译。与去噪预训练不同，在微调期间，源序列作为输入提供给编码器，而解码器生成目标序列。源序列和目标序列可以是代码片段或文本序列。表3展示了在不同生成任务中对PLBART的输入和输出的一些示例。需要注意的是，PLBART会在解码序列前添加一个语言标识符；这使得PLBART能够在多语言环境下进行微调（例如，在多种语言中进行代码生成）。

**序列分类Sequence Classification**

我们按照Lewis等人 (2020) 的方法，对PLBART在序列分类任务上进行微调。输入序列同时被送入编码器和解码器。对于一对输入，我们将它们拼接在一起，但在它们之间插入一个特殊的标记（“</s>”）。在输入序列末尾添加一个特殊的标记。来自最终解码器层的最后一个标记的表示被送入线性分类器进行预测。

**优化Optimization**

我们对PLBART进行最多100K步的微调，使用2500个预热步骤来处理所有下游任务。我们分别将最大学习率、有效批量大小和丢弃率设置为3e-5、32和0.1。最终的模型根据验证BLEU（在生成任务中）或准确性（在分类任务中）进行选择。

## 实验设置

为了在更广泛的背景下理解PLBART的性能，我们对其在多个任务上进行评估。我们的评估侧重于评估PLBART在源代码和相关自然语言文本中捕捉丰富语义的能力。

### 评估任务Evaluation Tasks

我们将评估任务分为四个类别。评估任务的数据集在表4中总结。我们使用CodeXGLUE（Lu等，2021）提供的公共数据集以及所有任务的相应的训练验证-测试划分。

**代码摘要化（Code Summarization）**是指从一段代码生成自然语言（英语）摘要的任务。我们对PLBART进行微调，用于摘要化六种不同编程语言的源代码，分别是Ruby、Javascript、Go、Python、Java和PHP。

**代码生成（Code Generation）**恰好是代码摘要化的反义词。它指的是根据自然语言描述生成目标编程语言的代码（PL即Programming Language）。我们对Concode数据集（Iyer等，2018）进行了PLBART的微调，该数据集的输入是描述Java中类成员函数和类环境的文本，输出则为目标函数。

**代码翻译(Code Translation)**需要一个模型，以从源编程语言中的输入代码生成目标编程语言中等效的代码。请注意，源语言和目标语言可以是相同的。因此，在这个类别中，我们考虑了两种类型的任务。

第一项任务是一个典型的编程语言翻译任务，即将代码从Java转换为C#，反之亦然。在这个任务中，翻译后的代码的语义意义应与输入代码完全匹配。因此，这个任务评估了PLBART对程序语义和语法在各种编程语言中的理解能力。我们考虑的第二个任务是程序修复。在这个任务中，输入是有错误的代码，输出是修复了错误的同一段代码的修改版本。这个任务帮助我们了解PLBART理解代码语义并在代码中应用语义更改的能力。

**代码分类**旨在预测单个或一对源代码的目标标签。我们在两个分类任务上评估PLBART。第一个任务是克隆检测，给定一对代码，目标是确定它们是否彼此克隆（类似于自然语言处理中的释义）。第二个任务是检测一段代码是否存在漏洞。这个任务可以帮助我们评估PLBART在未知PL中的程序理解能力，因为该任务中的代码示例是用C/C++编写的。

### 评估指标Evaluation Metrics

**BLEU**计算生成序列与参考文献集之间的n-gram重叠。对于所有生成任务，我们使用语料库级别的BLEU（Papineni等人，2002）得分，除了代码摘要，我们使用经过平滑的BLEU-4得分（Lin和Och，2004），按照Feng等人（2020）的方法。

**CodeBLEU**是用于衡量合成代码质量的度量标准（Ren等人，2020）。与BLEU不同，CodeBLEU还考虑了基于抽象语法树和数据流结构的语法和逻辑正确性。

**精确匹配（EM）**评估生成序列是否与参考文献完全匹配。

### 基线方法Baseline Methods

我们将PLBART与几个最先进的模型进行了比较，并广泛将它们分为两类。第一类是从头开始训练的模型，第二类是在未标记的语料库上进行预训练，然后再在评估任务上进行微调的模型。

#### 3.3.1 从头开始训练

**Seq2Seq**（Luong等，2015）是一种基于LSTM的Seq2Seq模型，具有注意机制。通过字节对编码来构建词汇表。

**Transformer**（Vaswani等，2017）是PLBART和其他预训练模型的基础架构。Transformer基线具有与PLBART相同数量的参数。因此，与这个基线的比较可以直接展示预训练PLBART的实际用途。

#### 3.3.2 预训练模型

如第2节所述，PLBART由编码器和自回归解码器组成。我们比较了两类预训练模型的PLBART。首先是仅编码器的模型（例如RoBERTa、CodeBERT和GraphCodeBERT），它们与一个随机初始化的解码器结合在一起用于任务特定的微调。第二类基准模型包括仅解码器的模型（CodeGPT），可以进行自动生成。

**RoBERTa和RoBERTa（code）**是RoBERTa（Liu等，2019）模型的变种。虽然RoBERTa是在自然语言上进行预训练的，但RoBERTa（code）是在CodeSearchNet（Husain等，2019）的源代码上进行预训练的。

**CodeBERT**（Feng等，2020）将掩码语言建模（MLM）（Devlin等，2019）与替换标记检测目标（Clark等，2020）相结合，进行了Transformer编码器的预训练。

**GraphCodeBERT**（Guo等，2021）是与本研究同时进行的一项工作，通过对代码标记之间的数据流边进行建模，改进了CodeBERT。由于GraphCodeBERT的实现尚未公开，我们直接从论文中报告了其表现。

**GPT-2、CodeGPT-2和CodeGPT-adapted**都是GPT风格的模型。虽然GPT-2（Radford等，2019）是在自然语言语料库上进行预训练的，但CodeGPT-2和CodeGPT-adapted是在CodeSearchNet（Lu等，2021）上进行预训练的。请注意，CodeGPT-adapted是从GPT-2检查点开始进行预训练的。

## 结果和分析

我们的目标是解答以下问题：
1. PLBART是否能够从无标签数据中学习强大的程序和语言表示？
2. PLBART是否能够学习程序的特征，例如语法、风格和逻辑数据流？
3. 在具有有限注释的未知语言中，PLBART的表现如何？

### 4.1 代码摘要

表格5展示了代码摘要的结果。PLBART在六种编程语言中的五种中表现优于基线方法，整体平均改善值为0.49 BLEU-4，超过了CodeBERT。改善幅度最大（约16%）的是Ruby语言，它的训练样本最少。与CodeBERT不同，PLBART没有在Ruby语言上进行预训练，然而显著的性能改善表明PLBART学习到了更好的通用程序语义。相比之下，PLBART在PHP语言中表现不佳。潜在原因是预训练语言与PHP之间的语法不匹配。令人惊讶的是，RoBERTa在PHP语言上的表现优于PLBART。我们怀疑这是因为RoBERTa只对自然语言进行了预训练，所以不会受到语法不匹配的问题的影响。总的来说，与Transformer基线相比，PLBART的改善平均为2.76 BLEU-4，我们将这一改善归功于预训练步骤。

4.2 代码生成

表6显示了从自然语言描述生成代码的评估结果。PLBART在BLEU和CodeBLEU方面都优于所有基线模型。虽然CodeGPT适应（Lu等，2021年）在精确匹配（EM）得分方面表现最佳，但在CodeBLEU方面，PLBART的优势要远远超过CodeGPT适应。这个结果表明，相比于所有基线模型，PLBART生成的代码在语法和逻辑上都更正确。

图2显示了PLBART生成的代码示例。参考代码和生成的代码之间的差异在第6行开始。在参考代码中，返回的是loc0，然而在生成的代码中，相同的loc0在else块中被返回。如果我们仔细观察，在参考代码中，只有当第3行的条件（即loc0 == null）为假时，才会执行第6行。在生成的代码中，只有当第3行的条件为假时，才会返回loc0，使得生成的代码在语义上等同于参考代码。

为了研究PLBART是否在预训练或微调过程中学习了代码语法和逻辑流程，我们进行了消融研究，在这个任务中使用了训练样本的子集（10K、20K和50K），对PLBART进行微调。如表6所示，仅使用10K个样本，PLBART在CodeBLUE方面优于所有基线模型。这个消融研究表明，PLBART在预训练期间学习了程序语法和数据流，即使在少量样本上进行微调，也可以在下游任务中发挥出色的性能。

### 4.3 代码翻译

表 7 展示了代码翻译的评估结果。PLBART 相对于 EM、BLEU 和 CodeBLEU，在所有基准模型中表现更优。在从 Java 翻译成 C# 和从 C# 翻译成 Java 时，PLBART 相较于 CodeBERT 分别提升了 9.5% 和 10.5%。尽管 PLBART 没有在 C# 语言上进行预训练，但 Java 和 C# 存在显著的语法和语义相似性。因此，PLBART 能理解 C# 的语法和语义。然而，这种相似性并不简单，使得 Naive copy 和 PBSMT 在翻译任务中表现非常差劲。

图 3 展示了一个示例，其中 PLBART 生成的 C# 代码与参考代码并不完全匹配；然而它们在语义上是等价的。在参考代码中，else 代码块（第 4-9 行）与生成的代码中的 else if 代码块（第 4-7 行）是等价的。此外，start 在函数参数中生成，且在函数体中使用，等价于参考代码中的 start_1。这进一步证明了 PLBART 对语法的理解以及其能够推理源代码中的数据流。我们在附录中提供更多定性示例。

在程序修复任务中，输入和输出都是相同的语言。输入是有错误的代码，输出应该是目标的无错误代码。因此，在这个任务中，精确匹配是关键指标。然而，如表 8 所示，在 Javasmall 和 Javamedium 数据集中，与 CodeBERT 相比，PLBART 能够生成比正确的错误修复数量分别多出 17.13% 和 74.03%。另一方面，PLBART 在使用结构感知预训练来学习程序语法和语义的 GraphCodeBERT 上表现相当。

### 4.4 分类

在克隆检测和漏洞检测任务中，PLBART表现优于CodeBERT。我们在表9中呈现了结果。在漏洞检测任务中，代码语义是最关键的特征（Zhou等，2019；Chakraborty等，2020）。由于PLBART没有在C/C++语言上进行预训练，与Transformer基准相比的提高性能证明了PLBART能够识别超出语言语法特定性的语义。此外，PLBART在程序理解上的改进表现也证实了它在生成能力之外的有效性。
我们承认，PLBART和CodeBERT都不是漏洞检测领域的最先进模型，因为基于图的模型在这个任务中表现最好。在这个评估中，我们的目标是研究PLBART在未知语言中对程序语义的理解能力，针对的是不同类型的任务（与生成不同，即分类）。

## 6 结论

本文介绍了PLBART，一个庞大的预训练序列到序列模型，它能够执行程序和语言理解以及生成任务。PLBART在包括代码摘要、代码生成和代码翻译在内的各种软件工程任务中取得了最先进的性能。此外，针对辨别性任务的实验证明了PLBART在程序理解方面的有效性。我们还展示了由于预训练，PLBART学习到了关键的程序特征，如语法、标识符命名规范和数据流。未来，我们希望探索一种同时在所有下游任务上对PLBART进行微调的方式。

### 更广泛的影响

在增加程序员生产力方面，软件工程中的自动化至关重要。开发人员日常工作中繁琐任务的减少，将使他们有更多时间解决对社会福祉有意义的重要问题。在软件开发生命周期中存在着许多程序和语言应用，如代码文档/摘要、代码合成、跨语言代码翻译等，这些都可以通过自动化来促进软件工程。大规模数据的可用性（多亏了开源仓库、论坛和全球数百万的贡献者）为以数据驱动方式解决这些问题提供了机会。PLBART旨在处理需要对源代码和相关文本数据进行完全句法和语义理解的程序和语言应用。对于我们展示的评估任务，PLBART将作为一个可靠且可复制的基线，指导未来的研究。我们还相信，我们的工作可以成为未来解决各种软件工程问题的出色起点。