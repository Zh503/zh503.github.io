---
title: REGVD
date: 2024-04-25 09:53:28
categories:
  - 学习笔记
  - 论文译文
tags:
  - 
author: 
  name: hao
  link: https://github.com/zh503
---

# REGVD

来源：In 44th International Conference on Software Engineering Companion (ICSE ’22 Companion),

源代码：https://github.com/daiquocnguyen/GNN-ReGVD

代码基于CodeXGLUE -- Defect Detection进行调整源代码：https://github.com/microsoft/CodeXGLUE/tree/main/Code-Code/Defect-detection

数据集来源文章：[*Devign*: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks](http://papers.nips.cc/paper/9209-devign-effective-vulnerability-identification-by-learning-comprehensive-program-semantics-via-graph-neural-networks.pdf)

数据集地址：https://drive.google.com/file/d/1x6hoF7G-tSYxg8AFybggypLZgMGDNHfF/view?usp=sharing

## 摘要

识别源代码中的漏洞对于保护软件系统免受网络安全攻击至关重要。然而，这也是一个具有挑战性的步骤，需要在安全和代码表示方面具备专业知识。为此，我们旨在开发一种通用、实用且与编程语言无关的模型，能够轻松运行在各种源代码和库上。因此，我们将漏洞检测视为归纳式文本分类问题，并提出了一种基于图神经网络的简单而有效的模型——ReGVD。具体而言，ReGVD将每个原始源代码视为一系列标记的扁平序列，从而构建一个图形，在其中节点特征仅由预训练编程语言（PL）模型的标记嵌入层初始化。然后，ReGVD利用GNN层之间的残差连接，并结合图级求和和最大池化来返回源代码的图嵌入。ReGVD在真实世界的CodeXGLUE漏洞检测基准数据集上表现优于现有的最先进模型，并获得最高准确性。我们的代码可以在https://github.com/daiquocnguyen/GNN-ReGVD上找到。

## INTRODUCTION

近期，软件漏洞问题迅速增多，无论是通过公开披露的信息安全缺陷和曝光（CVE），还是在私有源代码和开源库中被曝光。这些漏洞是导致软件系统遭受经济和社会上重大损害的网络安全攻击的主要原因[18,30]。因此，漏洞检测是识别源代码中的漏洞并为软件系统提供安全解决方案的必要且具有挑战性的步骤。早期的方法[18,22,25]通过仔细设计为机器学习算法而手动构建的特征来检测漏洞。然而，这些早期方法存在两个主要缺点。首先，创建良好的特征需要先前的知识，因此需要专业领域专家，并且通常耗时。其次，手动构建的特征不切实际且不容易适应随时间演化的众多开源代码和库中的所有漏洞。为了减少特征工程上的人力工作，一些方法[15,23]将每个原始源代码视为扁平的自然语言序列，并探索应用于自然语言处理（NLP）中的深度学习架构（如LSTMs [9]和CNNs [11]）来检测漏洞。最近，预训练的语言模型（例如BERT [4]）作为一种流行的学习范式出现，并在NLP应用中取得了显著的成功。受到这种流行的BERT风格学习范式的启发，预训练的编程语言（PL）模型，如CodeBERT [5]，在漏洞检测等PL下游任务的性能上有所提高。然而，正如[20]所提及的，BERT风格模型中自注意力层内所有位置之间的所有交互会构建出一个完整的图，即每个位置与所有其他位置都有边缘相连；因此，这限制了学习源代码中的局部结构以区分漏洞。

图神经网络（Graph Neural Networks，简称GNN）最近已经成为将节点和图嵌入到低维连续向量空间中的主要方法[7, 19, 26]。GNN提供了更快、更实用的训练方法，更高的准确性，并在文本分类等下游任务中取得了最新的研究成果[10, 21, 28, 29]。Devign提出利用带门控的GNN（Gated GNNs）[14]进行漏洞检测，其中Devign使用一个PL（编程语言）解析器提取多边图信息。然而，Devign在实际应用中存在困难。主要原因是现实中没有一个能够完美解析各种源代码和库，并且不出现任何内部编译错误和异常的解析器。本文的目标是开发一个通用、实用且不依赖于具体编程语言的模型，能够轻松运行于各种源代码和库中。因此，我们将漏洞检测视为归纳式文本分类问题，并引入ReGVD – 一种简单而有效的基于GNN的漏洞检测模型，具体如下：（i）ReGVD将每个原始源代码视为一个标记序列，用于构建图（在第2.2节中），其中节点特征仅通过预训练PL模型的标记嵌入层进行初始化。（ii）ReGVD利用GNN（如GCNs [13]或Gated GNNs [14]），在GNN层之间使用残差连接（在第2.3节中）。（iii）ReGVD对和嵌入图代码的汇总和最大池化进行混合，以产生源代码的图嵌入（在第2.4节中）。这个图嵌入被馈送到一个全连接层，然后是一个Softmax层来预测代码的漏洞。大量实验证明，相对于CodeXGLUE [17]中的基准漏洞检测数据集，ReGVD在性能上显著优于现有的最新模型。ReGVD的准确性最高为63.69%，相对于CodeBERT和GraphCodeBERT，分别获得了1.61%和1.39%的绝对改进；因此，ReGVD可以作为未来工作的新强基准线。

## THE PROPOSED REGVD

### Problem definition



我们在函数级别上考虑源代码的漏洞检测，即我们旨在确定给定的原始源代码中的函数是否存在漏洞[30]。我们将数据样本定义为$\{(c𝑖, y𝑖 )|c𝑖 ∈ C, y𝑖 ∈ Y\}^𝑛_𝑖=1$，其中C表示原始源代码的集合，Y = {0，1}表示标签集，1表示有漏洞，0表示没有漏洞，𝑛是实例的数量。在本文中，我们将漏洞检测视为一种归纳文本分类问题，并利用GNNs解决该问题。因此，我们为每个源代码c𝑖构建一个图$g_𝑖 (V, 𝑿, 𝑨) ∈ G$，其中V是图中的𝑚个节点的集合；$𝑿 ∈ R^{𝑚×𝑑}$是节点特征矩阵，其中每个节点v~𝑗~∈ V由一个𝑑维实值向量𝒙~𝑗~ ∈ R^𝑑^表示；𝑨 ∈ {0, 1}^𝑚×𝑚^是邻接矩阵，其中𝑨~v,u~等于1表示节点v和节点u之间有边，否则为0。我们旨在学习一个映射函数𝑓 : G → Y来确定给定的源代码是否存在漏洞。映射函数𝑓可以通过将损失函数最小化来学习，同时对模型参数进行正则化，如下所示：
$$
min∑︁^n_{𝑖=1}L(𝑓(g_𝑖(V,𝑿,𝑨){,} y_𝑖|c_𝑖 ))+ 𝜆\lVert\theta\rVert^2_2
$$


其中$L(.)$是交叉熵损失函数，𝜆是可调的权重。

### Graph construction

![image-20240425093240135](https://s2.loli.net/2024/04/25/1Vo5ORetNYaAXsr.png)

我们将原始源代码视为一个令牌的平面序列，并在图1中展示了两种图构建方法[10,29]，其中我们在这两种方法中省略了自循环，因为这些自循环在我们的实验中并未帮助改善性能。 

#### 独特令牌为中心的构建。 

独特的令牌聚焦构建。我们将独特的令牌表示为节点，并将令牌之间的语义关系（在固定大小的滑动窗口内）表示为边，从而得到的图形具有邻接矩阵 𝑨，如下所示：
$$
A_{v,u}=
\left\{\begin{matrix}
 1,如果v和u同时出现在滑动窗口内，并且v≠u。 \\
 0,其他
\end{matrix}\right.
$$

#### 基于索引的构建。

给定一个由𝑙个标记 $\{𝑡_i \}^𝑙_{i=1}$组成的平坦序列，我们将所有标记表示为节点，即将每个索引𝑖视为表示标记$𝑡_i$的节点。节点的数量等于序列长度。我们还将索引之间的共现关系（在一个固定大小的滑动窗口内）表示为边，得到的图具有邻接矩阵𝑨如下：
$$
A_{v,u}=\left\{\begin{matrix}1,如果i和j同时出现在滑动窗口内，并且i≠j。 \\ 0,其他\end{matrix}\right.
$$

### 节点特征初始化。 

值得注意的是，最近预训练的编程语言（PL）模型，如CodeBERT [5]，已经提高了PL下游任务，比如漏洞检测的性能。为了获得预训练PL模型的优势，并进行公正的比较，我们只使用预训练PL模型的标记嵌入层来初始化节点特征向量，以便报告我们的最终结果。

### 带有残差连接的图神经网络

图神经网络（GNNs）旨在通过递归地聚合节点周围的向量表示来更新节点的向量表示[13, 24]。在数学上，给定一个图 g(V, 𝑿, 𝑨)，我们可以简单地表示图神经网络如下：
$$
\mathrm{H}^{(k+1)}=\mathrm{GNN}\left(A,\mathrm{H}^{(k)}\right)
$$
其中$H^{(𝑘)}$是第𝑘次迭代/层的节点的 矩阵表示；$H^{(0)} = 𝑿$。最近的文献中提出了许多图神经网络（Graph Neural Networks，简称GNNs），其中图卷积网络（Graph Convolutional Networks，简称GCNs） [13] 是最广泛使用的一种，而门控图神经网络（Gated graph neural networks，简称“Gated GNNs”或“GGNNs”）[14] 也适用于我们的数据结构。我们的ReGVD将GCNs和GGNNs作为基本模型使用。形式上，GCNs定义如下：
$$
\mathrm{h}_{\mathrm{v}}^{(k+1)}=\phi\left(\sum_{\mathrm{u}\in{N_{\mathrm{v}}}}a_{\mathrm{v,u}}W^{(k)}\mathrm{h}_{\mathrm{u}}^{(k)}\right),\forall_\lor\in\mathbf{V}
$$
在拉普拉斯归一化邻接矩阵$D^{\frac{1}{2}}A D^{-{\frac{1}{2}}}$中，$𝑎_{v,u}$是节点v和u之间的边常数（因为我们省略了自环），其中D是𝑨的对角节点度矩阵；$𝑾^{(𝑘)}$是权重矩阵；而𝜙是诸如ReLU之类的非线性激活函数。

GGNNs采用GRUs[2]，展开固定次数的时间步长的循环，并消除了约束参数以确保收敛的需求。



![image-20240425092836907](https://s2.loli.net/2024/04/25/Tbx7DmaF9SJ4M5G.png)

其中 z 和 r 是更新门和重置门；𝜎 是 sigmoid 函数；⊙ 是逐元素乘法。

残差连接[8]被用来将在较低层学习到的信息融入到更高层，更重要的是，它允许梯度直接通过层传递，避免梯度消失或梯度爆炸的问题。受此启发，我们遵循[1]将残差连接应用于图神经网络的不同层之间，并在不同层之间保持相同的隐藏大小。具体来说，ReGVD重新定义了图神经网络如下：
$$
H^{(k+1)} = H^{(k)} + GNN (A, H^{(k)})
$$
![image-20240425093113013](https://s2.loli.net/2024/04/25/4ubFzsg3p7U2nMa.png)

### 2.4 图级读出池化层

图级读出层用于为每个输入图形产生一个图嵌入。ReGVD利用了求和池化，因为它在图分类方面能产生更好的结果[27] (在我们的试验研究中，使用总和池化的准确度比使用[29]中所用的均值池化更高。)。此外，ReGVD还利用了最大池化来利用更多节点表示的信息。然后，ReGVD将求和池化和最大池化混合以产生图嵌入 eg。

![image-20240425093713198](https://s2.loli.net/2024/04/25/Bj7YCkfOmWi1zl9.png)

其中，$ev$ 是节点 $v$ 的最终向量表示，其中 $\sigma(w^T h(K)_v + b)$ 作为对节点集的软注意机制 [14]，$h(K)_v$ 是最后第 $K$ 层节点 $v$ 的向量表示；$MIX(.)$ 表示任意函数。ReGVD探究了由SUM、MUL 和 CONCAT 组成的三个MIX函数，如下：

![image-20240425093809978](https://s2.loli.net/2024/04/25/3bBtuC9YMk8J1Uw.png)

接着，ReGVD将eg输入到一个全连接层，然后接一个softmax层，用于预测源代码是否存在漏洞，表达式如下：$\hat{y}_g = softmax(W_1e_g + b_1)$。最后，通过最小化第2.1节中提到的交叉熵损失函数来训练ReGVD。我们在图2中展示了提出的ReGVD的结构。

### 实验和结果

#### 实验设置

##### 数据集

使用CodeXGLUE[17]的真实世界基准进行功能级别的漏洞检测。该数据集由Zhou等人[30]首次创建，包括27318个手动标记的易受攻击或不易受攻击的函数，这些函数是从两个大型且流行的C编程语言开源项目（即QEMU和FFmpeg）的安全相关提交中提取的，并且功能多样化。然后，Lu等人[17]将这些项目合并，然后拆分为训练/验证/测试集。

##### 训练设置:

构建了一个2层模型,batch size:128,使用Adam 优化器(Adam optimizer)训练100 epochs

设置相同的hidden size 给hidden GNN层 改变值 {128,256,384}

改变滑动窗口(sliding window)大小:{2,3,4,5}

Adam initial learning rate(lr) {1e^-4^,5e^-4^,1e^-3^}

针对最佳模型检查点报告测试集上的最终精度，该检查点在验证集上获得最高精度。

•BiLSTM[9]和TextCNN[11]是应用于文本分类的两个众所周知的标准模型。

•RoBERTa[16]是在BERT[4]的基础上构建的，方法是删除下一个句子目标，并在具有较大小批量和学习率的大规模数据集上进行训练。

•Devign[30]从原始源代码构建一个多边缘图，然后使用门控GNN[14]更新节点表示，最后使用基于一维CNN的池化（“Conv”）进行预测。我们注意到周等人[30]没有公布Devign的正式实施。因此，我们使用相同的训练和评估协议重新实现Devign。

•CodeBERT[5]是一个预训练模型，也是基于6种编程语言（Python、Java、JavaScript、PHP、Ruby、Go）的BERT，使用屏蔽语言模型[4]和替换的令牌检测[3]目标。

•GraphCodeBERT[6]是一种新的预训练PL模型，扩展了CodeBERT以考虑进入训练目标的代码数据流的固有结构。

表1：测试集上的漏洞检测准确率（%）。最佳分数以粗体显示，次佳分数以下划线显示。BiLSTM、TextCNN、RoBERTa 和 CodeBERT 的结果取自[17]。★ 表示我们为其他基线报告的结果。“Idx” 和 “UniT” 分别表示基于索引的图构建和基于唯一标记的图构建。“CB” 和 “G-CB” 分别表示仅使用 CodeBERT 和 GraphCodeBERT 的令牌嵌入层来初始化节点特征。

![image-20240425094344933](https://s2.loli.net/2024/04/25/67JabBcFfIl9ZnD.png)

表1呈现了提出的ReGVD和最新强基线在来自CodeXGLUE漏洞检测实际基准数据集上的准确性结果。我们注意到最近的模型CodeBERT和GraphCodeBERT都取得了竞争力的表现，并且优于Devign，表明预训练PL模型的有效性。

更重要的是，ReGVD分别比CodeBERT和GraphCodeBERT提高了1.61%和1.39%的绝对改进。这表明了ReGVD在学习源代码内部的局部结构以区分漏洞方面有益处（相较于仅使用预训练PL模型的令牌嵌入层）。因此，我们的ReGVD显著优于最新的基线模型。

尤其是，ReGVD在CodeXGLUE漏洞检测数据集上实现了63.69%的最高准确性——创下了最新的最优结果。我们观察图3a的图层阅读层，以确定ReGVD中提出的图层比Devign中使用的Conv汇聚层性能更好。由于Devign还使用门控GNN来更新节点表示，并为设置（Idx+G-CB）取得了61.31%的最佳准确率；因此，我们考虑不使用残差连接进行公平比较的ReGVD设置（GGNN+Idx +G-CB），在其中，ReGVD实现了63.51%的准确率，比Devign高出2.20%。总的来说，从不使用残差连接的三个剩余ReGVD设置结果中，我们得出类似的结论：ReGVD中使用的图层阅读层优于Devign中使用的图层。

我们分析了残差连接和混合函数的影响。首先，我们回顾图3a，比较了在GNN层间是否使用残差连接对ReGVD准确性的影响。结果显示，残差连接有助于提升GNN在七种设置下的表现，其中在ReGVD设置（GCN+Idx+GCB）中准确率提高了最多达到2.05%。接着，我们看了图3b，比较了在不同MIX函数下的ReGVD结果。我们发现，使用MUL操作符的情况下，ReGVD在六种设置中通常获得最高准确性，在剩下的两种设置中使用SUM操作符。值得注意的是，使用CONCAT操作符的ReGVD设置（GGNN+Idx+CB）准确率为62.59%，仍高于Devign、CodeBERT和GraphCodeBERT。此外，相比使用完整训练数据的基准模型，我们的模型在有限的训练数据下也实现了令人满意的性能。例如，ReGVD在60%的训练集上取得了61.68%的准确率，高于BiLSTM、TextCNN、RoBERTa和Devign的准确率。它还在80%的训练集上取得了62.55%的准确率，优于CodeBERT和GraphCodeBERT。

![image-20240425094753437](https://s2.loli.net/2024/04/25/Ev2INkdaOLf7TbG.png)

## 结论 

我们将漏洞识别视为归纳文本分类问题，并引入了一种简单但有效的基于图神经网络的模型，命名为ReGVD，用于检测源代码中的漏洞。ReGVD将每个原始源代码转化为一个图，在这个过程中，ReGVD仅利用预训练编程语言模型的标记嵌入层来初始化节点特征向量。ReGVD利用GNN层之间的残差连接和总和与最大池化的混合来学习图的表示。为了证明ReGVD的有效性，我们进行了大量实验证明ReGVD在CodeXGLUE的基准漏洞检测数据集上与强大且最新的基准模型进行比较。实验结果表明，所提出的ReGVD明显优于基准模型，并在基准数据集上获得了63.69％的最高准确率。ReGVD可以看作是一个通用、实用且与编程语言无关的模型，可以在各种源代码和库上顺利运行。